---
title: 面试题
categories:
- Software
- Concept
---
# 面试题

## JVM

### 说一下垃圾回收机制？

- Java 语言中一个显著的特点就是引入了垃圾回收机制，在编写程序的时候不再需要考虑内存管理。垃圾回收机制可以有效的防止内存泄露，提高内存的内存率。
- 垃圾回收器通常是作为一个单独的低级线程运行，不可预知的情况下对堆中已经死亡的或者长时间没有使用的对象进行清理和回收。
- 回收机制的算法有：标记清除算法、复制算法、标记压缩算法等等。

### GC是什么？为什么要有GC？

- GC是垃圾收集的意思，内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃，Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的，Java语言没有提供释放已分配内存的显示操作方法。Java程序员不用担心内存管理，因为垃圾收集器会自动进行管理。要请求垃圾收集，可以调用下面的方法之一：`System.gc() `或`Runtime.getRuntime().gc()` ，但JVM可以屏蔽掉显示的垃圾回收调用。 
- 垃圾回收可以有效的防止内存泄露，有效的使用可以使用的内存。垃圾回收器通常是作为一个单独的低优先级的线程运行，不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收，程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收。在Java诞生初期，垃圾回收是Java最大的亮点之一，因为服务器端的编程需要有效的防止内存泄露问题，然而时过境迁，如今Java的垃圾回收机制已经成为被诟病的东西。移动智能终端用户通常觉得iOS的系统比Android系统有更好的用户体验，其中一个深层次的原因就在于Android系统中垃圾回收的不可预知性。

> **补充**：垃圾回收机制有很多种，包括：分代复制垃圾回收、标记垃圾回收、增量垃圾回收等方式。标准的Java进程既有栈又有堆。栈保存了原始型局部变量，堆保存了要创建的对象。Java平台对堆内存回收和再利用的基本算法被称为标记和清除，但是Java对其进行了改进，采用“分代式垃圾收集”。这种方法会跟Java对象的生命周期将堆内存划分为不同的区域，在垃圾收集过程中，可能会将对象移动到不同区域： 
>
> - 伊甸园（Eden）：这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。 
> - 幸存者乐园（Survivor）：从伊甸园幸存下来的对象会被挪到这里。 
> - 终身颐养园（Tenured）：这是足够老的幸存对象的归宿。年轻代收集（Minor-GC）过程是不会触及这个地方的。当年轻代收集不能把对象放进终身颐养园时，就会触发一次完全收集（Major-GC），这里可能还会牵扯到压缩，以便为大对象腾出足够的空间。

### 与垃圾回收相关的JVM参数：

> -Xms / -Xmx — 堆的初始大小 / 堆的最大大小
>
> -Xmn — 堆中年轻代的大小
> -XX:-DisableExplicitGC — 让System.gc()不产生任何作用
> -XX:+PrintGCDetails — 打印GC的细节
> -XX:+PrintGCDateStamps — 打印GC操作的时间戳
> -XX:NewSize / XX:MaxNewSize — 设置新生代大小/新生代最大大小
> -XX:NewRatio — 可以设置老生代和新生代的比例
> -XX:PrintTenuringDistribution — 设置每次新生代GC后输出幸存者乐园中对象年龄的分布
> -XX:InitialTenuringThreshold / -XX:MaxTenuringThreshold：设置老年代阀值的初始值和最大值
> -XX:TargetSurvivorRatio：设置幸存区的目标使用率

### 描述一下垃圾回收的流程？

- 首先有三个代，新生代、老年代、永久代。
- 在新生代有三个区域：一个Eden区和两个Survivor区。当一个实例被创建了，首先会被存储Eden 区中。
- 具体过程是这样的：
  - 一个对象实例化时，先去看Eden区有没有足够的空间。
  - 如果有，不进行垃圾回收，对象直接在Eden区存储。
  - 如果Eden区内存已满，会进行一次minor gc。
  - 然后再进行判断Eden区中的内存是否足够。
  - 如果不足，则去看存活区的内存是否足够。
  - 如果内存足够，把Eden区部分活跃对象保存在存活区，然后把对象保存在Eden区。
  - 如果内存不足，查询老年代的内存是否足够。
  - 如果老年代内存足够，将部分存活区的活跃对象存入老年代。然后把Eden区的活跃对象放入存活区，对象依旧保存在Eden区。
  - 如果老年代内存不足，会进行一次full gc，之后老年代会再进行判断 内存是否足够，如果足够 还是那些步骤。
  - 如果不足，会抛出OutOfMemoryError（内存溢出异常）。

### 描述一下JVM加载class文件的原理机制？

- JVM中类的装载是由类加载器（ClassLoader）和它的子类来实现的，Java中的类加载器是一个重要的Java运行时系统组件，它负责在运行时查找和装入类文件中的类。 
- 由于Java的跨平台性，经过编译的Java源程序并不是一个可执行程序，而是一个或多个类文件。当Java程序需要使用某个类时，JVM会确保这个类已经被加载、连接（验证、准备和解析）和初始化。类的加载是指把类的.class文件中的数据读入到内存中，通常是创建一个字节数组读入.class文件，然后产生与所加载类对应的Class对象。加载完成后，Class对象还不完整，所以此时的类还不可用。当类被加载后就进入连接阶段，这一阶段包括验证、准备（为静态变量分配内存并设置默认的初始值）和解析（将符号引用替换为直接引用）三个步骤。最后JVM对类进行初始化，包括：1)如果类存在直接的父类并且这个类还没有被初始化，那么就先初始化父类；2)如果类中存在初始化语句，就依次执行这些初始化语句。 
- 类的加载是由类加载器完成的，类加载器包括：根加载器（BootStrap）、扩展加载器（Extension）、系统加载器（System）和用户自定义类加载器（java.lang.ClassLoader的子类）。从Java 2（JDK 1.2）开始，类加载过程采取了父亲委托机制（PDM）。PDM更好的保证了Java平台的安全性，在该机制中，JVM自带的Bootstrap是根加载器，其他的加载器都有且仅有一个父类加载器。类的加载首先请求父类加载器加载，父类加载器无能为力时才由其子类加载器自行加载。JVM不会向Java程序提供对Bootstrap的引用。下面是关于几个类加载器的

> **说明**：
>
> Bootstrap：一般用本地代码实现，负责加载JVM基础核心类库（rt.jar）
> Extension：从java.ext.dirs系统属性所指定的目录中加载类库，它的父加载器是Bootstrap
> System：又叫应用类加载器，其父类是Extension。它是应用最广泛的类加载器。它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类，是用户自定义加载器的默认父加载器。

### 解释内存中的栈(stack)、堆(heap)和方法区(method area)的用法。

通常我们定义一个基本数据类型的变量，一个对象的引用，还有就是函数调用的现场保存都使用JVM中的栈空间；而通过new关键字和构造器创建的对象则放在堆空间，堆是垃圾收集器管理的主要区域，由于现在的垃圾收集器都采用分代收集算法，所以堆空间还可以细分为新生代和老生代，再具体一点可以分为Eden、Survivor（又可分为From Survivor和To Survivor）、Tenured；方法区和堆都是各个线程共享的内存区域，用于存储已经被JVM加载的类信息、常量、静态变量、JIT编译器编译后的代码等数据；程序中的字面量（literal）如直接书写的100、"hello"和常量都是放在常量池中，常量池是方法区的一部分，。栈空间操作起来最快但是栈很小，通常大量的对象都是放在堆空间，栈和堆的大小都可以通过JVM的启动参数来进行调整，栈空间用光了会引发StackOverflowError，而堆和常量池空间不足则会引发OutOfMemoryError。

```java
String str = new String("hello");
```

- 上面的语句中变量str放在栈上，用new创建出来的字符串对象放在堆上，而"hello"这个字面量是放在方法区的。

> 补充1：较新版本的Java（从Java 6的某个更新开始）中，由于JIT编译器的发展和"逃逸分析"技术的逐渐成熟，栈上分配、标量替换等优化技术使得对象一定分配在堆上这件事情已经变得不那么绝对了。
> 补充2：运行时常量池相当于Class文件常量池具有动态性，Java语言并不要求常量一定只有编译期间才能产生，运行期间也可以将新的常量放入池中，String类的intern()方法就是这样的。

- 看看下面代码的执行结果是什么并且比较一下Java 7以前和以后的运行结果是否一致。

```java
String s1 = new StringBuilder("go")
  .append("od").toString();
System.out.println(s1.intern() == s1);
String s2 = new StringBuilder("ja")
  .append("va").toString();
System.out.println(s2.intern() == s2)
```

### 解释一下JVM的内存模型？

- Java内存模型决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，定义了线程和主内存之间的抽象关系。
- 线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存（并不真实存在），本地内存中存储的是在主内存中共享变量的副本。
- 有两条规定：
  1. 线程对共享变量的所有操作都必须在自己的工作内存中进行，不能直接从主内存中读写。
  2. 线程的工作内存是私有的，其他线程无法访问，线程变量值的传递通过主内存来完成。

### GC回收的是堆内存还是栈内存？

主要管理的是堆内存。

### 什么时候新生代会转换为老年代？

- Eden区满时，进行Minor GC时。
- 对象体积太大, 新生代无法容纳时。
- 虚拟机对每个对象定义了一个对象年龄（Age）计数器。当年龄增加到一定的临界值时，就会晋升到老年代中。
- 如果在Survivor区中相同年龄的对象的所有大小之和超过Survivor空间的一半，包括比这个年龄大的对象就都可以直接进入老年代。

### 创建占大内存的对象分配到哪一代？

如果新创建的对象占用内存很大，则直接分配到老年代

### 新生代2个Survivor区的好处？

解决了内存碎片化问题。整个过程中，永远有一个Survivor区是空的，另一个非空的Survivor区是无碎片的。

### String s = new String("xyz");创建了几个字符串对象？

两个对象，一个是静态区的"xyz"，一个是用new创建在堆上的对象。

### Java 中会存在内存泄漏吗，请简单描述。 

理论上Java因为有垃圾回收机制（GC）不会存在内存泄露问题（这也是Java被广泛使用于服务器端编程的一个重要原因）；然而在实际开发中，可能会存在无用但可达的对象，这些对象不能被GC回收，因此也会导致内存泄露的发生。例如Hibernate的Session（一级缓存）中的对象属于持久态，垃圾回收器是不会回收这些对象的，然而这些对象中可能存在无用的垃圾对象，如果不及时关闭（close）或清空（flush）一级缓存就可能导致内存泄露。下面例子中的代码也会导致内存泄露。

上面的代码实现了一个栈（先进后出（FILO））结构，乍看之下似乎没有什么明显的问题，它甚至可以通过你编写的各种单元测试。然而其中的pop方法却存在内存泄露的问题，当我们用pop方法弹出栈中的对象时，该对象不会被当作垃圾回收，即使使用栈的程序不再引用这些对象，因为栈内部维护着对这些对象的过期引用（obsolete reference）。在支持垃圾回收的语言中，内存泄露是很隐蔽的，这种内存泄露其实就是无意识的对象保持。如果一个对象引用被无意识的保留起来了，那么垃圾回收器不会处理这个对象，也不会处理该对象引用的其他对象，即使这样的对象只有少数几个，也可能会导致很多的对象被排除在垃圾回收之外，从而对性能造成重大影响，极端情况下会引发Disk Paging（物理内存与硬盘的虚拟内存交换数据），甚至造成OutOfMemoryError。

### 遇到过OOM怎么解决?

我们可以修改虚拟机的参数，获取Heap Dump的文件，后缀名是.hprof。

```
-XX:+HeapDumpOnOutOfMemoryError 
-XX:HeapDumpPath=d:\jvm
```

之后可以使用JDK自带的一个工具jvisualvm来进行排查和定位。

### Thread类的sleep()方法和对象的wait()方法都可以让线程暂停执行，它们有什么区别? 

答：sleep()方法（休眠）是线程类（Thread）的静态方法，调用此方法会让当前线程暂停执行指定的时间，将执行机会（CPU）让给其他线程，但是对象的锁依然保持，因此休眠时间结束后会自动恢复（线程回到就绪状态，请参考第66题中的线程状态转换图）。wait()是Object类的方法，调用对象的wait()方法导致当前线程放弃对象的锁（线程暂停执行），进入对象的等待池（wait pool），只有调用对象的notify()方法（或notifyAll()方法）时才能唤醒等待池中的线程进入等锁池（lock pool），如果线程重新获得对象的锁就可以进入就绪状态。

补充：可能不少人对什么是进程，什么是线程还比较模糊，对于为什么需要多线程编程也不是特别理解。简单的说：进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是操作系统进行资源分配和调度的一个独立单位；线程是进程的一个实体，是CPU调度和分派的基本单位，是比进程更小的能独立运行的基本单位。线程的划分尺度小于进程，这使得多线程程序的并发性高；进程在执行时通常拥有独立的内存单元，而线程之间可以共享内存。使用多线程的编程通常能够带来更好的性能和用户体验，但是多线程的程序对于其他程序是不友好的，因为它可能占用了更多的CPU资源。当然，也不是线程越多，程序的性能就越好，因为线程之间的调度和切换也会浪费CPU时间。时下很时髦的Node.js就采用了单线程异步I/O的工作模式。

### 线程的sleep()方法和yield()方法有什么区别？ 

- sleep()方法给其他线程运行机会时不考虑线程的优先级，因此会给低优先级的线程以运行的机会；yield()方法只会给相同优先级或更高优先级的线程以运行的机会
- 线程执行sleep()方法后转入阻塞（blocked）状态，而执行yield()方法后转入就绪（ready）状态
- sleep()方法声明抛出InterruptedException，而yield()方法没有声明任何异常
- sleep()方法比yield()方法（跟操作系统CPU调度相关）具有更好的可移植性

### 举例说明同步和异步。 

如果系统中存在临界资源（资源数量少于竞争资源的线程数量的资源），例如正在写的数据以后可能被另一个线程读到，或者正在读的数据可能已经被另一个线程写过了，那么这些数据就必须进行同步存取（数据库操作中的排他锁就是最好的例子）。当应用程序在对象上调用了一个需要花费很长时间来执行的方法，并且不希望让程序等待方法的返回时，就应该使用异步编程，在很多情况下采用异步途径往往更有效率。事实上，所谓的同步就是指阻塞式操作，而异步就是非阻塞式操作。

### 类加载的过程

1. 加载：查找和导入Class文件
2. 校验：检查载入Class文件数据的正确性
3. 准备：给类的静态变量分配存储空间
4. 解析：将符号引用转成直接引用
5. 初始化：对类的静态变量，静态代码块执行初始化操作

### 垃圾回收算法

## Java基础

### int和Integer的区别?

- int是基本数据类型，Integer是他的包装类。
- Integer保存的是对象的引用，int保存的变量值。
- Integer默认是null，int默认是0。
- Integer变量必须实例化后才能使用，而int变量不需要。

### Java的基本数据类型和大小？

```
单位：字节
boolean(1) = byte(1) < short(2) = char(2) < int(4) = float(4) < long(8) = double(8)
```

### Java类冲突怎么解决（jar包冲突）?

1. 使用`mvn: dependency tree`查看冲突的jar
2. 然后在pom文件里边  使用`exclusion`标签排除掉这些冲突的jar包

### 接口和抽象类的区别？

1. 接口中所有的方法隐含的都是抽象的。而抽象类则可以同时包含抽象和非抽象的方法。
2. 类可以实现很多个接口，但是只能继承一个抽象类。
3. Java接口中声明的变量默认都是final的。抽象类可以包含非final的变量。
4. Java接口中的成员函数默认是public的。抽象类的成员函数可以是private，protected或者是public。
5. 抽象类和接口都不能够实例化，但可以定义抽象类和接口类型的引用。
6. 一个类如果继承了某个抽象类或者实现了某个接口都需要对其中的抽象方法全部进行实现，否则该类仍然需要被声明为抽象类。
7. 接口比抽象类更加抽象，因为抽象类中可以定义构造器，可以有抽象方法和具体方法，而接口中不能定义构造器而且其中的方法全部都是抽象方法。
8. 抽象类中的成员可以是private、默认、protected、public的，而接口中的成员全都是public的。抽象类中可以定义成员变量，而接口中定义的成员变量实际上都是常量。有抽象方法的类必须被声明为抽象类，而抽象类未必要有抽象方法。 

### JAVA异常

异常的定义

异常就是有异于常态，和正常情况不一样，有错误出现。在java中，阻止当前方法或作用域的情况，称之为异常。

异常的分类

![img](https://img-blog.csdnimg.cn/20190612234942627.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFfY3hycw==,size_16,color_FFFFFF,t_70) 

Error：是程序中无法处理的错误，表示运行应用程序中出现了严重的错误。此类错误一般表示代码运行时JVM出现问题。通常有Virtual MachineError（虚拟机运行错误）、NoClassDefFoundError（类定义错误）等。比如说当jvm耗完可用内存时，将出现OutOfMemoryError。此类错误发生时，JVM将终止线程。非代码性错误。因此，当此类错误发生时，应用不应该去处理此类错误。

Exception：：程序本身可以捕获并且可以处理的异常。

运行时异常(不受检异常)：RuntimeException类极其子类表示JVM在运行期间可能出现的错误。编译器不会检查此类异常，并且不要求处理异常，比如用空值对象的引用（NullPointerException）、数组下标越界（ArrayIndexOutBoundException）。此类异常属于不可查异常，一般是由程序逻辑错误引起的，在程序中可以选择捕获处理，也可以不处理。

非运行时异常(受检异常)：Exception中除RuntimeException极其子类之外的异常。编译器会检查此类异常，如果程序中出现此类异常，比如说IOException，必须对该异常进行处理，要么使用try-catch捕获，要么使用throws语句抛出，否则编译不通过。

> - ArithmeticException（算术异常） 
> - ClassCastException （类转换异常） 
> - IllegalArgumentException （非法参数异常） 
> - IndexOutOfBoundsException （下标越界异常） 
> - NullPointerException （空指针异常） 
> - SecurityException （安全异常）

### String和StringBuilder、StringBuffer的区别？

Java平台提供了两种类型的字符串：String和StringBuffer/StringBuilder，它们可以储存和操作字符串。其中String是只读字符串，也就意味着String引用的字符串内容是不能被改变的。而StringBuffer/StringBuilder类表示的字符串对象可以直接进行修改。StringBuilder是Java 5中引入的，它和StringBuffer的方法完全相同，区别在于它是在单线程环境下使用的，因为它的所有方面都没有被synchronized修饰，因此它的效率也比StringBuffer要高。

> - **面试题1** - 什么情况下用+运算符进行字符串连接比调用StringBuffer/StringBuilder对象的append方法连接字符串性能更好？
> - **面试题2** - 请说出下面程序的输出。

```java
class StringEqualTest {

  public static void main(String[] args) {
    String s1 = "Programming";
    String s2 = new String("Programming");
    String s3 = "Program";
    String s4 = "ming";
    String s5 = "Program" + "ming";
    String s6 = s3 + s4;
    System.out.println(s1 == s2);// false
    System.out.println(s1 == s5);// true
    System.out.println(s1 == s6);// false
    System.out.println(s1 == s6.intern());// true
    System.out.println(s2 == s2.intern());// false
  }
}
```

> 补充：解答上面的面试题需要清楚两点：1. String对象的intern方法会得到字符串对象在常量池中对应的版本的引用（如果常量池中有一个字符串与String对象的equals结果是true），如果常量池中没有对应的字符串，则该字符串将被添加到常量池中，然后返回常量池中字符串的引用；2. 字符串的+操作其本质是创建了StringBuilder对象进行append操作，然后将拼接后的StringBuilder对象用toString方法处理成String对象，这一点可以用javap -c StringEqualTest.class命令获得class文件对应的JVM字节码指令就可以看出来。

### transient

- 我们都知道一个对象只要实现了Serilizable接口，这个对象就可以被序列化，java的这种序列化模式为开发者提供了很多便利，我们可以不必关系具体序列化的过程，只要这个类实现了Serilizable接口，这个类的所有属性和方法都会自动序列化。
- 然而在实际开发过程中，我们常常会遇到这样的问题，这个类的有些属性需要序列化，而其他属性不需要被序列化，打个比方，如果一个用户有一些敏感信息（如密码，银行卡号等），为了安全起见，不希望在网络操作（主要涉及到序列化操作，本地序列化缓存也适用）中被传输，这些信息对应的变量就可以加上transient关键字。换句话说，这个字段的生命周期仅存于调用者的内存中而不会写到磁盘里持久化。
- 总之，java 的transient关键字为我们提供了便利，你只需要实现Serilizable接口，将不需要序列化的属性前添加关键字transient，序列化对象的时候，这个属性就不会序列化到指定的目的地中。

### 浅复制和深复制？怎样实现深复制？

​	在 Java 中，除了**基本数据类型**（元类型）之外，还存在 **类的实例对象** 这个引用数据类型。而一般使用 『 **=** 』号做赋值操作的时候。对于基本数据类型，实际上是拷贝的它的值，但是对于对象而言，其实赋值的只是这个对象的引用，将原对象的引用传递过去，他们实际上还是指向的同一个对象。

而浅拷贝和深拷贝就是在这个基础之上做的区分，如果在拷贝这个对象的时候，只对基本数据类型进行了拷贝，而对引用数据类型只是进行了引用的传递，而没有真实的创建一个新的对象，则认为是浅拷贝。反之，在对引用数据类型进行拷贝的时候，创建了一个新的对象，并且复制其内的成员变量，则认为是深拷贝。

### 自动拆箱装箱

**自动装箱与自动拆箱的实现原理**

- 既然Java提供了自动拆装箱的能力，那么，我们就来看一下，到底是什么原理，Java是如何实现的自动拆装箱功能。
- 自动拆装箱的代码：

```java
public static void main(String[]args){
  Integer integer=1; //装箱
  int i=integer; //拆箱
}
```

- 对以上代码进行反编译后可以得到以下代码：

```java
public static void main(String[]args){
  Integer integer=Integer.valueOf(1); 
  int i=integer.intValue(); 
}
```

**哪些地方会自动拆装箱**

1. 将基本数据类型放入集合类
2. 包装类型和基本类型的大小比较:包装类与基本数据类型进行比较运算，是先将包装类进行拆箱成基本数据类型，然后进行比较的。
3. 包装类型的运算:两个包装类型之间的运算，会被自动拆箱成基本类型进行
4. 三目运算符的使用:当第二，第三位操作数分别为基本类型和对象时，其中的对象就会拆箱为基本类型进行操作。

### Java中如何实现序列化，有什么意义？

- 序列化就是一种用来处理对象流的机制，所谓对象流也就是将对象的内容进行流化。可以对流化后的对象进行读写操作，也可将流化后的对象传输于网络之间。序列化是为了解决对象流读写操作时可能引发的问题（如果不进行序列化可能会存在数据乱序的问题）。 
- 要实现序列化，需要让一个类实现Serializable接口，该接口是一个标识性接口，标注该类对象是可被序列化的，然后使用一个输出流来构造一个对象输出流并通过writeObject(Object)方法就可以将实现对象写出（即保存其状态）；如果需要反序列化则可以用一个输入流建立对象输入流，然后通过readObject方法从流中读取对象。序列化除了能够实现对象的持久化之外，还能够用于对象的深度克隆（可以参考第29题）。

### 请列举你所知道的Object类的方法并简要说明

Object()默认构造方法。clone() 创建并返回此对象的一个副本。equals(Object obj) 指示某个其他对象是否与此对象“相等”。finalize()当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。getClass()返回一个对象的运行时类。hashCode()返回该对象的哈希码值。 notify()唤醒在此对象监视器上等待的单个线程。 notifyAll()唤醒在此对象监视器上等待的所有线程。toString()返回该对象的字符串表示。wait()导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。wait(long timeout)导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者超过指定的时间量。wait(long timeout, int nanos) 导致当前的线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法，或者其他某个线程中断当前线程，或者已超过某个实际时间量。

## 反射

### 获得一个类的类对象有哪些方式？ 

1. 类型.class，例如：String.class 
2. 对象.getClass()，例如："hello".getClass() 
3. Class.forName()，例如：Class.forName("java.lang.String")

### 如何通过反射创建对象？

1. 通过类对象调用newInstance()方法，例如：String.class.newInstance() 
2. 通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器（Constructor）对象并调用其newInstance()方法创建对象，例如：String.class.getConstructor(String.class).newInstance("Hello");

### 如何通过反射获取和设置对象私有字段的值？

- 可以通过类对象的getDeclaredField()方法字段（Field）对象，然后再通过字段对象的setAccessible(true)将其设置为可以访问，接下来就可以通过get/set方法来获取/设置字段的值了。

### 如何通过反射调用对象的方法？

```java
import java.lang.reflect.Method;

class MethodInvokeTest {

  public static void main(String[] args) throws Exception {
    String str = "hello";
    Method m = str.getClass().getMethod("toUpperCase");
    System.out.println(m.invoke(str));  // HELLO
  }
}
```

## 多线程

### 线程的状态

**线程的状态**

- Java中线程的状态分为6种。

  1. 初始(NEW)：新创建了一个线程对象，但还没有调用start()方法。
  2. 运行(RUNNABLE)：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为“运行”。
     线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此时处于就绪状态（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态（running）。
  3. 阻塞(BLOCKED)：表示线程阻塞于锁。
  4. 等待(WAITING)：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）。
  5. 超时等待(TIMED_WAITING)：该状态不同于WAITING，它可以在指定的时间后自行返回。
  6. 终止(TERMINATED)：表示该线程已经执行完毕。
- 这6种状态定义在Thread类的State枚举中，可查看源码进行一一对应

**线程的状态图**

<img src="https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-14-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==,size_16,color_FFFFFF,t_70.jpeg" alt="线程状态图" style="zoom: 50%;" />

### 线程池的参数有哪些，拒绝策略

- 主要参数有：
  - 线程池核心线程数大小
  - 最大线程数
  - 存储的队列
  - 拒绝策略
  - 空闲线程存活时长

- 当需要任务大于核心线程数时候，就开始把任务往存储任务的队列里，当存储队列满了的话，就开始增加线程池创建的线程数量，如果当线程数量也达到了最大，就开始执行拒绝策略，比如说记录日志，直接丢弃，或者丢弃最老的任务，或者交给提交任务的线程执行。

- 当一个线程完成时，它会从队列中取下一个任务来执行。当一个线程无事可做，且超过一定的时间（keepAliveTime）时，如果当前运行的线程数大于核心线程数，那么这个线程会停掉了。

### 多线程的创建方式

- 继承Thread类
- 实现Runnable接口
- 直接使用线程池
- 通过实现callable接口

实现Runnable接口这种方式更受欢迎，已经继承别的类的情况下只能实现接口。

### 进程与线程的区别

- 线程具有许多传统进程所具有的特征，故又称为轻型进程(Light—Weight Process)或进程元；而把传统的进程称为重型进程(Heavy—Weight Process)，它相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都有若干个线程，至少包含一个线程。
- 根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位,常用的Windows、Linux等操作系统都采用抢占式多任务，如何调度线程完全由操作系统决定，程序自己不能决定什么时候执行，以及执行多长时间。
- 资源开销：每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。
- 包含关系：如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
- 内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的
- 影响关系：一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
- 执行过程：每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

### 避免死锁

1. 避免一个线程同时获得多个锁
2. 避免一个线程在锁内部占有多个资源,尽量保证每个锁只占用一个资源
3. 尝试使用定时锁,使用lock.tryLock ( timeOut ) ,当超时等待时当前线程不会堵塞
4. 对于数据库锁,加锁和解锁必须在一个数据库连接里,否则会出现解锁失败的情况

### Sleep(0)表示什么？

- 触发操作系统立刻重新进行一次CPU竞争，竞争的结果也许是当前线程仍然获得CPU控制权，也许会换成别的线程获得CPU控制权。
- 线程有三个状态，就绪态，运行态，等待态。Sleep(n)方法是让当前线程在n秒内不会参与CPU竞争。线程进入等待队列，n秒之后再次进入就绪队列。
- Sleep(0)是让线程直接进入就绪状态。

### Sleep与Wait区别？

- sleep是线程类（Thread）的方法，导致此线程暂停执行指定时间，把执行机会给其他线程，但是监控状态依然保持，到时后会自动恢复。调用sleep不会释放对象锁。
- wait是Object类的方法，对象调用wait方法导致本线程放弃对象锁，进入等待池，只有针对此对象发出notify方法（或notifyAll）后本线程才进入锁池准备抢夺对象锁。

### 请你讲讲wait方法的底层原理

ObjectSynchronizer::wait方法通过object的对象中找到ObjectMonitor对象调用方法 void ObjectMonitor::wait(jlong millis, bool interruptible, TRAPS) 

通过ObjectMonitor::AddWaiter调用把新建立的ObjectWaiter对象放入到 _WaitSet 的队列的末尾中然后在ObjectMonitor::exit释放锁，接着 thread_ParkEvent->park 也就是wait。

### Thread.Join方法

- Thread.Join把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。
- 比如在线程B中调用了线程A的Join()方法，直到线程A执行完毕后，才会继续执行线程B。

### Lock锁与synchronized的区别？

- Lock能完成synchronized的所有功能。
- Lock是Java 5以后引入的新的API，和关键字synchronized相比主要相同点：Lock 能完成synchronized所实现的所有功能；主要不同点：Lock有比synchronized更精确的线程语义和更好的性能，而且不强制性的要求一定要获得锁。synchronized会自动释放锁，而Lock一定要求程序员手工释放，并且最好在finally 块中释放（这是释放外部资源的最好的地方）。
- Lock可以知道是不是已经获取到锁，而synchronized无法知道。
- synchronized是Java的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。JDK1.5以后引入了自旋锁、锁粗化、轻量级锁，偏向锁来有优化关键字的性能。
- Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现；synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁；Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断；通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。

### synchronize底层是怎么实现的

synchronize是java中的关键字，可以用来修饰实例方法、静态方法、还有代码块；主要有三种作用：可以确保原子性、可见性、有序性。

- 原子性就是能够保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等该线程处理完数据后才能进行。
- 可见性就是当一个线程在修改共享数据时，其他线程能够看到。
- 有序性就是，被synchronize锁住后的线程相当于单线程，在单线程环境jvm的重排序是不会改变程序运行结果的，可以防止重排序对多线程的影响

- synchronized的底层原理是跟monitor有关，也就是视图器锁，每个对象都有一个关联的monitor，当Synchronize获得monitor对象的所有权后会进行两个指令：加锁指令跟减锁指令。
- monitor里面有个计数器，初始值是从0开始的。如果一个线程想要获取monitor的所有权，就看看它的计数器是不是0，如果是0的话，那么就说明没人获取锁，那么它就可以获取锁了，然后将计数器+1，也就是执行monitorenter加锁指令；monitorexit减锁指令是跟在程序执行结束和异常里的，如果不是0的话，就会陷入一个堵塞等待的过程，直到为0等待结束。

- `synchronized`是同步锁，同步块内的代码相当于同一时刻单线程执行，故不存在原子性和指令重排序的问题
- `synchronized`关键字的语义JMM有两个规定，保证其实现内存可见性：
  - 线程解锁前，必须把共享变量的最新值刷新到主内存中；
  - 线程加锁前，将清空工作内存中共享变量的值，从主内存中冲洗取值。

### CAS是一种什么样的同步机制？

-  CAS，是Compare and Swap的简称，在这个机制中有三个核心的参数：
- 主内存中存放的共享变量的值：V（一般情况下这个V是内存的地址值，通过这个地址可以获得内存中的值）
- 工作内存中共享变量的副本值，也叫预期值：A
- 需要将共享变量更新到的最新值：B

### volatile的底层如何实现，怎么就能保住可见性了？

为什么要对线程间共享的变量用关键字`volatile`声明？这涉及到Java的内存模型。在Java虚拟机中，变量的值保存在主内存中，但是，当线程访问变量时，它会先获取一个副本，并保存在自己的工作内存中。如果线程修改了变量的值，虚拟机会在某个时刻把修改后的值回写到主内存，但是，这个时间是不确定的！

这会导致如果一个线程更新了某个变量，另一个线程读取的值可能还是更新前的。例如，主内存的变量`a = true`，线程1执行`a = false`时，它在此刻仅仅是把变量`a`的副本变成了`false`，主内存的变量`a`还是`true`，在JVM把修改后的`a`回写到主内存之前，其他线程读取到的`a`的值仍然是`true`，这就造成了多线程之间共享的变量不一致。

因此，`volatile`关键字的目的是告诉虚拟机：

- 每次访问变量时，总是获取主内存的最新值；
- 每次修改变量后，立刻回写到主内存。

`volatile`关键字解决的是可见性问题：当一个线程修改了某个共享变量的值，其他线程能够立刻看到修改后的值。

volatile关键字是用来保证有序性和可见性的。这跟Java内存模型有关。比如我们所写的代码，不一定是按照我们自己书写的顺序来执行的，编译器会做重排序，CPU也会做重排序的，这样的重排序是为了减少流水线的阻塞的，引起流水阻塞，比如数据相关性，提高CPU的执行效率。需要有一定的顺序和规则来保证，不然程序员自己写的代码都不知带对不对了，所以有happens-before规则，其中有条就是volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；有序性实现的是通过插入内存屏障来保证的。可见性：首先Java内存模型分为，主内存，工作内存。比如线程A从主内存把变量从主内存读到了自己的工作内存中，做了加1的操作，但是此时没有将i的最新值刷新会主内存中，线程B此时读到的还是i的旧值。加了volatile关键字的代码生成的汇编代码发现，会多出一个lock前缀指令。Lock指令对Intel平台的CPU，早期是锁总线，这样代价太高了，后面提出了缓存一致性协议，MESI，来保证了多核之间数据不一致性问题。

volatile是轻量级的synchronized，比它的执行成本更低,因为它不会引起线程的上下文切换，它保证了共享变量的`可见性`，`可见性`的意思是当一个线程修改一个变量时，另外一个线程能读到这个修改的值。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。还有就是它通过添加内存屏障的方式禁止指令的重排序。

**1.1、volatile变量的可见性**

Java虚拟机规范中定义了一种Java内存 模型（Java Memory Model，即JMM）来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的并发效果。Java内存模型的主要目标就是**定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的细节**。

JMM中规定所有的变量都存储在主内存（Main Memory）中，每条线程都有自己的工作内存（Work Memory），线程的工作内存中保存了该线程所使用的变量的从主内存中拷贝的副本。线程对于变量的读、写都必须在工作内存中进行，而不能直接读、写主内存中的变量。同时，本线程的工作内存的变量也无法被其他线程直接访问，必须通过主内存完成。

整体内存模型如下图所示：



![img](https://pic1.zhimg.com/80/v2-cf02b047fcd7eab8fe4e5e0b59e2e3f0_720w.jpg)



对于普通共享变量，线程A将变量修改后，体现在此线程的工作内存。在尚未同步到主内存时，若线程B使用此变量，从主内存中获取到的是修改前的值，便发生了共享变量值的不一致，也就是出现了**线程的可见性问题**。

`volatile`定义：

- 当对volatile变量执行写操作后，JMM会把工作内存中的最新变量值强制刷新到主内存
- 写操作会导致其他线程中的缓存无效

这样，其他线程使用缓存时，发现本地工作内存中此变量无效，便从主内存中获取，这样获取到的变量便是最新的值，实现了线程的可见性。

**1.2、volatile变量的禁止指令重排序**

`volatile`是通过编译器在生成字节码时，在指令序列中添加“**内存屏障**”来禁止指令重排序的。

硬件层面的“**内存屏障**”：

- **sfence**：即写屏障(Store Barrier)，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存，以保证写入的数据立刻对其他线程可见
- **lfence**：即读屏障(Load Barrier)，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据，以保证读取的是最新的数据。
- **mfence**：即全能屏障(modify/mix Barrier )，兼具sfence和lfence的功能
- **lock 前缀**：lock不是内存屏障，而是一种锁。执行时会锁住内存子系统来确保执行顺序，甚至跨多个CPU。

JMM层面的“**内存屏障**”：

- **LoadLoad屏障**： 对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
- **StoreStore屏障**：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
- **LoadStore屏障**：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
- **StoreLoad屏障**： 对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。

JVM的实现会在volatile读写前后均加上内存屏障，在一定程度上保证有序性。如下所示：

> LoadLoadBarrier
> volatile 读操作
> LoadStoreBarrier
>
> StoreStoreBarrier
> volatile 写操作
> StoreLoadBarrier

### 如何实现主线程等待子线程执行完后再继续执行？

1. 我们可以使用join方法，在主线程内部调用子线程.join方法。
2. CountDownLatch实现
   - 这是一个属于JUC的工具类，从1.5开始。主要用到方法是countDown() 和 await()。
   - await()方法阻塞当前线程，直到计数器等于0。
   - countDown()方法将计数器减一。
   - 思路：我们可以在创建CountDownLatch对象，然后将此对象通过构造参数传递给子线程，在开启子线程后主线程调用await()方法阻塞主线程，子线程调用countDown()方法计数器减一。

### 有几种线程池？并且详细描述一下线程池的实现过程

1. newFixedThreadPool创建一个指定大小的线程池。每当提交一个任务就创建一个线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到等待队列中。

2. newCachedThreadPool创建一个可缓存的线程池。这种类型的线程池特点是：

3. - 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程。
   - 如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。

4. newSingleThreadExecutor创建一个单线程的Executor，即只创建唯一的工作者线程来执行任务，如果这个线程异常结束，会有另一个取代它，保证顺序执行(我觉得这点是它的特色)。

5. newScheduleThreadPool创建一个定长的线程池，而且支持定时的以及周期性的任务执行，类似于Timer。(这种线程池原理暂还没完全了解透彻)

### 线程池的主要参数和处理流程

在面向对象编程中，创建和销毁对象是很费时间的，因为创建一个对象要获取内存资源或者其它更多资源。在Java中更是如此，虚拟机将试图跟踪每一个对象，以便能够在对象销毁后进行垃圾回收。所以提高服务程序效率的一个手段就是尽可能减少创建和销毁对象的次数，特别是一些很耗资源的对象创建和销毁，这就是”池化资源”技术产生的原因。线程池顾名思义就是事先创建若干个可执行的线程放入一个池（容器）中，需要的时候从池中获取线程不用自行创建，使用完毕不需要销毁线程而是放回池中，从而减少创建和销毁线程对象的开销。 

- 主要参数有：
  - 线程池核心线程数大小
  - 最大线程数
  - 存储的队列
  - 拒绝策略
  - 空闲线程存活时长
- 当需要任务大于核心线程数时候，就开始把任务往存储任务的队列里，当存储队列满了的话，就开始增加线程池创建的线程数量，如果当线程数量也达到了最大，就开始执行拒绝策略，比如说记录日志，直接丢弃，或者丢弃最老的任务，或者交给提交任务的线程执行。
- 当一个线程完成时，它会从队列中取下一个任务来执行。当一个线程无事可做，且超过一定的时间（keepAliveTime）时，如果当前运行的线程数大于核心线程数，那么这个线程会停掉了。

### 线程池的submit和execute的区别

1. execute提交的方式

   execute提交的方式只能提交一个Runnable的对象，且该方法的返回值是void，也即是提交后如果线程运行后，和主线程就脱离了关系了，当然可以设置一些变量来获取到线程的运行结果。并且当线程的执行过程中抛出了异常通常来说主线程也无法获取到异常的信息的，只有通过ThreadFactory主动设置线程的异常处理类才能感知到提交的线程中的异常信息。

2. submit提交的方式:submit提交的方式有如下三种情况

1. 

```java
<T> Future<T> submit(Callable<T> task);
```

这种提交的方式是提交一个实现了Callable接口的对象，Callable接口的定义如下

```java
public interface Callable<V> {
    /**
     * Computes a result, or throws an exception if unable to do so.
     *
     * @return computed result
     * @throws Exception if unable to compute a result
     */
    V call() throws Exception;
}
```

- 可以看到Callable接口和Runnable接口的定义很类似，只不过Runnable接口中是一个没有返回值的run方法，而Callable接口中是一个有返回值的call方法。
- 这种提交的方式会返回一个Future对象，这个Future对象代表这线程的执行结果，（前一阵子去阿里面试，还被问到Future是什么这个问题了，现在想想这个问题当初自己解释的是不是不太让面试官满意啊）
- 当主线程调用Future的get方法的时候会获取到从线程中返回的结果数据。
- 如果在线程的执行过程中发生了异常，get会获取到异常的信息。

2. 

```java
Future<?> submit(Runnable task);
```

也可以提交一个Runable接口的对象，这样当调用get方法的时候，如果线程执行成功会直接返回null，如果线程执行异常会返回异常的信息

```java
<T> Future<T> submit(Runnable task, T result);
```

这个接口就比较有意思了，除了task之外还有一个result对象，当线程正常结束的时候调用Future的get方法会返回result对象，当线程抛出异常的时候会获取到对应的异常的信息。

### ThreadLocal原理

## 集合

### List，Set，Map的区别？

- List以特定索引来存取元素，可以有重复元素。Set不能存放重复元素（用对象的equals()方法来区分元素是否重复）。
- Map保存键值对（key-value pair）映射，映射关系可以是一对一或多对一。
- Set和Map容器都有基于哈希存储和排序树的两种实现版本，基于哈希存储的版本理论存取时间复杂度为O(1)，而基于排序树版本的实现在插入或删除元素时会按照元素或元素的键（key）构成排序树从而达到排序和去重的效果。

### HashMap、Hashtable、LinkedHashMap 和 TreeMap 比较

- Hashmap 是一个最常用的 Map，它根据键的 HashCode 值存储数据，根据键可以直接获取它的值，具有很快的访问速度。遍历时，取得数据的顺序是完全随机的。**HashMap 最多只允许一条记录的键为 Null；允许多条记录的值为 Null；HashMap 不支持线程的同步，即任一时刻可以有多个线程同时写 HashMap；可能会导致数据的不一致。**如果需要同步，可以用 Collections 的 synchronizedMap 方法使 HashMap 具有同步的能力。
- Hashtable 与 HashMap 类似，不同的是：**它不允许记录的键或者值为空；它支持线程的同步**，即任一时刻只有一个线程能写 Hashtable，因此也导致了 Hashtale 在写入时会比较慢。
- LinkedHashMap 是 HashMap 的一个子类，如果需要输出的顺序和输入的相同，那么用 LinkedHashMap 可以实现，它还可以按读取顺序来排列，像连接池中可以应用。
  - LinkedHashMap 保存了记录的插入顺序，在用 Iterator 遍历 LinkedHashMap 时，先得到的记录肯定是先插入的，也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比 HashMap 慢，不过有种情况例外，**当 HashMap 容量很大，实际数据较少时，遍历起来可能会比 LinkedHashMap 慢，因为 LinkedHashMap 的遍历速度只和实际数据有关，和容量无关，而 HashMap 的遍历速度和他的容量有关。**
  - **LinkedHashMap 实现与 HashMap 的不同之处在于，后者维护着一个运行于所有条目的双重链表**。此链接列表定义了迭代顺序，该迭代顺序可以是插入顺序或者是访问顺序。对于 LinkedHashMap 而言，它继承与 HashMap、底层使用哈希表与双向链表来保存所有元素。其基本操作与父类 HashMap 相似，它通过重写父类相关的方法，来实现自己的链接列表特性。
- **TreeMap 实现 SortMap 接口，内部实现是红黑树。**能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用 Iterator 遍历 TreeMap 时，得到的记录是排过序的。TreeMap 不允许 key 的值为 null。非同步的。
  - TreeMap 取出来的是排序后的键值对。但如果您要按自然顺序或自定义顺序遍历键，那么 TreeMap 会更好。

### 请说说快速失败(fail-fast)和安全失败(fail-safe)的区别？

Iterator的安全失败是基于对底层集合做拷贝，因此，它不受源集合上修改的影响。java.util包下面的所有的集合类都是快速失败的，而java.util.concurrent包下面的所有的类都是安全失败的。快速失败的迭代器会抛出ConcurrentModificationException异常，而安全失败的迭代器永远不会抛出这样的异常。

### 红黑树

一种二叉查找树，但在每个节点增加一个存储位表示节点的颜色，可以是红或黑（非红即黑）。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍，因此，红黑树是一种弱平衡二叉树（由于是弱平衡，可以看到，在相同的节点情况下，AVL树的高度低于红黑树），相对于要求严格的AVL树来说，它的旋转次数少，所以对于搜索，插入，删除操作较多的情况下，我们就用红黑树。


1. 每个节点非黑即红。
2. 根节点是黑色的。
3. 每个哨兵节点是黑色的。
4. 红节点的两个子节点都是黑色的。
5. 每个节点到后代哨兵节点路径上的黑色节点数量是一样多的。

### 重写 equals 和 hashCode

正确使用`Map`必须保证：

1. 作为`key`的对象必须正确覆写`equals()`方法，相等的两个`key`实例调用`equals()`必须返回`true`
2. 作为`key`的对象还必须正确覆写`hashCode()`方法，因为通过`key`计算索引的方式就是调用`key`对象的`hashCode()`方法，它返回一个`int`整数。`HashMap`正是通过这个方法直接定位`key`对应的`value`的索引，继而直接返回`value`,且`hashCode()`方法要严格遵循以下规范：
   - 如果两个对象相等，则两个对象的`hashCode()`必须相等
   - 如果两个对象不相等，则两个对象的`hashCode()`尽量不要相等。
3. 即对应两个实例`a`和`b`：
   - 如果`a`和`b`相等，那么`a.equals(b)`一定为`true`，则`a.hashCode()`必须等于`b.hashCode()`；
   - 如果`a`和`b`不相等，那么`a.equals(b)`一定为`false`，则`a.hashCode()`和`b.hashCode()`尽量不要相等。

### TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？

TreeSet要求存放的对象所属的类必须实现Comparable接口，该接口提供了比较元素的compareTo()方法，当插入元素时会回调该方法比较元素的大小。TreeMap要求存放的键值对映射的键必须实现Comparable接口从而根据键对元素进行排序。Collections工具类的sort方法有两种重载的形式，第一种要求传入的待排序容器中存放的对象比较实现Comparable接口以实现元素的比较；第二种不强制性的要求容器中的元素必须可比较，但是要求传入第二个参数，参数是Comparator接口的子类型（需要重写compare方法实现元素的比较），相当于一个临时定义的排序规则，其实就是通过接口注入比较元素大小的算法，也是对回调模式的应用（Java中对函数式编程的支持）。 

### 阐述ArrayList、Vector、LinkedList的存储性能和特性。 

ArrayList 和Vector都是使用数组方式存储数据，此数组元素数大于实际存储的数据以便增加和插入元素，它们都允许直接按序号索引元素，但是插入元素要涉及数组元素移动等内存操作，所以索引数据快而插入数据慢，Vector中的方法由于添加了synchronized修饰，因此Vector是线程安全的容器，但性能上较ArrayList差，因此已经是Java中的遗留容器。LinkedList使用双向链表实现存储（将内存中零散的内存单元通过附加的引用关联起来，形成一个可以按序号索引的线性结构，这种链式存储方式与数组的连续存储方式相比，内存的利用率更高），按序号索引数据需要进行前向或后向遍历，但是插入数据时只需要记录本项的前后项即可，所以插入速度较快。Vector属于遗留容器（Java早期的版本中提供的容器，除此之外，Hashtable、Dictionary、BitSet、Stack、Properties都是遗留容器），已经不推荐使用，但是由于ArrayList和LinkedListed都是非线程安全的，如果遇到多个线程操作同一个容器的场景，则可以通过工具类Collections中的synchronizedList方法将其转换成线程安全的容器后再使用（这是对装潢模式的应用，将已有对象传入另一个类的构造器中创建新的对象来增强实现）。

### HashMap具体如何实现的？

- HashMap底层是基于数组+链表实现的，通过添加键的hashcode与上数组的长度来得到这个元素在数组中的位置，如果这个位置没有数据，那么就把这个数据当做第一个节点。如果这个位置有了链表，那么在JDK1.7的时候使用的是头插法，在JDK1.8的时候使用尾插法。
- HashMap在JDK1.8的版本中引入了红黑树结构做优化，当链表元素个数大于等于8时，链表转换成树结构；链表元素个数小于等于6时，树结构还原成链表。
- Hashmap基于数组实现的，通过对key的hashcode & 数组的长度得到在数组中位置，如当前数组有元素，则数组当前元素next指向要插入的元素，这样来解决hash冲突的，形成了拉链式的结构。put时在多线程情况下，会形成环从而导致死循环。数组长度一般是2n，从0开始编号，所以hashcode & （2n-1），（2n-1）每一位都是1，这样会让散列均匀。需要注意的是，HashMap在JDK1.8的版本中引入了红黑树结构做优化，当链表元素个数大于等于8时，链表转换成树结构；若桶中链表元素个数小于等于6时，树结构还原成链表。因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4，这才有转换为树的必要。链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。假设一下，如果设计成链表个数超过8则链表转换成树结构，链表个数小于8则树结构转换成链表，如果一个HashMap不停的插入、删除元素，链表个数在8左右徘徊，就会频繁的发生树转链表、链表转树，效率会很低。

### JDK1.8的时候为什么选择8和6作为转换点？

- 因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8/2=4，显然树的效率更高一些。
- 链表长度如果是小于等于6，6/2=3，虽然速度也很快的，但是树和链表相互转换的时间也不会太短。还有选择6和8，中间有个差值7可以有效防止链表和树频繁转换。

### HashMap的扩容机制？

- HashMap底层是数组，在第一次put的时候会初始化，发生第一次扩容到16。它有一个负载因子是0.75，下一次扩容的时候就是当前数组大小*0.75。扩大容量为原来的2倍。

### concurrentmap为什么是线程安全的？

- ConcurrentHashMap大部分的逻辑代码和HashMap是一样的，主要通过synchronized和来保证节点在插入扩容的时候是线程安全的。
- ConcurrentHashMap的扩容核心逻辑主要是给不同的线程分配不同的数组下标，然后每个线程处理各自下表区间的节点。同时处理节点复用了hashMap的逻辑，通过位运行，可以知道节点扩容后的位置，要么在原位置，要么在原位置+oldlength位置,最后直接赋值即可。

### ConcurrentHashMap的原理？

ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment。HashEntry 用来封装映射表的键 / 值对；Segment 用来充当锁的角色，每个 Segment 对象守护整个散列映射表的若干个桶。每个桶是由若干个 HashEntry 对象链接起来的链表。一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组。HashEntry 用来封装散列映射表中的键值对。在 HashEntry 类中，key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型。

在ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。 由于只能在表头插入，所以链表中节点的顺序和插入的顺序相反。

Segment 类继承于 ReentrantLock 类，从而使得 Segment 对象能充当锁的角色。每个 Segment 对象用来守护其（成员对象 table 中）包含的若干个桶。

ConcurrentHashMap的数据结构是由一个Segment数组和多个HashEntry组成的。HashEntry封装的就是每一个键值对。每一个Segment元素存储的是HashEntry数组 + 链表。Segment数组的意义就是将一个大的table分割成多个小的table来进行加锁，Segment本身可以充当锁的角色。ConcurrentHashMap在put的时候需要进行两次hash，第一次需要确定在Segment数组的位置，第二次hash是确定在HashEntry数组中的位置。同样在get的时候也需要经过两次hash。

## 设计模式

### DCL为什么要用volatile关键字？

先看一下DCL(双重检查锁模式)的示例代码：

```java
public class Singleton {
  //Singleton对象属性,加上volatile关键字是为了防止指定重排序,要知道singleton = new Singleton()拆分成cpu指令的话，有足足3个步骤
  private volatile static Singleton singleton;

  //对外提供的获取实例的方法
  public static Singleton getInstance() {
    if (singleton == null) {
      synchronized (Singleton.class) {
        if (singleton == null) {
          singleton = new Singleton();
        }
      }
    }
    return singleton;
  }
}
```

从代码里可以看到，做了两重的singleton == null的判断，中间还用了synchronized关键字，第一个singleton == null的判断是为了避免线程串行化，如果为空，就进入synchronized代码块中，获取锁后再操作，如果不为空，直接就返回singleton对象了，无需再进行锁竞争和等待了。而第二个singleton == null的判断是为了防止有多个线程同时跳过第一个singleton == null的判断，比如线程一先获取到锁，进入同步代码块中，发现singleton实例还是null，就会做new操作，然后退出同步代码块并释放锁，这时一起跳过第一层singleton == null的判断的还有线程二，这时线程一释放了锁，线程二就会获取到锁，如果没有第二层的singleton == null这个判断挡着，那就会再创建一个singleton实例，就违反了单例的约束了。

那为什么要加volatile关键字呢

synchronized在一定程度上可以保证有序性博主说的是一方面还有就是在 进入synchronized代码块会先添加一个 acquire barrier 在最后添加一个release barrier 保证同步代码块中的代码不能和同步代码块外面的代码进行指令重排，在其内部还是会发生指令重排但基本不会影响结果

了解下singleton = new Singleton()这段代码其实不是原子性的操作，它至少分为以下3个步骤：

给singleton对象分配内存空间
调用Singleton类的构造函数等，初始化singleton对象
将singleton对象指向分配的内存空间，这步一旦执行了，那singleton对象就不等于null了
这里还需要知道一点，就是有时候JVM会为了优化，而做指令重排序的操作，这里的指令，指的是CPU层面的。

正常情况下，singleton = new Singleton()的步骤是按照1->2->3这种步骤进行的，但是一旦JVM做了指令重排序，那么顺序很可能编程1->3->2，如果是这种顺序，可以发现，在3步骤执行完singleton对象就不等于null，但是它其实还没做步骤二的初始化工作，但是另一个线程进来时发现，singleton不等于null了，就这样把半成品的实例返回去，调用是会报错的。

可以画个出现指令重排序的图加深下理解：

<img src="https://img-blog.csdnimg.cn/20200425180018774.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODEwNjMyMg==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:33%;" />

出现了指令重排序后，按照上图的流程逻辑，很可能会返回还没完成初始化的singleton对象，导致使用这个对象时报错，而volatile关键字的作用之一就是禁止指令重排序。

**总结**

DCL使用volatile关键字，是为了禁止指令重排序，避免返回还没完成初始化的singleton对象，导致调用报错，也保证了线程的安全。

## SSM

### Springmvc的执行流程


![img](https://upload-images.jianshu.io/upload_images/5220087-3c0f59d3c39a12dd.png?imageMogr2/auto-orient/strip|imageView2/2/w/1002)

2. 用户发送请求至前端控制器DispatcherServlet

2. DispatcherServlet收到请求调用处理器映射器HandlerMapping

3. 处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet

4. DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作

5. 执行处理器Handler(Controller，也叫页面控制器)

6. Handler执行完成返回ModelAndView

7. HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet

8. DispatcherServlet将ModelAndView传给ViewReslover视图解析器

9. ViewReslover解析后返回具体View

10. DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）

11. DispatcherServlet响应用户。

    

### SpringMVC的常用注解

- `@Component`： 会被spring容器识别，并转为bean。
- `@Repository`： 对Dao实现类进行注解。
- `@Service`： 对业务逻辑层进行注解。
- `@Controller`： 表明这个类是Spring MVC里的Controller，将其声明为Spring的一个Bean，Dispatch Servlet会自动扫描注解了此注解的类，并将Web请求映射到注解了@RequestMapping的方法上。
- `@RequestMapping`： 用来映射Web请求（访问路径和参数）、处理类和方法的。它可以注解在类和方法上。注解在方法上的@RequestMapping路径会继承注解在类上的路径。
- `@RequestBody`： 可以将整个返回结果以某种格式返回，如json或xml格式。
- `@PathVariable`： 用来接收路径参数，如/news/001,可接收001作为参数，此注解放置在参数前。
- `@RequestParam`：用于获取传入参数的值。
- `@RestController`：是一个组合注解，组合了@Controller和@ResponseBody，意味着当只开发一个和页面交互数据的控制的时候，需要使用此注解。

### Spring MVC怎么将数据存储到session中？

我一般都是使用Servlet-Api，在处理请求的方法参数列表中，添加一个HTTPSession对象，之后SpringMVC就可以自动注入进来了。在方法体中调用session.setAttribute就可以了。

### 过滤器和拦截器的区别？

1. 拦截器是基于java的反射机制的，而过滤器是基于函数回调。
2. 拦截器不依赖servlet容器，过滤器依赖servlet容器。
3. 拦截器只能对action请求起作用，而过滤器则可以对几乎所有的请求起作用。
4. 拦截器可以访问action上下文、值栈里的对象，而过滤器不能访问。
5. 在action的生命周期中，拦截器可以多次被调用，而过滤器只能在容器初始化时被调用一次。
6. 拦截器可以获取IOC容器中的各个bean，而过滤器就不行，这点很重要，在拦截器里注入一个service，可以调用业务逻辑。

### Spring拦截器的执行顺序

Springmvc的拦截器实现HandlerInterceptor接口后，会有三个抽象方法需要实现，分别为方法前执行preHandle，方法后postHandle，页面渲染后afterCompletion。

1. 当俩个拦截器都实现放行操作时，顺序为preHandle 1，preHandle 2，postHandle 2，postHandle 1，afterCompletion 2，afterCompletion 1
2. 当第一个拦截器preHandle返回false，也就是对其进行拦截时，第二个拦截器是完全不执行的，第一个拦截器只执行preHandle部分。
3. 当第一个拦截器preHandle返回true，第二个拦截器preHandle返回false，顺序为preHandle 1，preHandle 2 ，afterCompletion 1

总结：

```
preHandle 按拦截器定义顺序调用
postHandler 按拦截器定义逆序调用
afterCompletion 按拦截器定义逆序调用
postHandler 在拦截器链内所有拦截器返成功调用
afterCompletion 只有preHandle返回true才调用
```

### Spring 核心功能

- spring 框架中核心组件有三个：Core、Context 和 Beans。其中最核心的组件就是Beans, Spring提供的最核心的功能就是Bean Factory。
- Spring 解决了的最核心的问题就是把对象之间的依赖关系转为用配置文件来管理，也就是Spring的依赖注入机制。这个注入机制是在Ioc 容器中进行管理的。

### @Autowired 和@Resource区别是什么？

- 共同点：两者都可以写在字段和setter方法上。两者如果都写在字段上，那么就不需要再写setter方法。
- @Autowired注解是按照类型（byType）装配依赖对象。当有且仅有一个匹配的Bean时，Spring将其注入@Autowired标注的变量中。如果我们想使用按照名称（byName）来装配，可以结合@Qualifier注解一起使用。
- @Resource默认按照ByName自动注入。@Resource有两个重要的属性：name和type，而Spring将@Resource注解的name属性解析为bean的名字，而type属性则解析为bean的类型。所以，如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不制定name也不制定type属性，这时将通过反射机制使用byName自动注入策略。

### SpringBootApplication是怎么加载的？

### SpringBoot配置多套环境

可以定义多个配置文件，比如开发，测试，上线。 我们可以在SpringBoot中定义多个application.properties。 我一般都用-名字做区别，比如：

```
application-dev.properties
application-test.properties
application-prod.properties
```

之后我们需要在默认的配置文件里面声明一下激活哪些配置文件。

```
spring.profiles.active=test
```

使用java -jar 方式启动的时候也可以添加参数指定配置文件启动

```
java -jar mm.jar --spring.profiles.active=dev
```

### SpringBoot的启动方式

1. 运行带有main方法类。
3. 通过spring-boot-plugin的方式，这种方式需要安装Maven的插件，然后通过命令`mvn spring-boot:run`启动项目。
3. 前台启动命令：`java -jar XXX.jar`
4. 后台启动命令：`java -jar xxx.jar &`，后台启动同时也可以制定控制台的输出标准，将日志输出到制定文件
5. 使用Docker的方式启动SpringBoot应用，需要将jar制作成docker镜像。

### MyBatis核心类

### Mybatis中dao层和xml配置怎么建立关系的

### Mybatis常用标签

### `#{ }` 和`${ }`的区别？

- `#{}`：这种方式是使用的预编译的方式，一个#{}就是一个占位符。相当于jdbc的占位符PrepareStatement。设置值的时候会加上引号。
- `${}`：这种方式是直接拼接的方式，不对数值做预编译。存在sql注入的现象。设置值的时候不会加上引号。

### MyBatis的二级缓存

- MyBatis一级缓存最大的共享范围就是一个SqlSession内部，那么如果多个SqlSession需要共享缓存，则需要开启二级缓存，开启二级缓存后，会使用CachingExecutor装饰Executor进入一级缓存的查询流程前，先在CachingExecutor进行二级缓存的查询。
- 当二级缓存开启后，同一个命名空间(namespace) 所有的操作语句，都影响着一个共同的 cache，也就是二级缓存被多个 SqlSession 共享，是一个全局的变量。当开启缓存后，数据的查询执行的流程就是 二级缓存 -> 一级缓存 -> 数据库。默认二级缓存不开启，需要在MyBatis的全局配置文件中进行配置。
- mybatis中一级缓存是默认开启的，二级缓存默认是不开启的，一级缓存是对于一个sqlSeesion而言，而二级缓存是对于一个nameSpace而言，可以多个SqlSession共享。

###  请问Spring中Bean的作用域有哪些？

在Spring的早期版本中，仅有两个作用域：singleton和prototype，前者表示Bean以单例的方式存在；后者表示每次从容器中调用Bean时，都会返回一个新的实例，prototype通常翻译为原型。 

设计模式中的创建型模式中也有一个原型模式，原型模式也是一个常用的模式，例如做一个室内设计软件，所有的素材都在工具箱中，而每次从工具箱中取出的都是素材对象的一个原型，可以通过对象克隆来实现原型模式。Spring 2.x中针对WebApplicationContext新增了3个作用域，分别是：request（每次HTTP请求都会创建一个新的Bean）、session（同一个HttpSession共享同一个Bean，不同的HttpSession使用不同的Bean）和globalSession（同一个全局Session共享一个Bean）。 

单例模式和原型模式都是重要的设计模式。一般情况下，无状态或状态不可变的类适合使用单例模式。在传统开发中，由于DAO持有Connection这个非线程安全对象因而没有使用单例模式；但在Spring环境下，所有DAO类对可以采用单例模式，因为Spring利用AOP和Java API中的ThreadLocal对非线程安全的对象进行了特殊处理。

### 请问什么是IoC和DI？并且简要说明一下DI是如何实现的？

IoC叫控制反转，是Inversion of Control的缩写，DI（Dependency Injection）叫依赖注入，是对IoC更简单的诠释。控制反转是把传统上由程序代码直接操控的对象的调用权交给容器，通过容器来实现对象组件的装配和管理。所谓的"控制反转"就是对组件对象控制权的转移，从程序代码本身转移到了外部容器，由容器来创建对象并管理对象之间的依赖关系。IoC体现了好莱坞原则 - "Don’t call me, we will call you"。依赖注入的基本原则是应用组件不应该负责查找资源或者其他依赖的协作对象。配置对象的工作应该由容器负责，查找资源的逻辑应该从应用组件的代码中抽取出来，交给容器来完成。DI是对IoC更准确的描述，即组件之间的依赖关系由容器在运行期决定，形象的来说，即由容器动态的将某种依赖关系注入到组件之中。 

一个类A需要用到接口B中的方法，那么就需要为类A和接口B建立关联或依赖关系，最原始的方法是在类A中创建一个接口B的实现类C的实例，但这种方法需要开发人员自行维护二者的依赖关系，也就是说当依赖关系发生变动的时候需要修改代码并重新构建整个系统。如果通过一个容器来管理这些对象以及对象的依赖关系，则只需要在类A中定义好用于关联接口B的方法（构造器或setter方法），将类A和接口B的实现类C放入容器中，通过对容器的配置来实现二者的关联。
依赖注入可以通过setter方法注入（设值注入）、构造器注入和接口注入三种方式来实现，Spring支持setter注入和构造器注入，通常使用构造器注入来注入必须的依赖关系，对于可选的依赖关系，则setter注入是更好的选择，setter注入需要类提供无参构造器或者无参的静态工厂方法来创建对象。 

### 请说明一下Spring中BeanFactory和ApplicationContext的区别是什么？

- BeanFactory： BeanFactory是spring中比较原始，比较古老的Factory。因为比较古老，所以BeanFactory无法支持spring插件，例如：AOP、Web应用等功能。 
- ApplicationContext ApplicationContext是BeanFactory的子类，因为古老的BeanFactory无法满足不断更新的spring的需求，于是ApplicationContext就基本上代替了BeanFactory的工作，以一种更面向框架的工作方式以及对上下文进行分层和实现继承，并在这个基础上对功能进行扩展：
  1. MessageSource, 提供国际化的消息访问 
  2. 资源访问（如URL和文件） 
  3. 事件传递 
  4. Bean的自动装配 
  5. 各种不同应用层的Context实现 

- 区别： 
- 如果使用ApplicationContext，如果配置的bean是singleton，那么不管你有没有或想不想用它，它都会被实例化。好处是可以预先加载，坏处是浪费内存。 
- BeanFactory，当使用BeanFactory实例化对象时，配置的bean不会马上被实例化，而是等到你使用该bean的时候（getBean）才会被实例化。好处是节约内存，坏处是速度比较慢。多用于移动设备的开发。 
- 没有特殊要求的情况下，应该使用ApplicationContext完成。因为BeanFactory能完成的事情，ApplicationContext都能完成，并且提供了更多接近现在开发的功能。 

### 请介绍一下bean的生命周期

Spring生命周期流程图： 

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-21-308572_1537967995043_4D7CF33471A392D943F00167D1C86C10.png)

### 请问AOP的原理是什么？

- AOP（Aspect Orient Programming），指面向方面（切面）编程，作为面向对象的一种补充，用于处理系统中分布于各个模块的横切关注点，比如事务管理、日志、缓存等等。AOP实现的关键在于AOP框架自动创建的AOP代理，AOP代理主要分为静态代理和动态代理，静态代理的代表为AspectJ；而动态代理则以Spring AOP为代表。通常使用AspectJ的编译时增强实现AOP，AspectJ是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强。 
- Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理。JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。 
- 如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意，CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。

### 请简要说明一下IOC和AOP是什么？

- 依赖注入的三种方式：
  - 接口注入
  - Construct注入
  - Setter注入
- 控制反转与依赖注入是同一个概念，引入IOC的目的：
  - 脱开、降低类之间的耦合
  - 倡导面向接口编程、实施依赖倒换原则
  - 提高系统可插入、可测试、可修改等特性。
- 具体做法：
  - 将bean之间的依赖关系尽可能地抓换为关联关系
  - 将对具体类的关联尽可能地转换为对Java interface的关联，而不是与具体的服务对象相关联
  - Bean实例具体关联相关Java interface的哪个实现类的实例，在配置信息的元数据中描述
  - 由IoC组件（或称容器）根据配置信息，实例化具体bean类、将bean之间的依赖关系注入进来。
- AOP是面向切面编程，可以说是面向对象编程的补充和完善。OOP引入封装、继承、多态等概念来建立一种对象层次结构，但是这些都是纵向的关系，但并不适合定义横向的关系，例如日志功能。日志代码往往横向地散布在所有对象层次中，但是这与核心的业务代码确没有关系。
- AOP利用"横切"的技术，把那些与业务无关，但是却为业务模块所共同调用的逻辑部分封装起来，便于减少系统的重复代码，降低模块之间的耦合度，并提高了系统的维护性。
- AOP把软件系统分为两个部分：核心关注点和横切关注点。业务处理的主要流程是核心关注点，与之关系不大的部分是横切关注点。横切关注点的一个特点是，他们经常发生在核心关注点的多处，而各处基本相似，比如日志还有事物。AOP的作用在于分离系统中的各种关注点，将核心关注点和横切关注点分离开来。

### 请说明一下springIOC原理是什么？如果你要实现IOC需要怎么做？请简单描述一下实现步骤？

- IoC（Inversion of Control，控制倒转）。这是spring的核心，贯穿始终。所谓IoC，对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。 
- IoC的一个重点是在系统运行中，动态的向某个对象提供它所需要的其他对象。这一点是通过DI（Dependency Injection，依赖注入）来实现的。比如对象A需要操作数据库，以前我们总是要在A中自己编写代码来获得一个Connection对象，有了 spring我们就只需要告诉spring，A中需要一个Connection，至于这个Connection怎么构造，何时构造，A不需要知道。在系统运行时，spring会在适当的时候制造一个Connection，然后像打针一样，注射到A当中，这样就完成了对各个对象之间关系的控制。A需要依赖 Connection才能正常运行，而这个Connection是由spring注入到A中的，依赖注入的名字就这么来的。那么DI是如何实现的呢？ Java 1.3之后一个重要特征是反射（reflection），它允许程序在运行的时候动态的生成对象、执行对象的方法、改变对象的属性，spring就是通过反射来实现注入的。 
- 实现IOC的步骤 
  - 定义用来描述bean的配置的Java类 
  - 解析bean的配置，將bean的配置信息转换为上面的BeanDefinition对象保存在内存中，spring中采用HashMap进行对象存储，其中会用到一些xml解析技术 
  - 遍历存放BeanDefinition的HashMap对象，逐条取出BeanDefinition对象，获取bean的配置信息，利用Java的反射机制实例化对象，將实例化后的对象保存在另外一个Map中即可。

### Spring ApplicationContext 容器

*Application Context* 是 spring 中较高级的容器。和 BeanFactory 类似，它可以加载配置文件中定义的 bean，将所有的 bean 集中在一起，当有请求的时候分配 bean。 另外，它增加了企业所需要的功能，比如，从属性文件从解析文本信息和将事件传递给所指定的监听器。这个容器在 `org.springframework.context.ApplicationContext interface` 接口中定义。

*ApplicationContext* 包含 *BeanFactory* 所有的功能，一般情况下，相对于 *BeanFactory*，*ApplicationContext* 会被推荐使用。*BeanFactory* 仍然可以在轻量级应用中使用，比如移动设备或者基于 applet 的应用程序。

最常被使用的 ApplicationContext 接口实现：

- **FileSystemXmlApplicationContext**：该容器从 XML 文件中加载已被定义的 bean。在这里，你需要提供给构造器 XML 文件的完整路径
- **ClassPathXmlApplicationContext**：该容器从 XML 文件中加载已被定义的 bean。在这里，你不需要提供 XML 文件的完整路径，只需正确配置 CLASSPATH 环境变量即可，因为，容器会从 CLASSPATH 中搜索 bean 配置文件。
- **WebXmlApplicationContext**：该容器会在一个 web 应用程序的范围内加载在 XML 文件中已被定义的 bean。

我们已经在 *Spring Hello World Example*章节中看到过 ClassPathXmlApplicationContext 容器，并且，在基于 spring 的 web 应用程序这个独立的章节中，我们讨论了很多关于 XmlWebApplicationContext。所以，接下来，让我们看一个关于 FileSystemXmlApplicationContext 的例子。

假设我们已经安装 Eclipse IDE，按照下面的步骤，我们可以创建一个 Spring 应用程序。

| 步骤 | 描述                                                         |
| :--- | :----------------------------------------------------------- |
| 1    | 创建一个名为 *SpringExample* 的工程， 在 **src** 下新建一个名为 *com.tutorialspoint* 的文件夹**src** |
| 2    | 点击右键，选择 *Add External JARs* 选项，导入 Spring 的库文件，正如我们在 *Spring Hello World Example* 章节中提到的导入方式。 |
| 3    | 在 *com.tutorialspoint* 文件夹下创建 *HelloWorld.java* 和 *MainApp.java* 两个类文件。 |
| 4    | 文件夹下创建 Bean 的配置文件 *Beans.xml*。                   |
| 5    | 最后的步骤是编辑所有 JAVA 文件的内容和 Bean 的配置文件,按照以前我们讲的那样去运行应用程序。 |

下面是文件 **HelloWorld.java** 的内容：

```java
package com.tutorialspoint;
public class HelloWorld {
   private String message;
   public void setMessage(String message){
      this.message  = message;
   }
   public void getMessage(){
      System.out.println("Your Message : " + message);
   }
}
```

下面是文件 **MainApp.java** 的内容：

```java
package com.tutorialspoint;
import org.springframework.context.ApplicationContext;
import org.springframework.context.support.FileSystemXmlApplicationContext;
public class MainApp {
   public static void main(String[] args) {
      ApplicationContext context = new FileSystemXmlApplicationContext
            ("C:/Users/ZARA/workspace/HelloSpring/src/Beans.xml");
      HelloWorld obj = (HelloWorld) context.getBean("helloWorld");
      obj.getMessage();
   }
}
```

在主程序当中，我们需要注意以下两点：

- 第一步生成工厂对象。加载完指定路径下 bean 配置文件后，利用框架提供的 **FileSystemXmlApplicationContext** API 去生成工厂 bean。**FileSystemXmlApplicationContext**负责生成和初始化所有的对象，比如，所有在 XML bean 配置文件中的 bean。
- 第二步利用第一步生成的上下文中的 **getBean()** 方法得到所需要的 bean。 这个方法通过配置文件中的 bean ID 来返回一个真正的对象。一旦得到这个对象，就可以利用这个对象来调用任何方法。
- 下面是配置文件 **Beans.xml** 中的内容：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="http://www.springframework.org/schema/beans
                           http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">

  <bean id="helloWorld" class="com.tutorialspoint.HelloWorld">
    <property name="message" value="Hello World!"/>
  </bean>

</beans>
```

如果你已经完成上面的内容，接下来，让我们运行这个应用程序。如果程序没有错误，你将从控制台看到以下信息：

```
Your Message : Hello World!
```

### Spring Security 原理

**过滤器**

- Spring Security 基本都是通过过滤器来完成配置的身份认证、权限认证以及登出。
- Spring Security 在 Servlet 的过滤链（filter chain）中注册了一个过滤器 `FilterChainProxy`，它会把请求代理到 Spring Security 自己维护的多个过滤链，每个过滤链会匹配一些 URL，如果匹配则执行对应的过滤器。过滤链是有顺序的，一个请求只会执行第一条匹配的过滤链。Spring Security 的配置本质上就是新增、删除、修改过滤器。
- 默认情况下系统帮我们注入的这 15 个过滤器，分别对应配置不同的需求。接下来我们重点是分析下 `UsernamePasswordAuthenticationFilter` 这个过滤器，他是用来使用用户名和密码登录认证的过滤器，但是很多情况下我们的登录不止是简单的用户名和密码，又可能是用到第三方授权登录，这个时候我们就需要使用自定义过滤器，当然这里不做详细说明，只是说下自定义过滤器怎么注入。

```java
@Override
protected void configure(HttpSecurity http) throws Exception {

  http.addFilterAfter(...);
  ...
}
```

**身份认证流程**

在开始身份认证流程之前我们需要了解下几个基本概念

**SecurityContextHolder**

`SecurityContextHolder` 存储 `SecurityContext` 对象。`SecurityContextHolder` 是一个存储代理，有三种存储模式分别是：

- MODE_THREADLOCAL：SecurityContext 存储在线程中。
- MODE_INHERITABLETHREADLOCAL：`SecurityContext` 存储在线程中，但子线程可以获取到父线程中的 `SecurityContext`。
- MODE_GLOBAL：`SecurityContext` 在所有线程中都相同。

`SecurityContextHolder` 默认使用 MODE_THREADLOCAL 模式，`SecurityContext` 存储在当前线程中。调用 `SecurityContextHolder` 时不需要显示的参数传递，在当前线程中可以直接获取到 `SecurityContextHolder` 对象。

```java
//获取当前线程里面认证的对象
SecurityContext context = SecurityContextHolder.getContext();
Authentication authentication = context.getAuthentication();

//保存认证对象 (一般用于自定义认证成功保存认证对象)
SecurityContextHolder.getContext().setAuthentication(authResult);

//清空认证对象 (一般用于自定义登出清空认证对象)
SecurityContextHolder.clearContext();
```

**2.Authentication**

`Authentication` 即验证，表明当前用户是谁。什么是验证，比如一组用户名和密码就是验证，当然错误的用户名和密码也是验证，只不过 Spring Security 会校验失败。

`Authentication` 接口

```java
public interface Authentication extends Principal, Serializable {
  //获取用户权限，一般情况下获取到的是用户的角色信息
  Collection<? extends GrantedAuthority> getAuthorities();
  //获取证明用户认证的信息，通常情况下获取到的是密码等信息，不过登录成功就会被移除
  Object getCredentials();
  //获取用户的额外信息，比如 IP 地址、经纬度等
  Object getDetails();
  //获取用户身份信息，在未认证的情况下获取到的是用户名，在已认证的情况下获取到的是 UserDetails (暂时理解为，当前应用用户对象的扩展)
  Object getPrincipal();
  //获取当前 Authentication 是否已认证
  boolean isAuthenticated();
  //设置当前 Authentication 是否已认证
  void setAuthenticated(boolean isAuthenticated);
}
```

**3.AuthenticationManager ProviderManager AuthenticationProvider**

其实这三者很好区分，`AuthenticationManager` 主要就是为了完成身份认证流程，`ProviderManager`是 `AuthenticationManager` 接口的具体实现类，`ProviderManager` 里面有个记录 `AuthenticationProvider` 对象的集合属性 `providers`，`AuthenticationProvider` 接口类里有两个方法

```java
public interface AuthenticationProvider {
  //实现具体的身份认证逻辑，认证失败抛出对应的异常
  Authentication authenticate(Authentication authentication)
    throws AuthenticationException;
  //该认证类是否支持该 Authentication 的认证
  boolean supports(Class<?> authentication);
}
```

接下来就是遍历 `ProviderManager` 里面的 `providers` 集合，找到和合适的 `AuthenticationProvider`完成身份认证。

**4.UserDetailsService UserDetails**

在 `UserDetailsService` 接口中只有一个简单的方法

```java
public interface UserDetailsService {
  //根据用户名查到对应的 UserDetails 对象
  UserDetails loadUserByUsername(String username) throws UsernameNotFoundException;
}
```

**5.流程**

对于上面概念有什么不明白的地方，在们在接下来的流程中慢慢分析

在运行到 `UsernamePasswordAuthenticationFilter` 过滤器的时候首先是进入其父类 `AbstractAuthenticationProcessingFilter` 的 `doFilter()` 方法中

```java
public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)
  throws IOException, ServletException {
  ...
    //首先配对是不是配置的身份认证的URI,是则执行下面的认证,不是则跳过
    if (!requiresAuthentication(request, response)) {
      chain.doFilter(request, response);

      return;
    }
  ...
    Authentication authResult;

  try {
    //关键方法, 实现认证逻辑并返回 Authentication, 由其子类 UsernamePasswordAuthenticationFilter 实现, 由下面 5.3 详解
    authResult = attemptAuthentication(request, response);
    if (authResult == null) {
      // return immediately as subclass has indicated that it hasn't completed
      // authentication
      return;
    }
    sessionStrategy.onAuthentication(authResult, request, response);
  }
  catch (InternalAuthenticationServiceException failed) {
    //认证失败调用...由下面 5.1 详解
    unsuccessfulAuthentication(request, response, failed);

    return;
  }
  catch (AuthenticationException failed) {
    //认证失败调用...由下面 5.1 详解
    unsuccessfulAuthentication(request, response, failed);

    return;
  }

  // Authentication success
  if (continueChainBeforeSuccessfulAuthentication) {
    chain.doFilter(request, response);
  }
  //认证成功调用...由下面 5.2 详解
  successfulAuthentication(request, response, chain, authResult);
}
```

**5.1 认证失败处理逻辑**

```java
protected void unsuccessfulAuthentication(HttpServletRequest request,
                                          HttpServletResponse response, AuthenticationException failed)
  throws IOException, ServletException {
  SecurityContextHolder.clearContext();
  ...
    rememberMeServices.loginFail(request, response);
  //该 handler 处理失败界面跳转和响应逻辑
  failureHandler.onAuthenticationFailure(request, response, failed);
}
```

这里默认配置的失败处理 handler 是 `SimpleUrlAuthenticationFailureHandler`，**可自定义**。

```java
public class SimpleUrlAuthenticationFailureHandler implements
        AuthenticationFailureHandler {
    ...

    public void onAuthenticationFailure(HttpServletRequest request,
            HttpServletResponse response, AuthenticationException exception)
            throws IOException, ServletException {
        //没有配置失败跳转的URL则直接响应错误
        if (defaultFailureUrl == null) {
            logger.debug("No failure URL set, sending 401 Unauthorized error");

            response.sendError(HttpStatus.UNAUTHORIZED.value(),
                HttpStatus.UNAUTHORIZED.getReasonPhrase());
        }
        else {
            //否则
            //缓存异常
            saveException(request, exception);
            //根据配置的异常页面是重定向还是转发进行不同方式跳转
            if (forwardToDestination) {
                logger.debug("Forwarding to " + defaultFailureUrl);

                request.getRequestDispatcher(defaultFailureUrl)
                        .forward(request, response);
            }
            else {
                logger.debug("Redirecting to " + defaultFailureUrl);
                redirectStrategy.sendRedirect(request, response, defaultFailureUrl);
            }
        }
    }
    //缓存异常,转发则保存在request里面,重定向则保存在session里面
    protected final void saveException(HttpServletRequest request,
            AuthenticationException exception) {
        if (forwardToDestination) {
            request.setAttribute(WebAttributes.AUTHENTICATION_EXCEPTION, exception);
        }
        else {
            HttpSession session = request.getSession(false);

            if (session != null || allowSessionCreation) {
                request.getSession().setAttribute(WebAttributes.AUTHENTICATION_EXCEPTION,
                        exception);
            }
        }
    }
}
```

**这里做下小拓展：用系统的错误处理handler，指定认证失败跳转的URL，在MVC里面对应的URL方法里面可以通过key从`request`或`session`里面拿到错误信息，反馈给前端**

**5.2 认证成功处理逻辑**

```java
protected void successfulAuthentication(HttpServletRequest request,
                                        HttpServletResponse response, FilterChain chain, Authentication authResult)
  throws IOException, ServletException {
  ...
    //这里要注意很重要，将认证完成返回的 Authentication 保存到线程对应的 `SecurityContext` 中
    SecurityContextHolder.getContext().setAuthentication(authResult);

  rememberMeServices.loginSuccess(request, response, authResult);

  // Fire event
  if (this.eventPublisher != null) {
    eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent(
      authResult, this.getClass()));
  }
  //该 handler 就是为了完成页面跳转
  successHandler.onAuthenticationSuccess(request, response, authResult);
}
```

这里默认配置的成功处理 handler 是 `SavedRequestAwareAuthenticationSuccessHandler`，里面的代码就不做具体展开了，反正是跳转到指定的认证成功之后的界面，**可自定义**。

**5.3 身份认证详情**

```java
public class UsernamePasswordAuthenticationFilter extends
  AbstractAuthenticationProcessingFilter {
  ...
    public static final String SPRING_SECURITY_FORM_USERNAME_KEY = "username";
  public static final String SPRING_SECURITY_FORM_PASSWORD_KEY = "password";

  private String usernameParameter = SPRING_SECURITY_FORM_USERNAME_KEY;
  private String passwordParameter = SPRING_SECURITY_FORM_PASSWORD_KEY;
  private boolean postOnly = true;

  ...
    //开始身份认证逻辑
    public Authentication attemptAuthentication(HttpServletRequest request,
                                                HttpServletResponse response) throws AuthenticationException {
    if (postOnly && !request.getMethod().equals("POST")) {
      throw new AuthenticationServiceException(
        "Authentication method not supported: " + request.getMethod());
    }

    String username = obtainUsername(request);
    String password = obtainPassword(request);

    if (username == null) {
      username = "";
    }

    if (password == null) {
      password = "";
    }

    username = username.trim();
    //先用前端提交过来的 username 和 password 封装一个简易的 AuthenticationToken
    UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(
      username, password);

    // Allow subclasses to set the "details" property
    setDetails(request, authRequest);
    //具体的认证逻辑还是交给 AuthenticationManager 对象的 authenticate(..) 方法完成,接着往下看
    return this.getAuthenticationManager().authenticate(authRequest);
  }
}
```

由源码断点跟踪得知，最终解析是由 `AuthenticationManager` 接口实现类 `ProviderManager` 来完成

```java
public class ProviderManager implements AuthenticationManager, MessageSourceAware,
InitializingBean {
  ...
    private List<AuthenticationProvider> providers = Collections.emptyList();
  ...

    public Authentication authenticate(Authentication authentication)
    throws AuthenticationException {
    ....
      //遍历所有的 AuthenticationProvider, 找到合适的完成身份验证
      for (AuthenticationProvider provider : getProviders()) {
        if (!provider.supports(toTest)) {
          continue;
        }
        ...
          try {
            //进行具体的身份验证逻辑, 这里使用到的是 DaoAuthenticationProvider, 具体逻辑记着往下看
            result = provider.authenticate(authentication);

            if (result != null) {
              copyDetails(authentication, result);
              break;
            }
          }
        catch 
          ...
      }
    ...
      throw lastException;
  }
}
```

`DaoAuthenticationProvider` 继承自 `AbstractUserDetailsAuthenticationProvider` 实现了 `AuthenticationProvider` 接口

```java
public abstract class AbstractUserDetailsAuthenticationProvider implements
  AuthenticationProvider, InitializingBean, MessageSourceAware {
  ...
    private UserDetailsChecker preAuthenticationChecks = new DefaultPreAuthenticationChecks();
  private UserDetailsChecker postAuthenticationChecks = new DefaultPostAuthenticationChecks();
  ...

    public Authentication authenticate(Authentication authentication)
    throws AuthenticationException {
    ...
      // 获得提交过来的用户名
      String username = (authentication.getPrincipal() == null) ? "NONE_PROVIDED"
      : authentication.getName();
    //根据用户名从缓存中查找 UserDetails
    boolean cacheWasUsed = true;
    UserDetails user = this.userCache.getUserFromCache(username);

    if (user == null) {
      cacheWasUsed = false;

      try {
        //缓存中没有则通过 retrieveUser(..) 方法查找 (看下面 DaoAuthenticationProvider 的实现)
        user = retrieveUser(username,
                            (UsernamePasswordAuthenticationToken) authentication);
      }
      catch 
        ...
    }

    try {
      //比对前的检查,例如账户以一些状态信息(是否锁定, 过期...)
      preAuthenticationChecks.check(user);
      //子类实现比对规则 (看下面 DaoAuthenticationProvider 的实现)
      additionalAuthenticationChecks(user,
                                     (UsernamePasswordAuthenticationToken) authentication);
    }
    catch (AuthenticationException exception) {
      if (cacheWasUsed) {
        // There was a problem, so try again after checking
        // we're using latest data (i.e. not from the cache)
        cacheWasUsed = false;
        user = retrieveUser(username,
                            (UsernamePasswordAuthenticationToken) authentication);
        preAuthenticationChecks.check(user);
        additionalAuthenticationChecks(user,
                                       (UsernamePasswordAuthenticationToken) authentication);
      }
      else {
        throw exception;
      }
    }

    postAuthenticationChecks.check(user);

    if (!cacheWasUsed) {
      this.userCache.putUserInCache(user);
    }

    Object principalToReturn = user;

    if (forcePrincipalAsString) {
      principalToReturn = user.getUsername();
    }
    //根据最终user的一些信息重新生成具体详细的 Authentication 对象并返回 
    return createSuccessAuthentication(principalToReturn, authentication, user);
  }
  //具体生成还是看子类实现
  protected Authentication createSuccessAuthentication(Object principal,
                                                       Authentication authentication, UserDetails user) {
    // Ensure we return the original credentials the user supplied,
    // so subsequent attempts are successful even with encoded passwords.
    // Also ensure we return the original getDetails(), so that future
    // authentication events after cache expiry contain the details
    UsernamePasswordAuthenticationToken result = new UsernamePasswordAuthenticationToken(
      principal, authentication.getCredentials(),
      authoritiesMapper.mapAuthorities(user.getAuthorities()));
    result.setDetails(authentication.getDetails());

    return result;
  }
}
```

接下来我们来看下 `DaoAuthenticationProvider` 里面的三个重要的方法，比对方式、获取需要比对的 `UserDetails` 对象以及生产最终返回 `Authentication` 的方法。

```java
public class DaoAuthenticationProvider extends AbstractUserDetailsAuthenticationProvider {
  ...
    //密码比对
    @SuppressWarnings("deprecation")
    protected void additionalAuthenticationChecks(UserDetails userDetails,
                                                  UsernamePasswordAuthenticationToken authentication)
    throws AuthenticationException {
    if (authentication.getCredentials() == null) {
      logger.debug("Authentication failed: no credentials provided");

      throw new BadCredentialsException(messages.getMessage(
        "AbstractUserDetailsAuthenticationProvider.badCredentials",
        "Bad credentials"));
    }

    String presentedPassword = authentication.getCredentials().toString();
    //通过 PasswordEncoder 进行密码比对, 注: 可自定义
    if (!passwordEncoder.matches(presentedPassword, userDetails.getPassword())) {
      logger.debug("Authentication failed: password does not match stored value");

      throw new BadCredentialsException(messages.getMessage(
        "AbstractUserDetailsAuthenticationProvider.badCredentials",
        "Bad credentials"));
    }
  }

  //通过 UserDetailsService 获取 UserDetails
  protected final UserDetails retrieveUser(String username,
                                           UsernamePasswordAuthenticationToken authentication)
    throws AuthenticationException {
    prepareTimingAttackProtection();
    try {
      //通过 UserDetailsService 获取 UserDetails
      UserDetails loadedUser = this.getUserDetailsService().loadUserByUsername(username);
      if (loadedUser == null) {
        throw new InternalAuthenticationServiceException(
          "UserDetailsService returned null, which is an interface contract violation");
      }
      return loadedUser;
    }
    catch (UsernameNotFoundException ex) {
      mitigateAgainstTimingAttack(authentication);
      throw ex;
    }
    catch (InternalAuthenticationServiceException ex) {
      throw ex;
    }
    catch (Exception ex) {
      throw new InternalAuthenticationServiceException(ex.getMessage(), ex);
    }
  }

  //生成身份认证通过后最终返回的 Authentication, 记录认证的身份信息
  @Override
  protected Authentication createSuccessAuthentication(Object principal,
                                                       Authentication authentication, UserDetails user) {
    boolean upgradeEncoding = this.userDetailsPasswordService != null
      && this.passwordEncoder.upgradeEncoding(user.getPassword());
    if (upgradeEncoding) {
      String presentedPassword = authentication.getCredentials().toString();
      String newPassword = this.passwordEncoder.encode(presentedPassword);
      user = this.userDetailsPasswordService.updatePassword(user, newPassword);
    }
    return super.createSuccessAuthentication(principal, authentication, user);
  }
}
```

## MySQL

### Mysql的存储引擎

- MySQL 支持多种类型的数据库引擎，可分别根据各个引擎的功能和特性为不同的数据库处理任务提供各自不同的适应性和灵活性。在 MySQL 中，可以利用 SHOW ENGINES 语句来显示可用的数据库引擎和默认引擎。
- MySQL 提供了多个不同的存储引擎，包括处理事务安全表的引擎和处理非事务安全表的引擎。在 MySQL 中，不需要在整个服务器中使用同一种存储引擎，针对具体的要求，可以对每一个表使用不同的存储引擎。
- MySQL 5.7 支持的存储引擎有 InnoDB、MyISAM、Memory、Merge、Archive、Federated、CSV、BLACKHOLE 等。

### B 树

- 关键字分布在整棵树的所有节点。
- 任何一个关键字 **出现且只出现在一个节点中**。
- 搜索有可能在 **非叶子节点** 结束。
- 其搜索性能等价于在关键字全集内做一次二分查找。如下图所示：

###  B+树

**B+树基本特点**

- 有n棵子树的非叶子结点中含有n个关键字（b树是n-1个），这些关键字不保存数据，只用来索引，所有数据都保存在叶子节点（b树是每个关键字都保存数据）。
- 所有的非叶子结点可以看成是索引部分，结点中仅含其子树中的最大（或最小）关键字。
- 非叶子节点的子树指针 P[i]，指向关键字属于 **[k[i],K[i+1])** 的子树（**注意：区间是前闭后开**)。
- 所有的叶子结点中包含了全部关键字的信息，及指向含这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。
- **所有关键字都在叶子节点出现**。

**B+树的特性**

- 所有的关键字 **都出现在叶子节点的链表中**，且链表中的关键字是有序的。
- **搜索只在叶子节点命中**。
- 非叶子节点相当于是 **叶子节点的索引层**，叶子节点是 **存储关键字数据的数据层**。

**相对 B 树，B+树做索引的优势**

- B+树的中间节点不保存数据，所以磁盘页能容纳更多节点元素，更“矮胖”；
- **树的查询效率更加稳定**。B+树所有数据都存在于叶子节点，所有关键字查询的路径长度相同，每次数据的查询效率相当。而 B 树可能在非叶子节点就停止查找了，所以查询效率不够稳定。
- **B+树只需要去遍历叶子节点就可以实现整棵树的遍历**。

### druid连接池

1. 强大的监控特性，通过Druid提供的监控功能，可以清楚知道连接池和SQL的工作情况。
   1.  监控SQL的执行时间、ResultSet持有时间、返回行数、更新行数、错误次数、错误堆栈信息;
   2.  SQL执行的耗时区间分布。什么是耗时区间分布呢？比如说，某个SQL执行了1000次，其中`0~1`毫秒区间50次，`1~10`毫秒800次，`10~100`毫秒100次，`100~1000`毫秒30次，`1~10`秒15次，10秒以上5次。通过耗时区间分布，能够非常清楚知道SQL的执行耗时情况
   3.  监控连接池的物理连接创建和销毁次数、逻辑连接的申请和关闭次数、非空等待次数、PSCache命中率等。
2. 其次，方便扩展。Druid提供了Filter-Chain模式的扩展API，可以自己编写Filter拦截JDBC中的任何方法，可以在上面做任何事情，比如说性能监控、SQL审计、用户名密码加密、日志等等。
3. Druid集合了开源和商业数据库连接池的优秀特性，并结合阿里巴巴大规模苛刻生产环境的使用经验进行优化

```yaml
spring:
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driverClassName: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://${url}:${port}/${数据库名}?useUnicode=true&characterEncoding=utf8&autoReconnect=true&useSSL=false&allowMultiQueries=true&useAffectedRows=true
    username: ${username}
    password: ${password}
  druid:
      initial-size: 10 # 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时
      min-idle: 10 # 最小连接池数量
      maxActive: 200 # 最大连接池数量
      maxWait: 60000 # 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置
      timeBetweenEvictionRunsMillis: 60000 # 关闭空闲连接的检测时间间隔.Destroy线程会检测连接的间隔时间，如果连接空闲时间大于等于minEvictableIdleTimeMillis则关闭物理连接。
      minEvictableIdleTimeMillis: 300000 # 连接的最小生存时间.连接保持空闲而不被驱逐的最小时间
      validationQuery: SELECT 1 FROM DUAL # 验证数据库服务可用性的sql.用来检测连接是否有效的sql 因数据库方言而差, 例如 oracle 应该写成 SELECT 1 FROM DUAL
      testWhileIdle: true # 申请连接时检测空闲时间，根据空闲时间再检测连接是否有效.建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRun
      testOnBorrow: false # 申请连接时直接检测连接是否有效.申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。
      testOnReturn: false # 归还连接时检测连接是否有效.归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。
      poolPreparedStatements: true # 开启PSCache
      maxPoolPreparedStatementPerConnectionSize: 20 #设置PSCache值
      connectionErrorRetryAttempts: 3 # 连接出错后再尝试连接三次
      breakAfterAcquireFailure: true # 数据库服务宕机自动重连机制
      timeBetweenConnectErrorMillis: 300000 # 连接出错后重试时间间隔
      asyncInit: true # 异步初始化策略
      remove-abandoned: true # 是否自动回收超时连接
      remove-abandoned-timeout: 1800 # 超时时间(以秒数为单位)
      transaction-query-timeout: 6000 # 事务超时时间
      filters: stat,wall,log4j2
      connectionProperties: druid.stat.mergeSql\=true;druid.stat.slowSqlMillis\=5000
      web-stat-filter:
        enabled: true
        url-pattern: "/*"
        exclusions: "*.js,*.gif,*.jpg,*.bmp,*.png,*.css,*.ico,/druid/*"
      stat-view-servlet:
        url-pattern: "/druid/*"
        allow:
        deny:
        reset-enable: false
        login-username: admin
        login-password: admin
```



### InnoDB和MyISAM的区别

- InnoDB支持事务，MyISAM不支持
- InnoDB支持行级锁而MyISAM仅仅支持表锁。但是InnoDB可能出现死锁。
- InnoDB的关注点在于：并发写、事务、更大资源。而MyISAM的关注点在于：节省资源、消耗少、简单业务
- InnoDB比MyISAM更安全，但是MyISAM的效率要比InnoDB高
- 在MySQL5.7的时候，默认就是InnoDb作为默认的存储引擎了

### Sql执行计划

- 使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。分析查询语句或是表结构的性能瓶颈。

```
Explain + SQL语句
```

- 通过Explain，我们可以获取以下信息：
  - 表的读取顺序
  - 哪些索引可以使用
  - 数据读取操作的操作类型
  - **哪些索引被实际使用**
  - 表之间的引用
  - **每张表有多少行被物理查询**

```
EXPLAIN SELECT * FROM USER;
```

![Image](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-11-640.png)

显示的结果一般不会全部去关注，比较关注的有：

- `id`是查询的序列号,包含一组数字，表示查询中执行select子句或操作表的顺序。
  - id相同，执行顺序由上至下。
  - 如果是子查询，id的序号会递增。id越大优先级越高，越先被执行。
  - id如果相同，可以认为是一组，从上往下顺序执行。在所有组中，id值越大，优先级越高，越先执行。
  - **id号每个号码，表示一趟独立的查询。一个sql的查询趟数越少越好。**
- 第二个是`type`，显示的是访问类型。如果是`All`就代表是全表扫描。需要进行优化。一般来说，得保证查询至少达到range级别，最好能达到ref。
- 然后是`possible_keys`：sql所用到的索引
- 还有一个就是`key`，这个就是实际使用的索引。如果为NULL，则没有使用索引。
- 然后`key_len`表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。key_len字段能够帮你检查where条件是否充分的利用上了索引。key_len越长，查询效率越高。
- `rows`列显示MySQL认为它执行查询时必须检查的行数。行数越少，效率越高！

### 数据库优化

- 选取最适用的字段属性
- 使用连接查询代替子查询
- 为合适的字段创建索引

### 在上线后数据库要增加几个字段，你们是怎么做的

可以使用alter添加列，这样原有的数据不会改变，新增的字段值是null。 还可以使用Navicat或者SQLyog这些可视化工具修改表的结构，效果和上面的一样

### 数据库索引的优化建议以及有哪些注意点

- 使用复合索引的效果会大于使用单个字段索引（但是要注意顺序）
- 查询条件时要按照索引中的定义顺序进行匹配。如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始并且不跳过索引中的列。
- 不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），会导致索引失效而转向全表扫描
- 存储引擎不能使用索引中范围条件右边的列，范围查询的列在定义索引的时候，应该放在最后面。
- mysql 在使用不等于(!= 或者<>)的时候无法使用索引会导致全表扫描
- is not null 也无法使用索引,但是is null是可以使用索引的
- like以通配符开头('%abc...')mysql索引失效会变成全表扫描的操作
- 字符串不加单引号索引失效（类型转换导致索引失效）

### MySQL锁

MyISAM支持表锁，InnoDB支持表锁和行锁，默认行锁。

- 表级锁：开锁小，加锁快，不会出现死锁。锁的粒度大，发生锁冲突的概率最高。并发量最低。
- 行级锁：开销大，加锁慢，会出现死锁，锁的粒度小，容易发生冲突的概率小，并发度最高

### 事务的ACID是指什么？

- 原子性(Atomic)：事务中各项操作，要么全做要么全不做，任何一项操作的失败都会导致整个事务的失败
- 一致性(Consistent)：事务结束后系统状态是一致的
- 隔离性(Isolated)：并发执行的事务彼此无法看到对方的中间状态
- 持久性(Durable)：事务完成后所做的改动都会被持久化，即使发生灾难性的失败。通过日志和同步备份可以在故障发生后重建数据

## 事务的隔离级别

- 只有存在并发数据访问时才需要事务。当多个事务访问同一数据时，可能会存在5类问题，包括3类数据读取问题（脏读、不可重复读和幻读）和2类数据更新问题（第1类丢失更新和第2类丢失更新）。

- 脏读（Dirty Read）：A事务读取B事务尚未提交的数据并在此基础上操作，而B事务执行回滚，那么A读取到的数据就是脏数据。
- 不可重复读（Unrepeatable Read）：事务A重新读取前面读取过的数据，发现该数据已经被另一个已提交的事务B修改过了。
- 幻读（Phantom Read）：事务A重新执行一个查询，返回一系列符合查询条件的行，发现其中插入了被事务B提交的行。
- 第1类丢失更新：事务A撤销时，把已经提交的事务B的更新数据覆盖了。
- 第2类丢失更新：事务A覆盖事务B已经提交的数据，造成事务B所做的操作丢失。

- 数据并发访问所产生的问题，在有些场景下可能是允许的，但是有些场景下可能就是致命的，数据库通常会通过锁机制来解决数据并发访问问题，按锁定对象不同可以分为表级锁和行级锁；按并发事务锁定关系可以分为共享锁和独占锁，具体的内容大家可以自行查阅资料进行了解。 
- 直接使用锁是非常麻烦的，为此数据库为用户提供了自动锁机制，只要用户指定会话的事务隔离级别，数据库就会通过分析SQL语句然后为事务访问的资源加上合适的锁，此外，数据库还会维护这些锁通过各种手段提高系统的性能，这些对用户来说都是透明的（就是说你不用理解，事实上我确实也不知道）。ANSI/ISO SQL 92标准定义了4个等级的事务隔离级别，如下表所示：

| 隔离级别        | 脏读   | 不可重复读 | 幻读   | 第一类丢失更新 | 第二类丢失更新 |
| --------------- | ------ | ---------- | ------ | -------------- | -------------- |
| READ UNCOMMITED | 允许   | 允许       | 允许   | 不允许         | 允许           |
| READ COMMITTED  | 不允许 | 允许       | 允许   | 不允许         | 允许           |
| REPEATABLE READ | 不允许 | 不允许     | 允许   | 不允许         | 不允许         |
| SERIALIZABLE    | 不允许 | 不允许     | 不允许 | 不允许         | 不允许         |

需要说明的是，事务隔离级别和数据访问的并发性是对立的，事务隔离级别越高并发性就越差。所以要根据具体的应用来确定合适的事务隔离级别，这个地方没有万能的原则。

### 连接池有什么作用？

由于创建连接和释放连接都有很大的开销（尤其是数据库服务器不在本地时，每次建立连接都需要进行TCP的三次握手，释放连接需要进行TCP四次握手，造成的开销是不可忽视的），为了提升系统访问数据库的性能，可以事先创建若干连接置于连接池中，需要时直接从连接池获取，使用结束时归还连接池而不必关闭连接，从而避免频繁创建和释放连接所造成的开销，这是典型的用空间换取时间的策略（浪费了空间存储连接，但节省了创建和释放连接的时间）。池化技术在Java开发中是很常见的，在使用线程时创建线程池的道理与此相同。基于Java的开源数据库连接池主要有：C3P0、Proxool、DBCP、BoneCP、Druid等。

> **补充**：在计算机系统中时间和空间是不可调和的矛盾，理解这一点对设计满足性能要求的算法是至关重要的。大型网站性能优化的一个关键就是使用缓存，而缓存跟上面讲的连接池道理非常类似，也是使用空间换时间的策略。可以将热点数据置于缓存中，当用户查询这些数据时可以直接从缓存中得到，这无论如何也快过去数据库中查询。当然，缓存的置换策略等也会对系统性能产生重要影响，对于这个问题的讨论已经超出了这里要阐述的范围。

### MySQL sql语句执行过程

## Redis

### 数据类型

| 类型                 | 简介                                                   | 特性                                                         | 场景                                                         |
| :------------------- | :----------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| String(字符串)       | 二进制安全                                             | 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M | ---                                                          |
| Hash(字典)           | 键值对集合,即编程语言中的Map类型                       | 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) | 存储、读取、修改用户属性                                     |
| List(列表)           | 链表(双向链表)                                         | 增删快,提供了操作某一段元素的API                             | 1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列          |
| Set(集合)            | 哈希表实现,元素不重复                                  | 1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 | 1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 |
| Sorted Set(有序集合) | 将Set中的元素增加一个权重参数score,元素按score有序排列 | 数据插入集合时,已经进行天然排序                              | 1、排行榜 2、带权重的消息队列                                |

### Redis 分布式锁

### Redis 缓存穿透,缓存击穿,缓存雪崩

#### 缓存穿透

- 缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。

**解决方法**

1. **将无效的key存放进Redis中**:当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置value="null"，并设置其过期时间极短，后面再出现查询这个key的请求的时候，直接返回null，就不需要再查询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义。
2. **使用布隆过滤器**:如果布隆过滤器判定某个 key 不存在布隆过滤器中，那么就一定不存在，如果判定某个 key 存在，那么很大可能是存在(存在一定的误判率)。于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。

**注意**

- 即使对空值设置了过期时间,还是会存在缓存层和存储层的数据会有一段时间窗口的不一致,这对于需要保持一致性的业务会有影响
- **如何选择**：针对一些恶意攻击，攻击带过来的大量key是随机，那么我们采用第一种方案就会缓存大量不存在key的数据。那么这种方案就不合适了，我们可以先对使用布隆过滤器方案进行过滤掉这些key。所以，针对这种key异常多、请求重复率比较低的数据，优先使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，则可优先采用第一种方式进行缓存。

#### 缓存击穿

- 缓存击穿跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种现象就叫做缓存击穿。

**解决方案**

1. **加互斥锁**:在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降
2. **热点数据缓存永远不过期**,永不过期实际包含两层意思：
   - 物理不过期，针对热点key不设置过期时间
   - 逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建

#### 缓存雪崩

- 如果缓存某一个时刻出现大规模的key失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。这就是缓存雪崩。

**解决方案**

1. 事前
   - 均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪崩，造成大量数据库的访问
   - 分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同
   - 热点数据缓存永远不过期
   - 保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，Redis集群来避免 Redis 全盘崩溃的情况
2. 事中
   - 互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降
   - 使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。
3. 事后
   - 开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。



### Redis的数据类型

- String字符串：字符串类型是 Redis 最基础的数据结构，首先键都是字符串类型，而且 其他几种数据结构都是在字符串类型基础上构建的，我们常使用的 set key value 命令就是字符串。常用在缓存、计数、共享Session、限速等。
- Hash哈希：在Redis中，哈希类型是指键值本身又是一个键值对结构，哈希可以用来存放用户信息，比如实现购物车。
- List列表（双向链表）：列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。
- Set集合：集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的，不能通过索引下标获取元素。利用 Set 的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
- Sorted Set有序集合（跳表实现）：Sorted Set 多了一个权重参数 Score，集合中的元素能够按 Score 进行排列。可以做排行榜应用，取 TOP N 操作。

### Redis的持久化

- Redis为了保证效率，数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。
- Redis的持久化策略有两种：
  1. RDB：快照形式是直接把内存中的数据保存到一个dump的文件中，定时保存，保存策略。当Redis需要做持久化时，Redis会fork一个子进程，子进程将数据写到磁盘上一个临时RDB文件中。 当子进程完成写临时文件后，将原来的RDB替换掉。
  2. AOF：把所有的对Redis的服务器进行修改的命令都存到一个文件里，命令的集合。使用AOF做持久化，每一个写命令都通过write函数追加到appendonly.aof中。aof的默认策略是每秒钟fsync一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。 缺点是对于相同的数据集来说，AOF的文件体积通常要大于RDB文件的体积。根据所使用的fsync策略，AOF的速度可能会慢于RDB。Redis默认是快照RDB的持久化方式。对于主从同步来说，主从刚刚连接的时候，进行全量同步（RDB）；全同步结束后，进行增量同步(AOF)。

### redis是单线程,但为什么快

1. 纯内存操作
2. 单线程操作，避免了频繁的上下文切换
3. 合理高效的数据结构
4. 采用了非阻塞I/O多路复用机制（有一个文件描述符同时监听多个文件描述符是否有数据到来）

### redis存的数据过期了，数据会立即删除吗

不会，其实有三种不同的删除策略：

1. 立即删除。在设置键的过期时间时，创建一个定时器，当过期时间达到时，立即执行删除操作。
2. 惰性删除。key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null。
3. 定时删除。每隔一段时间，对全部的键进行检查，删除里面的过期键。

### Redis 和 Mysql 数据库数据如何保持一致性

先更新数据库，再删缓存。数据库的读操作的速度远快于写操作的，所以脏数据很难出现。可以对异步延时删除策略，保证读请求完成以后，再进行删除操作。

### Redis的应用场景

- 缓存
- 共享Session
- 消息队列系统
- 分布式锁

### redis里的hash类型怎么模糊查询

可以使用Java连接Redis，获得指定hash的所有值，然后做正则验证。

### Redis常用命令

```
key
    keys * 获取所有的key
    select 0 选择第一个库
    move myString 1 将当前的数据库key移动到某个数据库,目标库有，则不能移动
    flush db      清除指定库
    randomkey     随机key
    type key      类型
    
    set key1 value1 设置key
    get key1    获取key
    mset key1 value1 key2 value2 key3 value3
    mget key1 key2 key3
    del key1   删除key
    exists key      判断是否存在key
    expire key 10   10过期
    pexpire key 1000 毫秒
    persist key     删除过期时间

string
    set name cxx
    get name
    getrange name 0 -1        字符串分段
    getset name new_cxx       设置值，返回旧值
    mset key1 key2            批量设置
    mget key1 key2            批量获取
    setnx key value           不存在就插入（not exists）
    setex key time value      过期时间（expire）
    setrange key index value  从index开始替换value
    incr age        递增
    incrby age 10   递增
    decr age        递减
    decrby age 10   递减
    incrbyfloat     增减浮点数
    append          追加
    strlen          长度
    getbit/setbit/bitcount/bitop    位操作
    
hash
    hset myhash name cxx
    hget myhash name
    hmset myhash name cxx age 25 note "i am notes"
    hmget myhash name age note   
    hgetall myhash               获取所有的
    hexists myhash name          是否存在
    hsetnx myhash score 100      设置不存在的
    hincrby myhash id 1          递增
    hdel myhash name             删除
    hkeys myhash                 只取key
    hvals myhash                 只取value
    hlen myhash                  长度

list
    lpush mylist a b c  左插入
    rpush mylist x y z  右插入
    lrange mylist 0 -1  数据集合
    lpop mylist  弹出元素
    rpop mylist  弹出元素
    llen mylist  长度
    lrem mylist count value  删除
    lindex mylist 2          指定索引的值
    lset mylist 2 n          索引设值
    ltrim mylist 0 4         删除key
    linsert mylist before a  插入
    linsert mylist after a   插入
    rpoplpush list list2     转移列表的数据
    
set
    sadd myset redis 
    smembers myset       数据集合
    srem myset set1         删除
    sismember myset set1 判断元素是否在集合中
    scard key_name       个数
    sdiff | sinter | sunion 操作：集合间运算：差集 | 交集 | 并集
    srandmember          随机获取集合中的元素
    spop                 从集合中弹出一个元素
    
zset
    zadd zset 1 one
    zadd zset 2 two
    zadd zset 3 three
    zincrby zset 1 one              增长分数
    zscore zset two                 获取分数
    zrange zset 0 -1 withscores     范围值
    zrangebyscore zset 10 25 withscores 指定范围的值
    zrangebyscore zset 10 25 withscores limit 1 2 分页
    Zrevrangebyscore zset 10 25 withscores  指定范围的值
    zcard zset  元素数量
    Zcount zset 获得指定分数范围内的元素个数
    Zrem zset one two        删除一个或多个元素
    Zremrangebyrank zset 0 1  按照排名范围删除元素
    Zremrangebyscore zset 0 1 按照分数范围删除元素
    Zrank zset 0 -1    分数最小的元素排名为0
    Zrevrank zset 0 -1  分数最大的元素排名为0
    Zinterstore
    zunionstore rank:last_week 7 rank:20150323 rank:20150324 rank:20150325  weights 1 1 1 1 1 1 1
    
    
排序：
    sort mylist  排序
    sort mylist alpha desc limit 0 2 字母排序
    sort list by it:* desc           by命令
    sort list by it:* desc get it:*  get参数
    sort list by it:* desc get it:* store sorc:result  sort命令之store参数：表示把sort查询的结果集保存起来
```

## RabbitMq

### 怎么防止重复消费

- 可能因为各种原因，导致了生产端发送了多条一样的消息给消费端，但是，消费端也只能消费一条，不会多消费。可以使用`唯一ID + 指纹码机制`防止消息被重复消费。
- 指纹码(就是时间戳 + 业务的一些规则， 来保证id + 指纹码在同一时刻是唯一的，不会出现重复)。
  1. 唯一ID + 指纹码机制，利用数据库主键去重
  2. select count(1) from t_order where id = 唯一ID + 指纹码
     - 如果不存在，则正常消费，消费完毕后将【唯一ID + 指纹码】 写入数据库
     - 如果存在，则证明消息被消费过，直接丢弃。

### Rabbitmq怎么防止消息丢失

将信道设置成confirm模式（发送方确认模式），则所有在信道上发布的消息都会被指派一个唯一的ID。 一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息），信道会发送一个确认给生产者（包含消息唯一ID）。

### 为什么选择使用MQ来实现同步

通过使用消息队列，我们可以异步处理请求，从而缓解系统的压力。同样可以达到解耦的效果。

## ElasticSearch

### 高亮你们是怎么做的

- SpringBoot整合ElasticSearch有一个searchSourceBuilder，通过链式调用一个highlighter方法，传入一个HighlightBuilder对象并设置好查询的列和高亮的标签。
- 之后调用RestHighLevelClient对象的Search方法之后返回一个SearchResponse对象，之后可以调用response.getHits().getHits();获得击中的结果数组，数组中每一个对象除了包含原始内容还包含了一个高亮结果集，是一个Map集合。

### SpringBoot怎么集成ElasticSearch

首先需要导入`spring-boot-starter-data-elasticsearch`，在Spring官网的data项目里面有详细的文档介绍，官方强烈建议使用  High Level REST Client来操作ES。之后需要添加一个配置类，在官方文档有介绍。之后我们就可以通过Spring容器来管理获取HighLevelRESTClient对象了。

## 其他

### Maven的生命周期？

- Maven有三套生命周期,分别是clean、default、site，每个生命周期都包含了一些阶段（phase）。三套生命周期相互独立，但各个生命周期中的phase却是有顺序的，且后面的phase依赖于前面的phase。执行某个phase时，其前面的phase会依顺序执行，但不会触发另外两套生命周期中的任何phase。
- clean的生命周期：

```
pre-clean：执行清理前的工作；
clean：清理上一次构建生成的所有文件；
post-clean：执行清理后的工作
```

- default的生命周期：default生命周期是最核心的，它包含了构建项目时真正需要执行的所有步骤。

```
validate
initialize
generate-sources
process-sources
generate-resources
process-resources    ：复制和处理资源文件到target目录，准备打包；
compile    ：编译项目的源代码；
process-classes
generate-test-sources
process-test-sources
generate-test-resources
process-test-resources
test-compile    ：编译测试源代码；
process-test-classes
test    ：运行测试代码；
prepare-package
package    ：打包成jar或者war或者其他格式的分发包；
pre-integration-test
integration-test
post-integration-test
verify
install    ：将打好的包安装到本地仓库，供其他项目使用；
deploy    ：将打好的包安装到远程仓库，供其他项目使用；
```

- site的生命周期：

```
pre-site
site    ：生成项目的站点文档；
post-site
site-deploy    ：发布生成的站点文档
```

### cookie和session区别

1. cookie数据存放在客户的浏览器上，session数据放在服务器上。
2. cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session。
3. session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie。
4. 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。
5. 可以考虑将登陆信息等重要信息存放为session，其他信息如果需要保留，可以放在cookie中。

## 数据结构

### 红黑树

​	根节点是黑色 

​	每个节点都只能是红色或者黑色

​	每个叶节点（NIL节点，空节点）是黑色的。 

​	如果一个节点是红色的，则它两个子节点都是黑色的，也就是说在一条路径上不能出现两个红色的节点。

​	从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

## 算法

### 排序算法

排序算法是最经典的算法知识。因为其实现代码短，应该广，在面试中经常会问到排序算法及其相关的问题。一般在面试中最常考的是快速排序和归并排序等基本的排序算法，并且经常要求现场手写基本的排序算法。如果这些问题回答不好，估计面试就凉凉了。所以熟练掌握排序算法思想及其特点并能够熟练地手写代码至关重要。

下面介绍几种常见的排序算法：冒泡排序、选择排序、插入排序、归并排序、快速排序、希尔排序、堆排序、计数排序、桶排序、基数排序的思想，其代码均采用Java实现。

#### 冒泡排序

冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 

**算法描述**

1. 比较相邻的元素。如果第一个比第二个大，就交换它们两个；
2. 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数；
3. 针对所有的元素重复以上的步骤，除了最后一个；
4. 重复步骤1~3，直到排序完成。

**动图演示**

![img](https://pic4.zhimg.com/v2-33a947c71ad62b254cab62e5364d2813_b.gif)

**算法实现**

```java
public static void bubbleSort(int[] arr) {
    int temp = 0;
    for (int i = arr.length - 1; i > 0; i--) { // 每次需要排序的长度
        for (int j = 0; j < i; j++) { // 从第一个元素到第i个元素
            if (arr[j] > arr[j + 1]) {
                temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
            }
        }//loop j
    }//loop i
}// method bubbleSort
```

**稳定性**

在相邻元素相等时，它们并不会交换位置，所以，冒泡排序是稳定排序。

**适用场景**

冒泡排序思路简单，代码也简单，特别适合小数据的排序。但是，由于算法复杂度较高，在数据量大的时候不适合使用。

**代码优化**

在数据完全有序的时候展现出最优时间复杂度，为O(n)。其他情况下，几乎总是O( n2 )。因此，算法在数据基本有序的情况下，性能最好。
要使算法在最佳情况下有O(n)复杂度，需要做一些改进，增加一个`swap`的标志，当前一轮没有进行交换时，说明数组已经有序，没有必要再进行下一轮的循环了，直接退出。

```java
public static void bubbleSort(int[] arr) {
    int temp = 0;
    boolean swap;
    for (int i = arr.length - 1; i > 0; i--) { // 每次需要排序的长度
        swap=false;
        for (int j = 0; j < i; j++) { // 从第一个元素到第i个元素
            if (arr[j] > arr[j + 1]) {
                temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
                swap=true;
            }
        }//loop j
        if (swap==false){
            break;
        }
    }//loop i
}// method bubbleSort
```

#### 选择排序

选择排序是一种简单直观的排序算法，它也是一种交换排序算法，和冒泡排序有一定的相似度，可以认为选择排序是冒泡排序的一种改进。

**算法描述**

1. 在未排序序列中找到最小（大）元素，存放到排序序列的起始位置
2. 从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。
3. 重复第二步，直到所有元素均排序完毕。

**动图演示**

![img](https://pic1.zhimg.com/v2-1c7e20f306ddc02eb4e3a50fa7817ff4_b.gif)

**算法实现**

```java
public static void selectionSort(int[] arr) {
    int temp, min = 0;
    for (int i = 0; i < arr.length - 1; i++) {
        min = i;
        // 循环查找最小值
        for (int j = i + 1; j < arr.length; j++) {
            if (arr[min] > arr[j]) {
                min = j;
            }
        }
        if (min != i) {
            temp = arr[i];
            arr[i] = arr[min];
            arr[min] = temp;
        }
    }
}
```

**稳定性**

用数组实现的选择排序是不稳定的，用链表实现的选择排序是稳定的。
不过，一般提到排序算法时，大家往往会默认是数组实现，所以选择排序是不稳定的。

**适用场景**

选择排序实现也比较简单，并且由于在各种情况下复杂度波动小，因此一般是优于冒泡排序的。在所有的完全交换排序中，选择排序也是比较不错的一种算法。但是，由于固有的O(n2)复杂度，选择排序在海量数据面前显得力不从心。因此，它适用于简单数据排序。

#### 插入排序

插入排序是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。

**算法描述**

1. 把待排序的数组分成已排序和未排序两部分，初始的时候把第一个元素认为是已排好序的。
2. 从第二个元素开始，在已排好序的子数组中寻找到该元素合适的位置并插入该位置。
3. 重复上述过程直到最后一个元素被插入有序子数组中。

**动图演示**

![img](https://pic3.zhimg.com/v2-91b76e8e4dab9b0cad9a017d7dd431e2_b.jpg)

**算法实现**

```java
public static void insertionSort(int[] arr){
    for (int i=1; i<arr.length; ++i){
        int value = arr[i];
        int position=i;
        while (position>0 && arr[position-1]>value){
            arr[position] = arr[position-1];
            position--;
        }
        arr[position] = value;
    }//loop i
}
```

**稳定性**

由于只需要找到不大于当前数的位置而并不需要交换，因此，直接插入排序是稳定的排序方法。

**适用场景**

插入排序由于O( n2 )的复杂度，在数组较大的时候不适用。但是，在数据比较少的时候，是一个不错的选择，一般做为快速排序的扩充。例如，在STL的sort算法和stdlib的qsort算法中，都将插入排序作为快速排序的补充，用于少量元素的排序。又如，在JDK 7 java.util.Arrays所用的sort方法的实现中，当待排数组长度小于47时，会使用插入排序。

#### 归并排序

归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。 

**算法描述**

两种方法

- 递归法（Top-down）

1. 申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列
2. 设定两个指针，最初位置分别为两个已经排序序列的起始位置
3. 比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置
4. 重复步骤3直到某一指针到达序列尾
5. 将另一序列剩下的所有元素直接复制到合并序列尾

- 迭代法（Bottom-up）

原理如下（假设序列共有n个元素）：

1. 将序列每相邻两个数字进行归并操作，形成ceil(n/2)个序列，排序后每个序列包含两/一个元素
2. 若此时序列数不是1个则将上述序列再次归并，形成ceil(n/4)个序列，每个序列包含四/三个元素
3. 重复步骤2，直到所有元素排序完毕，即序列数为1

**动图演示**

![img](https://pic3.zhimg.com/v2-cdda3f11c6efbc01577f5c29a9066772_b.gif)

**算法实现**

```java
public static void mergeSort(int[] arr){
    int[] temp =new int[arr.length];
    internalMergeSort(arr, temp, 0, arr.length-1);
}
private static void internalMergeSort(int[] arr, int[] temp, int left, int right){
    //当left==right的时，已经不需要再划分了
    if (left<right){
        int middle = (left+right)/2;
        internalMergeSort(arr, temp, left, middle);          //左子数组
        internalMergeSort(arr, temp, middle+1, right);       //右子数组
        mergeSortedArray(arr, temp, left, middle, right);    //合并两个子数组
    }
}
// 合并两个有序子序列
private static void mergeSortedArray(int arr[], int temp[], int left, int middle, int right){
    int i=left;      
    int j=middle+1;
    int k=0;
    while (i<=middle && j<=right){
        temp[k++] = arr[i] <= arr[j] ? arr[i++] : arr[j++];
    }
    while (i <=middle){
        temp[k++] = arr[i++];
    }
    while ( j<=right){
        temp[k++] = arr[j++];
    }
    //把数据复制回原数组
    for (i=0; i<k; ++i){
        arr[left+i] = temp[i];
    }
}
```

**稳定性**

因为我们在遇到相等的数据的时候必然是按顺序“抄写”到辅助数组上的，所以，归并排序同样是稳定算法。

**适用场景**

归并排序在数据量比较大的时候也有较为出色的表现（效率上），但是，其空间复杂度O(n)使得在数据量特别大的时候（例如，1千万数据）几乎不可接受。而且，考虑到有的机器内存本身就比较小，因此，采用归并排序一定要注意。

#### **快速排序**

快速排序是一个知名度极高的排序算法，其对于大数据的优秀排序性能和相同复杂度算法中相对简单的实现使它注定得到比其他算法更多的宠爱。

**算法描述**

1. 从数列中挑出一个元素，称为"基准"（pivot），
2. 重新排序数列，所有比基准值小的元素摆放在基准前面，所有比基准值大的元素摆在基准后面（相同的数可以到任何一边）。在这个分区结束之后，该基准就处于数列的中间位置。这个称为分区（partition）操作。
3. 递归地（recursively）把小于基准值元素的子数列和大于基准值元素的子数列排序。

**动图演示**

![img](https://pic1.zhimg.com/v2-c411339b79f92499dcb7b5f304c826f4_b.gif)

**算法实现**

```java
public static void quickSort(int[] arr){
    qsort(arr, 0, arr.length-1);
}
private static void qsort(int[] arr, int low, int high){
    if (low >= high)
        return;
    int pivot = partition(arr, low, high);        //将数组分为两部分
    qsort(arr, low, pivot-1);                   //递归排序左子数组
    qsort(arr, pivot+1, high);                  //递归排序右子数组
}
private static int partition(int[] arr, int low, int high){
    int pivot = arr[low];     //基准
    while (low < high){
        while (low < high && arr[high] >= pivot) --high;
        arr[low]=arr[high];             //交换比基准大的记录到左端
        while (low < high && arr[low] <= pivot) ++low;
        arr[high] = arr[low];           //交换比基准小的记录到右端
    }
    //扫描完成，基准到位
    arr[low] = pivot;
    //返回的是基准的位置
    return low;
}
```

- **稳定性**:快速排序并不是稳定的。这是因为我们无法保证相等的数据按顺序被扫描到和按顺序存放。
- **适用场景**:快速排序在大多数情况下都是适用的，尤其在数据量大的时候性能优越性更加明显。但是在必要的时候，需要考虑下优化以提高其在最坏情况下的性能。

#### **堆排序**

堆排序(Heapsort)是指利用堆积树（堆）这种数据结构所设计的一种排序算法，它是选择排序的一种。可以利用数组的特点快速定位指定索引的元素。堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。

**堆的概念**

堆是一种特殊的完全二叉树（complete binary tree）。完全二叉树的一个“优秀”的性质是，除了最底层之外，每一层都是满的，这使得堆可以利用数组来表示（普通的一般的二叉树通常用链表作为基本容器表示），每一个结点对应数组中的一个元素。
如下图，是一个堆和数组的相互关系：

![img](https://pic3.zhimg.com/80/v2-ee5361924b3a5d942045f0455989b496_720w.jpg)


对于给定的某个结点的下标 i，可以很容易的计算出这个结点的父结点、孩子结点的下标：

- Parent(i) = floor(i/2)，i 的父节点下标
- Left(i) = 2i，i 的左子节点下标
- Right(i) = 2i + 1，i 的右子节点下标

二叉堆一般分为两种：最大堆和最小堆。
**最大堆：**
最大堆中的最大元素值出现在根结点（堆顶）
堆中每个父节点的元素值都大于等于其孩子结点（如果存在）

![img](https://pic3.zhimg.com/80/v2-03738a5cbdc36e179153de3c1c444a86_720w.jpg)


**最小堆：**
最小堆中的最小元素值出现在根结点（堆顶）
堆中每个父节点的元素值都小于等于其孩子结点（如果存在）

![img](https://pic4.zhimg.com/80/v2-7706ecb76bb194619d8c996281ba96c3_720w.jpg)



**堆排序原理**

堆排序就是把最大堆堆顶的最大数取出，将剩余的堆继续调整为最大堆，再次将堆顶的最大数取出，这个过程持续到剩余数只有一个时结束。在堆中定义以下几种操作：

- 最大堆调整（Max-Heapify）：将堆的末端子节点作调整，使得子节点永远小于父节点
- 创建最大堆（Build-Max-Heap）：将堆所有数据重新排序，使其成为最大堆
- 堆排序（Heap-Sort）：移除位在第一个数据的根节点，并做最大堆调整的递归运算 继续进行下面的讨论前，需要注意的一个问题是：数组都是 Zero-Based，这就意味着我们的堆数据结构模型要发生改变



![img](https://pic2.zhimg.com/80/v2-c701eeb7741b66f7cc23aa1834c8e539_720w.jpg)


相应的，几个计算公式也要作出相应调整：

- Parent(i) = floor((i-1)/2)，i 的父节点下标
- Left(i) = 2i + 1，i 的左子节点下标
- Right(i) = 2(i + 1)，i 的右子节点下标

**堆的建立和维护**

堆可以支持多种操作，但现在我们关心的只有两个问题：

1. 给定一个无序数组，如何建立为堆？
2. 删除堆顶元素后，如何调整数组成为新堆？

先看第二个问题。假定我们已经有一个现成的大根堆。现在我们删除了根元素，但并没有移动别的元素。想想发生了什么：根元素空了，但其它元素还保持着堆的性质。我们可以把**最后一个元素**（代号A）移动到根元素的位置。如果不是特殊情况，则堆的性质被破坏。但这仅仅是由于A小于其某个子元素。于是，我们可以把A和这个子元素调换位置。如果A大于其所有子元素，则堆调整好了；否则，重复上述过程，A元素在树形结构中不断“下沉”，直到合适的位置，数组重新恢复堆的性质。上述过程一般称为“筛选”，方向显然是自上而下。

> 删除后的调整，是把最后一个元素放到堆顶，自上而下比较

删除一个元素是如此，插入一个新元素也是如此。不同的是，我们把新元素放在**末尾**，然后和其父节点做比较，即自下而上筛选。

> 插入是把新元素放在末尾，自下而上比较

那么，第一个问题怎么解决呢？

常规方法是从第一个非叶子结点向下筛选，直到根元素筛选完毕。这个方法叫“筛选法”，需要循环筛选n/2个元素。

但我们还可以借鉴“插入排序”的思路。我们可以视第一个元素为一个堆，然后不断向其中添加新元素。这个方法叫做“插入法”，需要循环插入(n-1)个元素。

由于筛选法和插入法的方式不同，所以，相同的数据，它们建立的堆一般不同。大致了解堆之后，堆排序就是水到渠成的事情了。

**动图演示**

![img](https://pic3.zhimg.com/v2-c66a7e83189427b6a5a5c378f73c17ca_b.jpg)



**算法描述**

我们需要一个升序的序列，怎么办呢？我们可以建立一个最小堆，然后每次输出根元素。但是，这个方法需要额外的空间（否则将造成大量的元素移动，其复杂度会飙升到O(n2) ）。如果我们需要就地排序（即不允许有O(n)空间复杂度），怎么办？

有办法。我们可以建立最大堆，然后我们倒着输出，在最后一个位置输出最大值，次末位置输出次大值……由于每次输出的最大元素会腾出第一个空间，因此，我们恰好可以放置这样的元素而不需要额外空间。很漂亮的想法，是不是？

**算法实现**

```java
public class ArrayHeap {
    private int[] arr;
    public ArrayHeap(int[] arr) {
        this.arr = arr;
    }
    private int getParentIndex(int child) {
        return (child - 1) / 2;
    }
    private int getLeftChildIndex(int parent) {
        return 2 * parent + 1;
    }
    private void swap(int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
    /**
     * 调整堆。
     */
    private void adjustHeap(int i, int len) {
        int left, right, j;
        left = getLeftChildIndex(i);
        while (left <= len) {
            right = left + 1;
            j = left;
            if (j < len && arr[left] < arr[right]) {
                j++;
            }
            if (arr[i] < arr[j]) {
                swap(array, i, j);
                i = j;
                left = getLeftChildIndex(i);
            } else {
                break; // 停止筛选
            }
        }
    }
    /**
     * 堆排序。
     * */
    public void sort() {
        int last = arr.length - 1;
        // 初始化最大堆
        for (int i = getParentIndex(last); i >= 0; --i) {
            adjustHeap(i, last);
        }
        // 堆调整
        while (last >= 0) {
            swap(0, last--);
            adjustHeap(0, last);
        }
    }

}
```

**稳定性**

堆排序存在大量的筛选和移动过程，属于不稳定的排序算法。

**适用场景**

堆排序在建立堆和调整堆的过程中会产生比较大的开销，在元素少的时候并不适用。但是，在元素比较多的情况下，还是不错的一个选择。尤其是在解决诸如“前n大的数”一类问题时，几乎是首选算法。

#### **希尔排序（插入排序的改良版）**

在希尔排序出现之前，计算机界普遍存在“排序算法不可能突破O(n2)”的观点。希尔排序是第一个突破O(n2)的排序算法，它是简单插入排序的改进版。希尔排序的提出，主要基于以下两点：

1. 插入排序算法在数组基本有序的情况下，可以近似达到O(n)复杂度，效率极高。
2. 但插入排序每次只能将数据移动一位，在数组较大且基本无序的情况下性能会迅速恶化。

**算法描述**

先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述：

- 选择一个增量序列t1，t2，…，tk，其中ti>tj，tk=1；
- 按增量序列个数k，对序列进行 k 趟排序；
- 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。

**动图演示**



![img](https://pic3.zhimg.com/v2-f14e4169ff39bad42c3dd6c385ad9c72_b.gif)



**算法实现**

Donald Shell增量

```java
public static void shellSort(int[] arr){
    int temp;
    for (int delta = arr.length/2; delta>=1; delta/=2){                              //对每个增量进行一次排序
        for (int i=delta; i<arr.length; i++){              
            for (int j=i; j>=delta && arr[j]<arr[j-delta]; j-=delta){ //注意每个地方增量和差值都是delta
                temp = arr[j-delta];
                arr[j-delta] = arr[j];
                arr[j] = temp;
            }
        }//loop i
    }//loop delta
}
```

O(n3/2) by Knuth

```java
public static void shellSort2(int[] arr){
    int delta = 1;
    while (delta < arr.length/3){//generate delta
        delta=delta*3+1;    // <O(n^(3/2)) by Knuth,1973>: 1, 4, 13, 40, 121, ...
    }         
    int temp;
    for (; delta>=1; delta/=3){
        for (int i=delta; i<arr.length; i++){              
            for (int j=i; j>=delta && arr[j]<arr[j-delta]; j-=delta){
                temp = arr[j-delta];
                arr[j-delta] = arr[j];
                arr[j] = temp;
            }
        }//loop i
    }//loop delta
}
```

**希尔排序的增量**

希尔排序的增量数列可以任取，需要的唯一条件是最后一个一定为1（因为要保证按1有序）。但是，不同的数列选取会对算法的性能造成极大的影响。上面的代码演示了两种增量。
切记：增量序列中每两个元素最好不要出现1以外的公因子！（很显然，按4有序的数列再去按2排序意义并不大）。
下面是一些常见的增量序列。
\- 第一种增量是最初Donald Shell提出的增量，即折半降低直到1。据研究，使用希尔增量，其时间复杂度还是O(n2)。

第二种增量Hibbard：{1, 3, ..., 2k-1}。该增量序列的时间复杂度大约是O(n1.5)。

第三种增量Sedgewick增量：(1, 5, 19, 41, 109,...)，其生成序列或者是9*4i* *- 9*2i + 1或者是4i - 3*2i + 1。

**稳定性**

我们都知道插入排序是稳定算法。但是，Shell排序是一个多次插入的过程。在一次插入中我们能确保不移动相同元素的顺序，但在多次的插入中，相同元素完全有可能在不同的插入轮次被移动，最后稳定性被破坏，因此，Shell排序不是一个稳定的算法。

**适用场景**

Shell排序虽然快，但是毕竟是插入排序，其数量级并没有后起之秀--快速排序O(n㏒n)快。在大量数据面前，Shell排序不是一个好的算法。但是，中小型规模的数据完全可以使用它。

#### **计数排序**

计数排序不是基于比较的排序算法，其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。

**算法描述**

1. 找出待排序的数组中最大和最小的元素；
2. 统计数组中每个值为i的元素出现的次数，存入数组C的第i项；
3. 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；
4. 反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。

**动图演示**



![img](https://pic4.zhimg.com/v2-3c7ddb59df2d21b287e42a7b908409cb_b.jpg)



**算法实现**

```java
public static void countSort(int[] a, int max, int min) {
     int[] b = new int[a.length];//存储数组
     int[] count = new int[max - min + 1];//计数数组

     for (int num = min; num <= max; num++) {
        //初始化各元素值为0，数组下标从0开始因此减min
        count[num - min] = 0;
     }

     for (int i = 0; i < a.length; i++) {
        int num = a[i];
        count[num - min]++;//每出现一个值，计数数组对应元素的值+1
     }

     for (int num = min + 1; num <= max; num++) {
        //加总数组元素的值为计数数组对应元素及左边所有元素的值的总和
        count[num - min] += sum[num - min - 1]
     }

     for (int i = 0; i < a.length; i++) {
          int num = a[i];//源数组第i位的值
          int index = count[num - min] - 1;//加总数组中对应元素的下标
          b[index] = num;//将该值存入存储数组对应下标中
          count[num - min]--;//加总数组中，该值的总和减少1。
     }

     //将存储数组的值一一替换给源数组
     for(int i=0;i<a.length;i++){
         a[i] = b[i];
     }
}
```

**稳定性**

最后给 b 数组赋值是倒着遍历的，而且放进去一个就将C数组对应的值（表示前面有多少元素小于或等于A[i]）减去一。如果有相同的数x1,x2，那么相对位置后面那个元素x2放在（比如下标为4的位置），相对位置前面那个元素x1下次进循环就会被放在x2前面的位置3。从而保证了稳定性。

**适用场景**

排序目标要能够映射到整数域，其最大值最小值应当容易辨别。例如高中生考试的总分数，显然用0-750就OK啦；又比如一群人的年龄，用个0-150应该就可以了，再不济就用0-200喽。另外，计数排序需要占用大量空间，它比较适用于数据比较集中的情况。

#### **桶排序**

桶排序又叫箱排序，是计数排序的升级版，它的工作原理是将数组分到有限数量的桶子里，然后对每个桶子再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序），最后将各个桶中的数据有序的合并起来。

> 计数排序是桶排序的一种特殊情况，可以把计数排序当成每个桶里只有一个元素的情况。网络中很多博文写的桶排序实际上都是计数排序，并非标准的桶排序，要注意辨别。

**算法描述**

1. 找出待排序数组中的最大值max、最小值min
2. 我们使用 动态数组ArrayList 作为桶，桶里放的元素也用 ArrayList 存储。桶的数量为(max-min)/arr.length+1
3. 遍历数组 arr，计算每个元素 arr[i] 放的桶
4. 每个桶各自排序
5. 遍历桶数组，把排序好的元素放进输出数组

**图片演示**



![img](https://pic1.zhimg.com/80/v2-465190477b7fb90d17aef27c2a213368_720w.jpg)



**算法实现**

```java
public static void bucketSort(int[] arr){
    int max = Integer.MIN_VALUE;
    int min = Integer.MAX_VALUE;
    for(int i = 0; i < arr.length; i++){
        max = Math.max(max, arr[i]);
        min = Math.min(min, arr[i]);
    }
    //桶数
    int bucketNum = (max - min) / arr.length + 1;
    ArrayList<ArrayList<Integer>> bucketArr = new ArrayList<>(bucketNum);
    for(int i = 0; i < bucketNum; i++){
        bucketArr.add(new ArrayList<Integer>());
    }
    //将每个元素放入桶
    for(int i = 0; i < arr.length; i++){
        int num = (arr[i] - min) / (arr.length);
        bucketArr.get(num).add(arr[i]);
    }
    //对每个桶进行排序
    for(int i = 0; i < bucketArr.size(); i++){
        Collections.sort(bucketArr.get(i));
    }
    System.out.println(bucketArr.toString());
}
```

**稳定性**

可以看出，在分桶和从桶依次输出的过程是稳定的。但是，由于我们在对每个桶进行排序时使用了其他算法，所以，桶排序的稳定性依赖于这一步。如果我们使用了快排，显然，算法是不稳定的。

**适用场景**

桶排序可用于最大最小值相差较大的数据情况，但桶排序要求数据的分布必须均匀，否则可能导致数据都集中到一个桶中。比如[104,150,123,132,20000], 这种数据会导致前4个数都集中到同一个桶中。导致桶排序失效。

#### **基数排序**

基数排序(Radix Sort)是桶排序的扩展，它的基本思想是：将整数按位数切割成不同的数字，然后按每个位数分别比较。
排序过程：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。

**算法描述**

1. 取得数组中的最大数，并取得位数；
2. arr为原始数组，从最低位开始取每个位组成radix数组；
3. 对radix进行计数排序（利用计数排序适用于小范围数的特点）；

**动图**

![img](https://pic3.zhimg.com/v2-3a6f1e5059386523ed941f0d6c3a136e_b.jpg)

**算法实现**

```java
public abstract class Sorter {
     public abstract void sort(int[] array);
}
 
public class RadixSorter extends Sorter {
     
     private int radix;
     
     public RadixSorter() {
          radix = 10;
     }
     
     @Override
     public void sort(int[] array) {
          // 数组的第一维表示可能的余数0-radix，第二维表示array中的等于该余数的元素
          // 如：十进制123的个位为3，则bucket[3][] = {123}
          int[][] bucket = new int[radix][array.length];
          int distance = getDistance(array); // 表示最大的数有多少位
          int temp = 1;
          int round = 1; // 控制键值排序依据在哪一位
          while (round <= distance) {
               // 用来计数：数组counter[i]用来表示该位是i的数的个数
               int[] counter = new int[radix];
               // 将array中元素分布填充到bucket中，并进行计数
               for (int i = 0; i < array.length; i++) {
                    int which = (array[i] / temp) % radix;
                    bucket[which][counter[which]] = array[i];
                    counter[which]++;
               }
               int index = 0;
               // 根据bucket中收集到的array中的元素，根据统计计数，在array中重新排列
               for (int i = 0; i < radix; i++) {
                    if (counter[i] != 0)
                         for (int j = 0; j < counter[i]; j++) {
                              array[index] = bucket[i][j];
                              index++;
                         }
                    counter[i] = 0;
               }
               temp *= radix;
               round++;
          }
     }
     
     private int getDistance(int[] array) {
          int max = computeMax(array);
          int digits = 0;
          int temp = max / radix;
          while(temp != 0) {
               digits++;
               temp = temp / radix;
          }
          return digits + 1;
     }
     
     private int computeMax(int[] array) {
          int max = array[0];
          for(int i=1; i<array.length; i++) {
               if(array[i]>max) {
                    max = array[i];
               }
          }
          return max;
     }
}
```

**稳定性**

通过上面的排序过程，我们可以看到，每一轮映射和收集操作，都保持从左到右的顺序进行，如果出现相同的元素，则保持他们在原始数组中的顺序。可见，基数排序是一种稳定的排序。

**适用场景**

基数排序要求较高，元素必须是整数，整数时长度10W以上，最大值100W以下效率较好，但是基数排序比其他排序好在可以适用字符串，或者其他需要根据多个条件进行排序的场景，例如日期，先排序日，再排序月，最后排序年 ，其它排序算法可是做不了的。

#### **总结**

<img src="https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-14-v2-f718f6b01ad35a60b9d4f02330f81439_720w.jpg" alt="img" style="zoom:50%;" />

### 二叉树遍历

- 前序遍历：根结点 ---> 左子树 ---> 右子树
- 中序遍历：左子树---> 根结点 ---> 右子树
- 后序遍历：左子树 ---> 右子树 ---> 根结点
- 层次遍历：只需按层次遍历即可

<img src="https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-23-image-20210423144633672.png" alt="image-20210423144633672" style="zoom:50%;" />

- 前序遍历：1  2  4  5  7  8  3  6 
- 中序遍历：4  2  7  5  8  1  3  6
- 后序遍历：4  7  8  5  2  6  3  1
- 层次遍历：1  2  3  4  5  6  7  8

一、前序遍历

1）根据上文提到的遍历思路：根结点 ---> 左子树 ---> 右子树，很容易写出递归版本：

```java
public void preOrderTraverse1(TreeNode root) {
  if (root != null) {
    System.out.print(root.val+"  ");
    preOrderTraverse1(root.left);
    preOrderTraverse1(root.right);
  }
}
```

2）现在讨论非递归的版本：
根据前序遍历的顺序，优先访问根结点，然后在访问左子树和右子树。所以，对于任意结点node，第一部分即直接访问之，之后在判断左子树是否为空，不为空时即重复上面的步骤，直到其为空。若为空，则需要访问右子树。注意，在访问过左孩子之后，需要反过来访问其右孩子，所以，需要栈这种数据结构的支持。对于任意一个结点node，具体步骤如下：

a)访问之，并把结点node入栈，当前结点置为左孩子；

b)判断结点node是否为空，若为空，则取出栈顶结点并出栈，将右孩子置为当前结点；否则重复a)步直到当前结点为空或者栈为空（可以发现栈中的结点就是为了访问右孩子才存储的）

代码如下：

```java
public void preOrderTraverse2(TreeNode root) {
  LinkedList<TreeNode> stack = new LinkedList<>();
  TreeNode pNode = root;
  while (pNode != null || !stack.isEmpty()) {
    if (pNode != null) {
      System.out.print(pNode.val+"  ");
      stack.push(pNode);
      pNode = pNode.left;
    } else { //pNode == null && !stack.isEmpty()
      TreeNode node = stack.pop();
      pNode = node.right;
    }
  }
}
```

二、中序遍历
1)根据上文提到的遍历思路：左子树 ---> 根结点 ---> 右子树，很容易写出递归版本：

```java
public void inOrderTraverse1(TreeNode root) {
  if (root != null) {
    inOrderTraverse1(root.left);
    System.out.print(root.val+"  ");
    inOrderTraverse1(root.right);
  }
}
```

2）非递归实现，有了上面前序的解释，中序也就比较简单了，相同的道理。只不过访问的顺序移到出栈时。代码如下：

```java
public void inOrderTraverse2(TreeNode root) {
  LinkedList<TreeNode> stack = new LinkedList<>();
  TreeNode pNode = root;
  while (pNode != null || !stack.isEmpty()) {
    if (pNode != null) {
      stack.push(pNode);
      pNode = pNode.left;
    } else { //pNode == null && !stack.isEmpty()
      TreeNode node = stack.pop();
      System.out.print(node.val+"  ");
      pNode = node.right;
    }
  }
}
```

三、后序遍历

1）根据上文提到的遍历思路：左子树 ---> 右子树 ---> 根结点，很容易写出递归版本：

```java
public void postOrderTraverse1(TreeNode root) {
  if (root != null) {
    postOrderTraverse1(root.left);
    postOrderTraverse1(root.right);
    System.out.print(root.val+"  ");
  }
}
```

2）非递归的代码，暂且不写

```java

    public static void postTraverse(TreeNode node) {
        if (node == null)
            return;
        Deque<TreeNode> s = new LinkedList<>();

        TreeNode curNode; //当前访问的结点
        TreeNode lastVisitNode; //上次访问的结点
        curNode = node;
        lastVisitNode = null;

        //把currentNode移到左子树的最下边
        while (curNode != null) {
            s.push(curNode);
            curNode = curNode.left;
        }
        while (!s.isEmpty()) {
            curNode = s.pop();  //弹出栈顶元素
            //一个根节点被访问的前提是：无右子树或右子树已被访问过
            if (curNode.right != null && curNode.right != lastVisitNode) {
                //根节点再次入栈
                s.push(curNode);
                //进入右子树，且可肯定右子树一定不为空
                curNode = curNode.right;
                while (curNode != null) {
                    //再走到右子树的最左边
                    s.push(curNode);
                    curNode = curNode.left;
                }
            } else {
                //访问
                System.out.print(curNode.val + "  ");
                //修改最近被访问的节点
                lastVisitNode = curNode;
            }
        } //while
```

四、层次遍历

层次遍历的代码比较简单，只需要一个队列即可，先在队列中加入根结点。之后对于任意一个结点来说，在其出队列的时候，访问之。同时如果左孩子和右孩子有不为空的，入队列。代码如下：

```java
public void levelTraverse(TreeNode root) {
  if (root == null) {
    return;
  }
  LinkedList<TreeNode> queue = new LinkedList<>();
  queue.offer(root);
  while (!queue.isEmpty()) {
    TreeNode node = queue.poll();
    System.out.print(node.val+"  ");
    if (node.left != null) {
      queue.offer(node.left);
    }
    if (node.right != null) {
      queue.offer(node.right);
    }
  }
}
```

五、深度优先遍历
其实深度遍历就是上面的前序、中序和后序。但是为了保证与广度优先遍历相照应，也写在这。代码也比较好理解，其实就是前序遍历，代码如下：

```java
public void depthOrderTraverse(TreeNode root) {
  if (root == null) {
    return;
  }
  LinkedList<TreeNode> stack = new LinkedList<>();
  stack.push(root);
  while (!stack.isEmpty()) {
    TreeNode node = stack.pop();
    System.out.print(node.val+"  ");
    if (node.right != null) {
      stack.push(node.right);
    }
    if (node.left != null) {
      stack.push(node.left);
    }
  }
}
```

### DCL

```java
public class LazyMan {

  private LazyMan() {
    System.out.println(Thread.currentThread().getName());
  }

  private volatile static LazyMan lazyman;

  public static LazyMan getInstance() {
    if (lazyman == null) {
      synchronized (LazyMan.class) {
        if (lazyman == null) {
          lazyman = new LazyMan();
        }
      }
    }
    return lazyman;
  }

  // 模拟多线程并发
  public static void main(String[] args) {
    for (int i = 0; i < 10; i++) {
      new Thread(() -> {
        LazyMan.getInstance();
      }).start();
    }
  }
}
```

### 用Java写一个冒泡排序

冒泡排序几乎是个程序员都写得出来，但是面试的时候如何写一个逼格高的冒泡排序却不是每个人都能做到，下面提供一个参考代码：

```java
import java.util.Comparator;

/**
 * 排序器接口(策略模式: 将算法封装到具有共同接口的独立的类中使得它们可以相互替换)
 *
 */
public interface Sorter {

  /**
    * 排序
    * @param list 待排序的数组
    */
  public <T extends Comparable<T>> void sort(T[] list);

  /**
    * 排序
    * @param list 待排序的数组
    * @param comp 比较两个对象的比较器
    */
  public <T> void sort(T[] list, Comparator<T> comp);
}
```

```java
import java.util.Comparator;

/**
 * 冒泡排序
 * 
 * @author骆昊
 *
 */
public class BubbleSorter implements Sorter {

  @Override
  public <T extends Comparable<T>> void sort(T[] list) {
    boolean swapped = true;
    for (int i = 1, len = list.length; i < len && swapped; ++i) {
      swapped = false;
      for (int j = 0; j < len - i; ++j) {
        if (list[j].compareTo(list[j + 1]) > 0) {
          T temp = list[j];
          list[j] = list[j + 1];
          list[j + 1] = temp;
          swapped = true;
        }
      }
    }
  }

  @Override
  public <T> void sort(T[] list, Comparator<T> comp) {
    boolean swapped = true;
    for (int i = 1, len = list.length; i < len && swapped; ++i) {
      swapped = false;
      for (int j = 0; j < len - i; ++j) {
        if (comp.compare(list[j], list[j + 1]) > 0) {
          T temp = list[j];
          list[j] = list[j + 1];
          list[j + 1] = temp;
          swapped = true;
        }
      }
    }
  }
}
```

### 用Java写一个折半查找

折半查找，也称二分查找、二分搜索，是一种在有序数组中查找某一特定元素的搜索算法。搜素过程从数组的中间元素开始，如果中间元素正好是要查找的元素，则搜素过程结束；如果某一特定元素大于或者小于中间元素，则在数组大于或小于中间元素的那一半中查找，而且跟开始一样从中间元素开始比较。如果在某一步骤数组已经为空，则表示找不到指定的元素。这种搜索算法每一次比较都使搜索范围缩小一半，其时间复杂度是O(logN)。

```java
import java.util.Comparator;

public class MyUtil {

  public static <T extends Comparable<T>> int binarySearch(T[] x, T key) {
    return binarySearch(x, 0, x.length- 1, key);
  }

  // 使用循环实现的二分查找
  public static <T> int binarySearch(T[] x, T key, Comparator<T> comp) {
    int low = 0;
    int high = x.length - 1;
    while (low <= high) {
      int mid = (low + high) >>> 1;
      int cmp = comp.compare(x[mid], key);
      if (cmp < 0) {
        low= mid + 1;
      }
      else if (cmp > 0) {
        high= mid - 1;
      }
      else {
        return mid;
      }
    }
    return -1;
  }

  // 使用递归实现的二分查找
  private static<T extends Comparable<T>> int binarySearch(T[] x, int low, int high, T key) {
    if(low <= high) {
      int mid = low + ((high -low) >> 1);
      if(key.compareTo(x[mid])== 0) {
        return mid;
      }
      else if(key.compareTo(x[mid])< 0) {
        return binarySearch(x,low, mid - 1, key);
      }
      else {
        return binarySearch(x,mid + 1, high, key);
      }
    }
    return -1;
  }
}
```

> **说明**：上面的代码中给出了折半查找的两个版本，一个用递归实现，一个用循环实现。需要注意的是计算中间位置时不应该使用(high+ low) / 2的方式，因为加法运算可能导致整数越界，这里应该使用以下三种方式之一：low + (high - low) / 2或low + (high – low) >> 1或(low + high) >>> 1（>>>是逻辑右移，是不带符号位的右移）

### 递归实现字符串反转

递归实现字符串反转，代码如下所示

```java
public static String reverse(String originStr) {
  if(originStr == null || originStr.length() <= 1) 
    return originStr;
  return reverse(originStr.substring(1)) + originStr.charAt(0);
}
```

## 操作系统

### 线程与进程

### 线程的状态

进程的状态

就绪(Ready)状态

当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。

执行状态

进程已获得CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态； 在多处理机系统中，则有多个进程处于执行状态。

阻塞状态

正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态，亦即进程的执行受到阻塞，把这种暂停状态称为阻塞状态，有时也称为等待状态或封锁状态。致使进程阻塞的典型事件有：请求I/O，申请缓冲空间等。通常将这种处于阻塞状态的进程也排成一个队列。有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列。

**三者的转换图如下：**

![img](https:////upload-images.jianshu.io/upload_images/1485056-efde09b1217348ee.png?imageMogr2/auto-orient/strip|imageView2/2/w/852)

**挂起状态**

在不少系统中进程只有上述三种状态，但在另一些系统中，又增加了一些新状态，最重要的是挂起状态。引入挂起状态的原因有：

(1) 终端用户的请求。当终端用户在自己的程序运行期间发现有可疑问题时，希望暂时使自己的程序静止下来。亦即，使正在执行的进程暂停执行；若此时用户进程正处于就绪状态而未执行，则该进程暂不接受调度，以便用户研究其执行情况或对程序进行修改。我们把这种静止状态称为挂起状态。

(2) 父进程请求。有时父进程希望挂起自己的某个子进程，以便考查和修改该子进程，或者协调各子进程间的活动。

(3) 负荷调节的需要。当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。

(4) 操作系统的需要。操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。

**具有挂起状态的转换图**

![img](https:////upload-images.jianshu.io/upload_images/1485056-999cd919ddf7beac.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/927)

**创建状态**

创建一个进程一般要通过一下两个两个步骤

(1) 为一个新进程创建PCB，并填写必要的管理信息.

(2) 把该进程转入就绪状态并插入就绪队列之中。当一个新进程被创建时，系统已为其分配了PCB，填写了进程标识等信息，但由于该进程所必需的资源或其它信息，如主存资源尚未分配等，一般而言，此时的进程已拥有了自己PCB，但进程自身还未进入主存，即创建工作尚未完成，进程还不能被调度运行，其所处的状态就是创建状态。 引入创建状态，是为了保证进程的调度必须在创建工作完成后进行，以确保对进程控制块操作的完整性。同时，创建状态的引入，也增加了管理的灵活性，操作系统可以根据系统性能或主存容量的限制，推迟创建状态进程的提交。对于处于创建状态的进程，获得了其所必需的资源，以及对其PCB初始化工作完成后，进程状态便可由创建状态转入就绪状态。

终止状态

等待操作系统进行善后处理，然后将其PCB清零，并将PCB空间返还系统。当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入终止状态。进入终止态的进程以后不能再执行，但在操作系统中依然保留一个记录，其中保存状态码和一些计时统计数据，供其它进程收集。一旦其它进程完成了对终止状态进程的信息提取之后，操作系统将删除该进程。

增加了创建状态和终止状态后，进程的三种基本状态及转换图衍变为五种状态及转换关系图



![img](https:////upload-images.jianshu.io/upload_images/1485056-9d17cf698a3f0dbc.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200)



### 死锁

-  AB两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。
  -   互斥条件：一个资源每次只能被一个进程使用。 
  - 请求与保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 
  - 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺
  - 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 
- 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之
-  **死锁避免**
   - 允许进程动态的申请资源，但系统在进行资源分配前，应先计算此次资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源你分配给进程，否则，让进程等待。
   - 所谓安全状态，是指系统能按某种进程推进顺序，为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求，是每个进程都可以顺序的完成。此时成P1P2P3...为安全序列，如果系统无法找到一个安全序列，则称系统处于不安全状态。
   - 并非所有的不安全状态都是死锁状态，但当系统进入不安全状态后，便可能进入死锁状态；反之，只要系统处于安全状态，系统便可以避免进入死锁状态。
   - 银行家算法是最著名的死锁避免算法。
- 死锁解除
  - 资源剥夺法。挂起某些思索进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源时，而处于资源匮乏的状态。
  - 进程撤销法。强制撤销一个或一部分进程并剥夺这些进程的资源。撤销的原则可以按进程的优先级和撤销进程代价的高低进行。
  - 进程回退法。让一个或多个进程回退到足以回避死锁的地步，进程回退时资源释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

## 计算机网络

### OSI七层模型和协议

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-21-v2-2d62ba265be486cb94ab531912aa3b9c_720w.jpg)

### TCP三次握手，4次挥手的过程描述一下

**握手过程**：

1. 主机A向主机B发送请求连接数据报，其中包括A的序列号`seq=x`，请求连接的标志位`SYN=1`
2. 主机B收到请求之后返回确认连接数据报，其中包括B的序列号`seq=y`，请求连接的标志位`SYN=1`，`ACK=1`还有一个确认号，`ack=x+1`
3. 主机A收到了B的确认报文后再次做出确认，再发送一个数据报，其中包括：`ACK=1`，`seq=x+1`，`ack=y+1`

- 至于为什么要发送第三条是因为在发送第一条的时候，可能因为网络原因导致数据报滞留，那么超过一定时间主机A会再次发送请求连接的数据报文。之后主机B返回确认连接报文，如果主机A收到确认报文之后不发送第三条报文告诉主机B自己已经收到了，那么B其实是不知道的，这时候可能A第一次发送的原本滞留的报文突然正常了，B就再次收到了请求连接的报文，但是实际上A已经连接了。

**挥手过程**：

1. 客户端向服务器发送一个请求断开连接的数据报，终止位`FIN=1`，序列号`seq=u`
2. 服务器收到请求后返回`ACK=1`，`seq=v`，`ack=u+1`。之后客户端通往服务器的单向连接就断开了。
3. 之后服务器也需要和客户端断开连接，也是发送了一个FIN
4. 客户端收到FIN后返回ACK，并将确认号设置为收到的序号+1

- 其实在客户端断开和服务器的单向连接之后，服务器仍然可以往客户端发送数据，需要处理一下事情。
- 客户端需要最后等一段时间才能进入关闭状态是因为：客户端无法保证最后发送的ACK报文会一定被对方收到，所以有时候需要重发可能丢失的ACK报文。

### Http 长连接短连接

​	Connection:keep-alive

​	**短连接**的操作步骤是：

​	建立连接——数据传输——关闭连接...建立连接——数据传输——关闭连接

​	**长连接**的操作步骤是：

​	建立连接——数据传输...（保持连接）...数据传输——关闭连接

​	**长连接**多用于操作频繁，点对点的通讯，而且连接数不能太多情况，。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，次处理时直接发送数据包就OK了，不用建立TCP连接。例如：数据库的连接用长连接， 如果用短连接频繁的通信会造成socket错误，而且频繁的socket 创建也是对资源的浪费。 

　　而像WEB网站的http服务一般都用**短链接**，因为长连接对于服务端来说会耗费一定的资源，而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连好。

### TCP流量控制,拥塞控制

**一：流量控制**

什么是流量控制？流量控制的目的？

如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止分组丢失，它是构成TCP可靠性的一方面。

如何实现流量控制？

由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。

流量控制引发的死锁？怎么避免死锁的发生？

当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。
为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。

**二：拥塞控制和流量控制的区别**

拥塞控制：拥塞控制是作用于网络的，它是防止过多的数据注入到网络中，避免出现网络负载过大的情况；常用的方法就是：（ 1 ）慢开始、拥塞避免（ 2 ）快重传、快恢复。

流量控制：流量控制是作用于接收者的，它是控制发送者的发送速度从而使接收者来得及接收，防止分组丢失的。

**三：拥塞控制的算法**

我们在开始假定：1、数据是单方向传递，另一个窗口只发送确认；2、接收方的缓存足够大，因此发送方的大小的大小由网络的拥塞程度来决定。

（一）慢开始算法：

发送方维持一个叫做拥塞窗口cwnd（congestion window）的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口，另外考虑到接受方的接收能力，发送窗口可能小于拥塞窗口。

慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。

这里用报文段的个数作为拥塞窗口的大小举例说明慢开始算法，实际的拥塞窗口大小是以字节为单位的。如下图：



![img](https://pic2.zhimg.com/80/v2-54715533f093170d50f1ff1be39006e9_1440w.jpg)



从上图可以看到，一个传输轮次所经历的时间其实就是往返时间RTT，而且没经过一个传输轮次（transmission round），拥塞窗口cwnd就加倍。

为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：当cwnd<ssthresh时，使用慢开始算法。
当cwnd>ssthresh时，改用拥塞避免算法。
当cwnd=ssthresh时，慢开始与拥塞避免算法任意

注意，这里的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd=1，然后逐渐增大，这当然比按照大的cwnd一下子把许多报文段突然注入到网络中要“慢得多”。

（二）拥塞避免算法：

拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。

无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。

整个拥塞控制的流程如下图：



![img](https://pic3.zhimg.com/80/v2-f7db63b1f00cbd8170e1435616e06216_1440w.jpg)



（1）拥塞窗口cwnd初始化为1个报文段，慢开始门限初始值为16
（2）执行慢开始算法，指数规律增长到第4轮，即cwnd=16=ssthresh，改为执行拥塞避免算法，拥塞窗口按线性规律增长
（3）假定cwnd=24时，网络出现超时（拥塞），则更新后的ssthresh=12，cwnd重新设置为1，并执行慢开始算法。当cwnd=12=ssthresh时，改为执行拥塞避免算法

关于 乘法减小（Multiplicative Decrease）和加法增大（Additive Increase）：

“乘法减小”指的是无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞，就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半，并执行慢开始算法，所以当网络频繁出现拥塞时，ssthresh下降的很快，以大大减少注入到网络中的分组数。“加法增大”是指执行拥塞避免算法后，使拥塞窗口缓慢增大，以防止过早出现拥塞。常合起来成为AIMD算法。

注意：“拥塞避免”并非完全能够避免了阻塞，而是使网络比较不容易出现拥塞。

（三）快重传算法：

快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方，可提高网络吞吐量约20%）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。如下图：



![img](https://pic3.zhimg.com/80/v2-c72fce5494ca8ee12244189430f12cea_1440w.jpg)



（四）快恢复算法：

- 快重传配合使用的还有快恢复算法，有以下两个要点：
- 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢开始算法
  考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。如下图：TCP Reno版本是目前使用最广泛的版本。

![img](https://pic4.zhimg.com/80/v2-5f4034bc11c3a48a1d1a115f9ee0259b_1440w.jpg)

注意：在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用

## 场景题

### 高并发减库存

**一、防止重复**

**利用redis分布式锁**

用分布式锁，是为了防刷、防止同一个用户同一秒里面把购物车里的商品进行多次结算，防止前端代码出问题触发两次。 利用Jedis客户端编写分布式锁

```java
String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);
```

lockKey是redis的Key，为用户id+商品id+商品数量组成，这样同一秒中只能有一次处理逻辑。 requestId是redis的value，实际是当前线程id，表示有一条线程占用。

> 大家要注意这种分布式锁写法，是同时设定超时时间的。有些分布式锁的文章可能是比较旧版的redis不支持同时设置超时时间，他就一条语句先设置key value，另一条语句后设置超时时间。所以大家留意一下。

**二、扣减库存**

安全扣减库存方案有很多说法，列一下几个方案和我推荐的方案。

**方案一：分布式锁**

有的文章会用redis分布式锁来做保证扣库存数量准确的环节，让点击结算时，后端逻辑会查询库存和扣库存的update语句同时只有一条线程能够执行，以商品id为分布式锁的key，锁一个商品。但是这样，其他购买相同商品的用户将会进行等待。

- 优点：这样做虽然安全
- 缺点：但是失去的是性能问题。

**方案二：分布式锁+分段缓存**

也有文章会说借鉴ConcurrenthashMap，分段锁的机制，把100个商品，分在3个段上，key为分段名字，value为库存数量。用户下单时对用户id进行%3计算，看落在哪个redis的key上，就去取哪个。

> 如key1=product-01,value1=33;key2=product-02,value2=33;key3=product-03,value3=33;

其实会有几个问题：

- 一个是用户想买34件的时候，要去两个片查
- 一个片上卖完了为0，又要去另外一个片查
- 取余方式计算每一片数量，除不尽时，让最后一片补，如100/3=33.33。

**缺点：**

- 方案复杂
- 有遗留问题

**方案三： redis的lpush rpop**

redis队列的lpush、rpop都是只能每次进出一个，对于购买多个数量的情况下不适用，只适用于秒杀情况购买一个的场景、或者抢红包的场景，所以觉得不是很通用。

> 备注：这个抢红包场景以后再分享。

**方案四：推荐使用redis原子操作+sql乐观锁**

**利用Redis increment 的原子操作，保证库存数安全**

1. 先查询redis中是否有库存信息，如果没有就去数据库查，这样就可以减少访问数据库的次数。 获取到后把数值填入redis，以商品id为key，数量为value。 注意要设置**序列化方式为StringRedisSerializer**，不然不能把value做加减操作。 还需要设置redis对应这个key的超时时间，以防所有商品库存数据都在redis中。
2. 比较下单数量的大小，如果够就做后续逻辑。
3. 执行redis客户端的increment，参数为负数，则做减法。因为redis是**单线程处理**，并且因为**increment让key对应的value 减少后返回的是修改后的值**。 有的人会不做第一步查询直接减，其实这样不太好，因为当库存为1时，很多做减3，或者减30情况，其实都是不够，这样就白减。
4. 扣减数据库的库存，这个时候就不需要再select查询，直接乐观锁update，把库存字段值减1 。
5. 做完扣库存就在订单系统做下单。

***样例场景：***

1. 假设两个用户在第一步查询得到库存等于10，A用户走到第二步扣10件，同时一秒内B用户走到第二部扣3件。
2. 因为redis单线程处理，若A用户线程先执行redis语句，那么现在库存等于0，B就只能失败，就不会出更新数据库了。

```java
public void order(OrderReq req) {
  String key = "product:" + req.getProductId();
  // 第一步：先检查 库存是否充足
  Integer num = (Integer) redisTemplate.get(key);
  if (num == null){
    // 去查数据库的数据
    // 并且把数据库的库存set进redis，注意使用NX参数表示只有当没有redis中没有这个key的时候才set库存数量到redis
    //注意要设置序列化方式为StringRedisSerializer，不然不能把value做加减操作
    // 同时设置超时时间，因为不能让redis存着所有商品的库存数，以免占用内存。
    if (count >=0) {
      //设置有效期十分钟
      redisTemplate.expire(key, 60*10+随机数防止雪崩, TimeUnit.SECONDS);
    }
    // 减少经常访问数据库，因为磁盘比内存访问速度要慢
  }
  if (num < req.getNum()) {
    logger.info("库存不足");
  }
  // 第二步：减少库存
  long value = redisTemplate.increment(key, -req.getNum().longValue());
  // 库存充足
  if (value >= 0) {
    logger.info("成功购买");
    // update 数据库中商品库存和订单系统下单，单的状态未待支付
    // 分开两个系统处理时，可以用LCN做分布式事务，但是也是有概率会订单系统的网络超时
    // 也可以使用最终一致性的方式，更新库存成功后，发送mq，等待订单创建生成回调。
    boolean res= updateProduct(req);
    if (res)
      createOrder(req);
  } else {
    // 减了后小小于0 ，如两个人同时买这个商品，导致A人第一步时看到还有10个库存，但是B人买9个先处理完逻辑，
    // 导致B人的线程10-9=1, A人的线程1-10=-9，则现在需要增加刚刚减去的库存，让别人可以买1个
    redisTemplate.increment(key, req.getNum().longValue());
    logger.info("恢复redis库存");
  }
}
```

**update使用乐观锁**

updateProduct方法中执行的sql如下：

```
update Product set count = count - #{购买数量} where id = #{id} and count - #{购买数量} >= 0;
复制代码
```

虽然redis已经防止了超卖，但是数据库层面，为了也要防止超卖，以防redis崩溃时无法使用或者不需要redis处理时，则用乐观锁，因为不一定全部商品都用redis。

利用sql每条单条语句都是有事务的，所以两条sql同时执行，也就只会有其中一条sql先执行成功，另外一条后执行，也如上文提及到的场景一样。

**简单说一下分布式事务：**

分开两个系统处理库存和订单时，这个时候可以用LCN框架做分布式事务，但是因为是http请求的，也是有概率会订单系统的网络超时，导致未返回结果。

其实也可以使用最终一致性的方式，数据表记录一条交互流水记录，更新库存成功后，更新这个交互流水记录的库存操作字段为已处理，订单处理字段为处理中，然后发送mq，等待订单创建生成回调。也要做定时任务做主动查询订单系统的结果，以防没有结果回来。

**方案优势**

- 不需要频繁访问数据库商品库存还有多少
- 不阻塞其他用户
- 安全扣减库存量
- 内存访问库存数量，减少数据库交互

**高并发额外优化**

- 用户访问下单是，前端ui可以让用户触发结算后，把按钮置灰色，防止重复触发。
- 可以按照库存数量来选定是否要用redis，因为如果库存数量少，或者说最近下单次数少的商品，就不用放redis，因为少人看和买的情况下，不必放redis导致占用内存。
- 如果到时间点抢购时，可以使用mq队列形式，用户触发购买商品后，进入队列，让用户的页面一直在转圈圈，等轮到他买的时候再进入结算页面，结算页面的后续流程和本文一致。

### 如何保证Redis和 MySQL双写数据一致性

**1.MySQL持久化数据，Redis只读数据**

redis在启动之后，从数据库加载数据。

**读请求：**

**不要求强一致性的读请求，走redis，要求强一致性的直接从mysql读取**

**写请求：**

**数据首先都写到数据库，之后更新redis**（先写redis再写mysql，如果写入失败事务回滚会造成redis中存在脏数据）

**2.MySQL和Redis处理不同的数据类型**

- MySQL处理实时性数据，例如金融数据、交易数据
- Redis处理实时性要求不高的数据，例如网站最热贴排行榜，好友列表等

在并发不高的情况下，读操作优先读取redis，不存在的话就去访问MySQL，并把读到的数据写回Redis中；

写操作的话，直接写MySQL，成功后再写入Redis(可以在MySQL端定义CRUD触发器，在触发CRUD操作后写数据到Redis，也可以在Redis端解析binlog，再做相应的操作)

在并发高的情况下，读操作和上面一样，写操作是异步写，写入Redis后直接返回，然后定期写入MySQL

几个例子：

1.当更新数据时，如更新某商品的库存，当前商品的库存是100，现在要更新为99，先更新数据库更改成99，然后删除缓存，发现删除缓存失败了，这意味着数据库存的是99，而缓存是100，这导致数据库和缓存不一致。

解决方法：

这种情况应该是先删除缓存，然后再更新数据库，如果删除缓存失败，那就不要更新数据库，如果说删除缓存成功，而更新数据库失败，那查询的时候只是从数据库里查了旧的数据而已，这样就能保持数据库与缓存的一致性。

2.在高并发的情况下，如果当删除完缓存的时候，这时去更新数据库，但还没有更新完，另外一个请求来查询数据，发现缓存里没有，就去数据库里查，还是以上面商品库存为例，如果数据库中产品的库存是100，那么查询到的库存是100，然后插入缓存，插入完缓存后，原来那个更新数据库的线程把数据库更新为了99，导致数据库与缓存不一致的情况

解决方法：

遇到这种情况，可以用队列的去解决这个问，创建几个队列，如20个，根据商品的ID去做hash值，然后对队列个数取摸，当有数据更新请求时，先把它丢到队列里去，当更新完后再从队列里去除。如果在更新的过程中，遇到以上场景，先去缓存里看下有没有数据，如果没有，可以先去队列里看是否有相同商品ID在做更新，如果有也把查询的请求发送到队列里去，然后同步等待缓存更新完成。

这里有一个优化点，如果发现队列里有一个查询请求了，那么就不要放新的查询操作进去了，用一个while（true）循环去查询缓存，循环个200MS左右，如果缓存里还没有则直接取数据库的旧数据，一般情况下是可以取到的。

在高并发下解决场景二要注意的问题：

**1、读请求时长阻塞**

由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时间内返回，该解决方案最大的风险在于可能数据更新很频繁，导致队列中挤压了大量的更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库，像遇到这种情况，一般要做好足够的压力测试，如果压力过大，需要根据实际情况添加机器。

**2、请求并发量过高**

这里还是要做好压力测试，多模拟真实场景，并发量在最高的时候QPS多少，扛不住就要多加机器，还有就是做好读写比例是多少

**3、多服务实例部署的请求路由**

可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，都通过nginx服务器路由到相同的服务实例上

**4、热点商品的路由问题，导致请求的倾斜**

某些商品的读请求特别高，全部打到了相同的机器的相同丢列里了，可能造成某台服务器压力过大，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以更新频率不是太高的话，这个问题的影响并不是很大，但是确实有可能某些服务器的负载会高一些。

 

![如何保证Redis和 MySQL双写数据一致性](http://p3.pstatp.com/large/pgc-image/51d30e5381ca4663aff8c97a39c9af9f)
