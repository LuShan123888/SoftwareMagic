---
title: 面试题
categories:
- Software
- Concept
---
# 面试题

## JVM

### GC

- 垃圾回收可以有效的防止内存泄露,有效的使用可以使用的内存,垃圾回收器通常是作为一个单独的低优先级的线程运行,不可预知的情况下对内存堆中已经死亡的或者长时间没有使用的对象进行清除和回收,程序员不能实时的调用垃圾回收器对某个对象或所有对象进行垃圾回收

### 与垃圾回收相关的JVM参数

> -Xms / -Xmx — 堆的初始大小 / 堆的最大大小
>
> -Xmn — 堆中年轻代的大小
> -XX:-DisableExplicitGC — 让System.gc()不产生任何作用
> -XX:+PrintGCDetails — 打印GC的细节
> -XX:+PrintGCDateStamps — 打印GC操作的时间戳
> -XX:NewSize / XX:MaxNewSize — 设置新生代大小/新生代最大大小
> -XX:NewRatio — 可以设置老生代和新生代的比例
> -XX:PrintTenuringDistribution — 设置每次新生代GC后输出幸存者乐园中对象年龄的分布
> -XX:InitialTenuringThreshold / -XX:MaxTenuringThreshold:设置老年代阀值的初始值和最大值
> -XX:TargetSurvivorRatio:设置幸存区的目标使用率

### 垃圾回收的流程

- 首先有三个代,新生代,老年代,永久代
- 在新生代有三个区域:一个Eden区和两个Survivor区,当一个实例被创建了,首先会被存储Eden 区中
- 具体过程是这样的:
  - 一个对象实例化时,先去看Eden区有没有足够的空间
  - 如果有,不进行垃圾回收,对象直接在Eden区存储
  - 如果Eden区内存已满,会进行一次minor gc
  - 然后再进行判断Eden区中的内存是否足够
  - 如果不足,则去看Survivor区的内存是否足够
  - 如果内存足够,把Eden区部分活跃对象保存在Survivor区,然后把对象保存在Eden区
  - 如果内存不足,查询老年代的内存是否足够
  - 如果老年代内存足够,将部分Survivor区的活跃对象存入老年代,然后把Eden区的活跃对象放入Survivor区,对象依旧保存在Eden区
  - 如果老年代内存不足,会进行一次full gc,之后老年代会再进行判断 内存是否足够,如果足够 还是那些步骤
  - 如果不足,会抛出OutOfMemoryError(内存溢出异常)

### GC算法

- **标记-清除算法**:遍历 `GC Roots`,然后将所有 `GC Roots` 可达的对象标记,将没有标记的对象全部清除掉
- **复制算法**:它将可用内存按容量划分为大小相等的两块,每次只使用其中的一块,当这一块内存用完,需要进行垃圾收集时,就将存活者的对象复制到另一块上面,然后将第一块内存全部清除
- **标记-整理算法**:遍历 `GC Roots`,然后将存活的对象标记,移动所有存活的对象,且按照内存地址次序依次排列,然后将末端内存地址以后的内存全部回收,因此
- **标记-压缩算法**:首先也需要从根节点开始对所有可达对象做一次标记之后,它并不简单地清理未标记的对象,而是将所有的存活对象压缩到内存的一端,再清理边界外所有的空间

### 垃圾回收器

- CMS 垃圾收集器以获取最短回收停顿时间为目标的收集器(追求低停顿),它在垃圾收集时使得用户线程和 GC 线程并发执行,因此在垃圾收集过程中用户也不会感到明显的卡顿
    - 初始标记:Stop The World,仅使用一条初始标记线程对所有与 GC Roots 直接关联的对象进行标记
    - 并发标记:使用**多条**标记线程,与用户线程并发执行,此过程进行可达性分析,标记出所有废弃对象,速度很慢
    - 重新标记:Stop The World,使用多条标记线程并发执行,将刚才并发标记过程中新出现的废弃对象标记出来
    - 并发清除:只使用一条 GC 线程,与用户线程并发执行,清除刚才标记的对象,这个过程非常耗时
- G1 通用垃圾收集器是一款面向服务端应用的垃圾收集器,它没有新生代和老年代的概念,而是将堆划分为一块块独立的 Region,当要进行垃圾收集时,首先估计每个 Region 中垃圾的数量,每次都从垃圾回收价值最大的 Region 开始回收,因此可以获得最大的回收效率
    - 从整体上看,G1 是基于"标记-整理”算法实现的收集器,从局部(两个 Region 之间)上看是基于"复制”算法实现的,这意味着运行期间不会产生内存空间碎片
    - 可以非常精确控制停顿时间,在不牺牲吞吐量前提下,实现低停顿垃圾回收
    - 如果不计算维护 Remembered Set 的操作,G1 收集器的工作过程分为以下几个步骤:
        - 初始标记:Stop The World,仅使用一条初始标记线程对所有与 GC Roots 直接关联的对象进行标记
        - 并发标记:使用**一条**标记线程与用户线程并发执行,此过程进行可达性分析,速度很慢
        - 最终标记:Stop The World,使用多条标记线程并发执行
        - 筛选回收:回收废弃对象,此时也要 Stop The World,并使用多条筛选回收线程并发执行

### 分代收集算法

根据对象存活周期的不同,将内存划分为几块,一般是把 Java 堆分为新生代和老年代,针对各个年代的特点采用最适当的收集算法

- 新生代:复制算法
- 老年代:标记-清除算法,标记-整理算法

### 可达性分析法

- 所有和 GC Roots 直接或间接关联的对象都是有效对象,和 GC Roots 没有关联的对象就是无效对象
- GC Roots 是指:
    - Java 虚拟机栈(栈帧中的本地变量表)中引用的对象
    - 本地方法栈中引用的对象
    - 方法区中常量引用的对象
    - 方法区中类静态属性引用的对象
- GC Roots 并不包括堆中对象所引用的对象,这样就不会有循环引用的问题

### 引用类型

- 强引用:类似`Object obj = new Object()`这类的引用,就是强引用
- 软引用:软引用是一种相对强引用弱化一些的引用,可以让对象豁免一些垃圾收集,只有当 JVM 认为内存不足时,才会去试图回收软引用指向的对象,JVM 会确保在抛出`OutOfMemoryError`之前,清理软引用指向的对象,软引用通常用来**实现内存敏感的缓存**,如果还有空闲内存,就可以暂时保留缓存,当内存不足时清理掉,这样就保证了使用缓存的同时,不会耗尽内存
- 弱引用:弱引用的**强度比软引用更弱**一些,当 JVM 进行垃圾回收时,**无论内存是否充足,都会回收**只被弱引用关联的对象
- 虚引用虚引用也称幽灵引用或者幻影引用,它是**最弱**的一种引用关系,一个对象是否有虚引用的存在,完全不会对其生存时间构成影响,它仅仅是提供了一种确保对象被 finalize 以后,做某些事情的机制,比如,通常用来做所谓的 Post-Mortem 清理机制

### 什么时候新生代会转换为老年代

- Eden区满时,进行Minor GC时
- 如果新创建的对象占用内存很大,则直接分配到老年代
- 虚拟机对每个对象定义了一个对象年龄(Age)计数器,当年龄增加到一定的临界值时,就会晋升到老年代中
- 如果在Survivor区中相同年龄的对象的所有大小之和超过Survivor空间的一半,包括比这个年龄大的对象就都可以直接进入老年代

### 新生代2个Survivor区的好处

解决了内存碎片化问题,整个过程中,永远有一个Survivor区是空的,另一个非空的Survivor区是无碎片的

### 遇到过OOM怎么解决

我们可以修改虚拟机的参数,获取Heap Dump的文件,后缀名是.hprof

```
-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=d:\jvm
```

之后可以使用JDK自带的一个工具jvisualvm来进行排查和定位

### 对象创建的过程

### 垃圾回收算法

### JVM内存结构

- Java 虚拟机的内存空间分为 5 个部分:
    - 程序计数器
    - Java 虚拟机栈
        - 存放基本变量类型(会包含这个基本类型的基本数值)
        - 引用对象的变量(会存放这个引用在堆里面的具体地址)
    - 本地方法栈
    - 堆
        - 存放new的对象和数组
        - 可以被所有的线程共享,不会存放别的对象引用
        - **方法区**(堆中特殊的区域)
            - 可以被所有的线程共享
            - 包含了所有的class和static变量
    - 方法区

<img src="https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-03-14-jvm-memory-structure.jpg" alt="jvm-memory-structure" style="zoom: 67%;" />

**注意**:JDK 1.8 同 JDK 1.7 比,最大的差别就是:元空间(元数据区)取代了永久代,元空间的本质和永久代类似,都是对 JVM 规范中方法区的实现,不过元空间与永久代之间最大的区别在于:元空间并不在虚拟机中,而是使用本地内存

### 类的加载过程

1. 加载:查找和导入Class文件
2. 校验:检查载入Class文件数据的正确性
3. 准备:给类的静态变量分配存储空间
4. 解析:将符号引用转成直接引用
5. 初始化:对类的静态变量,静态代码块执行初始化操作

> **什么时候会发生类初始化?**
>
> - **类的主动引用**(一定会发生类的初始化)
>     - 当虚拟机启动,先初始化main方法所在的类
>     - new一个类的对象
>     - 调用类的静态成员(除final常量)和静态方法
>     - 使用`java.lang.reflect`包的方法对类进行反射调用
>     - 当初始化一个类,如果其父类没有被初始化,则会先初始化它的父类
> - **类的被动引用**(不会发生类的初始化)
>     - 当访问一个静态域时,只有真正声明这个域的类才会被初始化,如:当通过子类引用父类的静态变量,不会导致子类初始化
>     - 通过数组定义类引用,不会触发此类的初始化
>     - 引用常量不会触发此类的初始化(常量在链接阶段就存入调用类的常量池中)

#### 加载class文件的原理机制

- 类的加载是由类加载器完成的,类加载器包括:根加载器(BootStrap),扩展加载器(Extension),系统加载器(System)和用户自定义类加载器(java.lang.ClassLoader的子类)
- 类加载过程采取了双亲委托机制,更好的保证了Java平台的安全性,在该机制中,JVM自带的Bootstrap是根加载器,其他的加载器都有且仅有一个父类加载器,类的加载首先请求父类加载器加载,父类加载器无能为力时才由其子类加载器自行加载,JVM不会向Java程序提供对Bootstrap的引用

> **说明**:
>
> Bootstrap:一般用本地代码实现,负责加载JVM基础核心类库(rt.jar)
> Extension:从java.ext.dirs系统属性所指定的目录中加载类库,它的父加载器是Bootstrap
> System:又叫应用类加载器,其父类是Extension,它是应用最广泛的类加载器,它从环境变量classpath或者系统属性java.class.path所指定的目录中记载类,是用户自定义加载器的默认父加载器

## Java SE

### int和Integer的区别

- int是基本数据类型,Integer是他的包装类
- Integer保存的是对象的引用,int保存的变量值
- Integer默认是null,int默认是0
- Integer变量必须实例化后才能使用,而int变量不需要

### Java的基本数据类型和大小

```
单位:字节
boolean(1) = byte(1) < short(2) = char(2) < int(4) = float(4) < long(8) = double(8)
```

### jar包冲突怎么解决

1. 使用`mvn: dependency tree`查看冲突的jar
2. 然后在pom文件里边  使用`exclusion`标签排除掉这些冲突的jar包

### 接口和抽象类的区别

1. 接口中所有的方法隐含的都是抽象的,而抽象类则可以同时包含抽象和非抽象的方法
2. 类可以实现很多个接口,但是只能继承一个抽象类
3. Java接口中声明的变量默认都是final的,抽象类可以包含非final的变量
4. Java接口中的成员函数默认是public的,抽象类的成员函数可以是private,protected或者是public
5. 抽象类和接口都不能够实例化,但可以定义抽象类和接口类型的引用
6. 一个类如果继承了某个抽象类或者实现了某个接口都需要对其中的抽象方法全部进行实现,否则该类仍然需要被声明为抽象类
7. 接口比抽象类更加抽象,因为抽象类中可以定义构造器,可以有抽象方法和具体方法,而接口中不能定义构造器而且其中的方法全部都是抽象方法
8. 抽象类中的成员可以是private,默认,protected,public的,而接口中的成员全都是public的,抽象类中可以定义成员变量,而接口中定义的成员变量实际上都是常量,有抽象方法的类必须被声明为抽象类,而抽象类未必要有抽象方法

### 异常

-   Error:是程序中无法处理的错误,表示运行应用程序中出现了严重的错误,此类错误一般表示代码运行时JVM出现问题,通常有Virtual MachineError(虚拟机运行错误),NoClassDefFoundError(类定义错误)等,比如说当jvm耗完可用内存时,将出现OutOfMemoryError,此类错误发生时,JVM将终止线程,非代码性错误,因此,当此类错误发生时,应用不应该去处理此类错误
-   Exception::程序本身可以捕获并且可以处理的异常
    -   运行时异常(不受检异常):RuntimeException类极其子类表示JVM在运行期间可能出现的错误,编译器不会检查此类异常,并且不要求处理异常,比如用空值对象的引用(NullPointerException),数组下标越界(ArrayIndexOutBoundException),此类异常属于不可查异常,一般是由程序逻辑错误引起的,在程序中可以选择捕获处理,也可以不处理
    -   非运行时异常(受检异常):Exception中除RuntimeException极其子类之外的异常,编译器会检查此类异常,如果程序中出现此类异常,比如说IOException,必须对该异常进行处理,要么使用try-catch捕获,要么使用throws语句抛出,否则编译不通过

### String和StringBuilder,StringBuffer的区别

Java平台提供了两种类型的字符串:String和StringBuffer/StringBuilder,它们可以储存和操作字符串,其中String是只读字符串,也就意味着String引用的字符串内容是不能被改变的,而StringBuffer/StringBuilder类表示的字符串对象可以直接进行修改,StringBuilder是Java 5中引入的,它和StringBuffer的方法完全相同,区别在于它是在单线程环境下使用的,因为它的所有方面都没有被synchronized修饰,因此它的效率也比StringBuffer要高

### 浅复制和深复制

- 如果在拷贝这个对象的时候,只对基本数据类型进行了拷贝,而对引用数据类型只是进行了引用的传递,而没有真实的创建一个新的对象,则认为是浅拷贝
- 反之,在对引用数据类型进行拷贝的时候,创建了一个新的对象,并且复制其内的成员变量,则认为是深拷贝

### 自动拆箱装箱

**自动装箱与自动拆箱的实现原理**

- 既然Java提供了自动拆装箱的能力,那么,我们就来看一下,到底是什么原理,Java是如何实现的自动拆装箱功能
- 自动拆装箱的代码:

```java
public static void main(String[]args){
  Integer integer=1; //装箱
  int i=integer; //拆箱
}
```

- 对以上代码进行反编译后可以得到以下代码:

```java
public static void main(String[]args){
  Integer integer=Integer.valueOf(1);
  int i=integer.intValue();
}
```

**哪些地方会自动拆装箱**

1. 将基本数据类型放入集合类
2. 包装类型和基本类型的大小比较:包装类与基本数据类型进行比较运算,是先将包装类进行拆箱成基本数据类型,然后进行比较的
3. 包装类型的运算:两个包装类型之间的运算,会被自动拆箱成基本类型进行
4. 三目运算符的使用:当第二,第三位操作数分别为基本类型和对象时,其中的对象就会拆箱为基本类型进行操作

### Object类的方法

-   clone() 创建并返回此对象的一个副本
-   equals(Object obj) 指示某个其他对象是否与此对象"相等”
-   finalize()当垃圾回收器确定不存在对该对象的更多引用时,由对象的垃圾回收器调用此方法
-   getClass()返回一个对象的运行时类
-   hashCode()返回该对象的哈希码值
-   notify()唤醒在此对象监视器上等待的单个线程
-   notifyAll()唤醒在此对象监视器上等待的所有线程
-   toString()返回该对象的字符串表示
-   wait()导致当前的线程等待,直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法
-   wait(long timeout)导致当前的线程等待,直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法,或者超过指定的时间量
-   wait(long timeout, int nanos) 导致当前的线程等待,直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法,或者其他某个线程中断当前线程,或者已超过某个实际时间量

### String为什么不可变

-   不可变对象是指一个对象的状态在对象被创建之后就不再变化,不可改变的意思就是说:不能改变对象内的成员变量,包括基本数据类型的值不能改变,引用类型的变量不能指向其他的对象,引用类型指向的对象的状态也不能改变
-   String 不可变是因为在 JDK 中 String 类被声明为一个 final 类,且类内部的 value 字节数组也是 final 的,只有当字符串是不可变时字符串池才有可能实现,字符串池的实现可以在运行时节约很多 heap 空间,因为不同的字符串变量都指向池中的同一个字符串

### 序列化与反序列化

- Java序列化是将一个对象编码成一个字节流,反序列化将字节流编码转换成一个对象,为了实现用户自定义的序列化,相应的类必须实现`Serializable`接口,`Serializable`接口中没有定义任何方法在,Java 中实现了 Serializable 接口后, JVM 会在底层帮我们实现序列化和反序列

### serialVersionUID 的作用

-   Java的序列化机制是通过在运行时判断类的serialVersionUID来验证版本一致性的,在进行反序列化时,JVM会把传来的字节流中的serialVersionUID与本地相应实体(类)的serialVersionUID进行比较,如果相同就认为是一致的,可以进行反序列化,否则就会出现序列化版本不一致的异常
-   如果不显示指定 serialVersionUID, JVM 在序列化时会根据属性自动生成一个 serialVersionUID, 然后与属性一起序列化, 再进行持久化或网络传输. 在反序列化时, JVM 会再根据属性自动生成一个新版 serialVersionUID, 然后将这个新版 serialVersionUID 与序列化时生成的旧版 serialVersionUID 进行比较, 如果相同则反序列化成功, 否则报错
-   如果显示指定了 serialVersionUID, JVM 在序列化和反序列化时仍然都会生成一个 serialVersionUID, 但值为我们显示指定的值, 这样在反序列化时新旧版本的 serialVersionUID 就一致了
-   当序列化了一个类实例后,希望更改一个字段或添加一个字段,不设置serialVersionUID,所做的任何更改都将导致无法反序化旧有实例,并在反序列化时抛出异常

### Java 值传递与引用传递

-   Java参数传递分为值传递和引用传递,基本类型是值传递,封装的对象时引用传递

### Statement和PreparedStatement的区别

- PreparedStatement接口代表预编译的语句,它主要的优势在于可以减少SQL的编译错误并增加SQL的安全性(减少SQL注射攻击的可能性)
- PreparedStatement中的SQL语句是可以带参数的,避免了用字符串连接拼接SQL语句的麻烦和不安全
- 当批量处理SQL或频繁执行相同的查询时,PreparedStatement有明显的性能上的优势,由于数据库可以将编译优化后的SQL语句缓存起来,下次执行相同结构的语句时就会很快(不用再次编译和生成执行计划)

### JDBC中Class.forName的作用

`Class.forName`方法的作用，就是初始化给定的类。而我们给定的 MySQL 的 Driver 类中，它在静态代码块中通过 JDBC 的 DriverManager 注册了一下驱动。我们也可以直接使用 JDBC 的驱动管理器注册 mysql 驱动，从而代替使用`Class.forName`

## Java EE

### forward与redirect

- **forward**:服务器请求资源,服务器直接访问目标地址的URL,把对应URL的响应内容读取过来,再发送给浏览器,所以URL不变,可以共享request的数据
- **redirect**:服务器发送一个状态码302,告诉浏览器重新去请求指定的地址,不能共享数据,地址栏显示的是新的URL

### Cookie与Session

1. cookie数据存放在客户的浏览器上,session数据放在服务器上
2. cookie不是很安全,别人可以分析存放在本地的cookie并进行cookie欺骗,考虑到安全应当使用session
3. session会在一定时间内保存在服务器上,当访问增多,会比较占用你服务器的性能,考虑到减轻服务器性能方面,应当使用cookie
4. 单个cookie保存的数据不能超过4K,很多浏览器都限制一个站点最多保存20个cookie
5. 可以考虑将登陆信息等重要信息存放为session,其他信息如果需要保留,可以放在cookie中

## 反射

### 获得一个类的类对象

1. 类名.class,例如:String.class
2. 对象.getClass(),例如:"hello".getClass()
3. Class.forName(),例如:Class.forName("java.lang.String")

### 通过反射创建对象

1. 通过类对象调用newInstance()方法,例如:String.class.newInstance()
2. 通过类对象的getConstructor()或getDeclaredConstructor()方法获得构造器(Constructor)对象并调用其newInstance()方法创建对象,例如:String.class.getConstructor(String.class).newInstance("Hello");

### 通过反射获取和设置对象私有字段的值

- 可以通过类对象的getDeclaredField()方法字段(Field)对象,然后再通过字段对象的setAccessible(true)将其设置为可以访问,接下来就可以通过get/set方法来获取/设置字段的值了

### 通过反射调用对象的方法

```java
import java.lang.reflect.Method;

class MethodInvokeTest {

  public static void main(String[] args) throws Exception {
    String str = "hello";
    Method m = str.getClass().getMethod("toUpperCase");
    System.out.println(m.invoke(str));  // HELLO
  }
}
```

## 多线程

### 线程的状态

**线程的状态**

- Java中线程的状态分为6种

  1. 初始(NEW):新创建了一个线程对象,但还没有调用start()方法
  2. 运行(RUNNABLE):Java线程中将就绪(ready)和运行中(running)两种状态笼统的称为"运行”
     线程对象创建后,其他线程(比如main线程)调用了该对象的start()方法,该状态的线程位于可运行线程池中,等待被线程调度选中,获取CPU的使用权,此时处于就绪状态(ready),就绪状态的线程在获得CPU时间片后变为运行中状态(running)
  3. 阻塞(BLOCKED):表示线程阻塞于锁
  4. 等待(WAITING):进入该状态的线程需要等待其他线程做出一些特定动作(通知或中断)
  5. 超时等待(TIMED_WAITING):该状态不同于WAITING,它可以在指定的时间后自行返回
  6. 终止(TERMINATED):表示该线程已经执行完毕
- 这6种状态定义在Thread类的State枚举中,可查看源码进行一一对应

**线程的状态图**

<img src="https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-14-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3BhbmdlMTk5MQ==,size_16,color_FFFFFF,t_70.jpeg" alt="线程状态图" style="zoom: 50%;" />

### 多线程的创建方式

- 继承Thread类
- 实现Runnable接口
- 实现Callable接口

### 线程有关的方法

- `Thread.sleep(long millis)`:一定是当前线程调用此方法,当前线程进入TIMED_WAITING状态,但不释放对象锁,millis后线程自动苏醒进入就绪状态
- `Thread.yield()`:一定是当前线程调用此方法,当前线程放弃获取的CPU时间片,但不释放锁资源,由运行状态变为就绪状态,让OS再次选择线程
- `thread.join()/thread.join(long millis)`:当前线程里调用其它线程t的join方法,当前线程进入`WAITING/TIMED_WAITING`状态,当前线程不会释放已经持有的对象锁,线程t执行完毕或者millis时间到,当前线程一般情况下进入RUNNABLE状态,也有可能进入BLOCKED状态(因为join是基于wait实现的)
- `obj.wait()`:当前线程调用对象的wait()方法,当前线程释放对象锁,进入等待队列,依靠notify()/notifyAll()唤醒或者wait(long timeout) timeout时间到自动唤醒
- `obj.notify()`:唤醒在此对象监视器上等待的单个线程,选择是任意性的
- `notifyAll()`:唤醒在此对象监视器上等待的所有线程

### wait方法的底层原理

- `ObjectSynchronizer::wait`方法通过object的对象中找到ObjectMonitor对象调用方法`void ObjectMonitor::wait(jlong millis, bool interruptible, TRAPS) `
- 通过`ObjectMonitor::AddWaiter`调用把新建立的`ObjectWaiter`对象放入到`_WaitSet`的队列的末尾中然后在`ObjectMonitor::exit`释放锁,接着 `thread_ParkEvent->park`也就是wait

### Lock锁与synchronized的区别

- Lock 能完成synchronized所实现的所有功能
- Lock可以知道是不是已经获取到锁,而synchronized无法知道
- Lock是显式锁(手动开启和关闭锁),synchronized是隐式锁,出了作用域自动释放
- Lock只有代码块锁,synchronized有代码块和方法锁
- Lock是一个接口,而synchronized是Java中的关键字,synchronized是内置的语言实现,synchronized在发生异常时,会自动释放线程占有的锁,因此不会导致死锁现象发生,而Lock在发生异常时,如果没有主动通过unLock()去释放锁,则很可能造成死锁现象,因此使用Lock时需要在finally块中释放锁

### CAS是一种什么样的同步机制？

-  CAS,是Compare and Swap的简称,在这个机制中有三个核心的参数:
- 主内存中存放的共享变量的值:V(一般情况下这个V是内存的地址值,通过这个地址可以获得内存中的值)
- 工作内存中共享变量的副本值,也叫预期值:A
- 需要将共享变量更新到的最新值:B

### 如何实现主线程等待子线程执行完后再继续执行？

1. 可以使用join方法,在主线程内部调用子线程.join方法
2. CountDownLatch实现
   - await()方法阻塞当前线程,直到计数器等于0
   - countDown()方法将计数器减一
3. 思路:我们可以在创建CountDownLatch对象,然后将此对象通过构造参数传递给子线程,在开启子线程后主线程调用await()方法阻塞主线程,子线程调用countDown()方法计数器减一

### cyclicbarrier与countdownlatch区别

- CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后,它才执行
- CyclicBarrier一般用于一组线程互相等待至某个状态,然后这一组线程再同时执行
- CountDownLatch是不能够重用的,而CyclicBarrier是可以重用的

### 多线程回调

所谓回调,就是客户程序C调用服务程序S中的某个方法A,然后S又在某个时候反过来调用C中的某个方法B,对于C来说,这个B方法便叫做回调方法框架

### 公平锁与非公平锁

如果一个锁是公平的,那么锁的获取顺序就应该符合请求的绝对时间顺序FIFO,对于非公平锁,只要CAS设置同步状态成功,则表示当前线程获取了锁,而公平锁还需要判断当前节点是否有前驱节点,如果有,则表示有线程比当前线程更早请求获取锁,因此需要等待前驱线程获取并释放锁之后才能继续获取锁

### AQS

Java中的锁,可以分为Synchronized,AQS这两类

- Synchronized是隐式锁,通过内部对象Monitor(监控器锁)实现,具体是由JVM中C++代码实现,它有一个同步队列,一个等待队列
- AQS是显示锁,通过CAS,LockSurpport,CLH 双向链表实现,是由java代码实现,它有一个同步队列,多个等待队列,当使用Condition的时候,调用condition的await方法,将会使当前线程进入等待队列,等待队列的唤醒是调用condition的signal方法,而AQS可以设置多个Condition,也就有了多个等待队列
- AQS的同步队列和等待队列如下图:

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-06-20-watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xpc2hlbmc1MjE4,size_16,color_FFFFFF,t_70.png)

### 原子性,可见性,有序性

- **原子性**:能够保证同一时刻有且只有一个线程在操作共享数据,其他线程必须等该线程处理完数据后才能进行
- **可见性**:当一个线程在修改共享数据时,其他线程能够看到
- **有序性**:在Java中,JVM能够根据处理器特性(CPU多级缓存系统,多核处理器等)适当对机器指令进行重排序,最大限度发挥机器性能,Java中的指令重排序有两次,第一次发生在将字节码编译成机器码的阶段,第二次发生在CPU执行的时候,也会适当对指令进行重排

### JMM

- Java虚拟机规范中定义了一种Java内存模型(Java Memory Model,即JMM)来屏蔽掉各种硬件和操作系统的内存访问差异,以实现让Java程序在各种平台下都能达到一致的并发效果,Java内存模型的主要目标就是**定义程序中各个变量的访问规则,即在虚拟机中将变量存储到内存和从内存中取出变量这样的细节**
- JMM中规定所有的变量都存储在主内存(Main Memory)中,每条线程都有自己的工作内存(Work Memory),线程的工作内存中保存了该线程所使用的变量的从主内存中拷贝的副本,线程对于变量的读,写都必须在工作内存中进行,而不能直接读,写主内存中的变量,同时,本线程的工作内存的变量也无法被其他线程直接访问,必须通过主内存完成
- 关于主内存与工作内存之间的具体交互协议,即一个变量如何从主内存拷贝到工作内存,如何从工作内存同步到主内存之间的实现细节,Java内存模型定义了以下八种操作来完成:
    1. **lock(锁定)**:作用于主内存的变量,把一个变量标识为一条线程独占状态
    2. **unlock(解锁)**:作用于主内存变量,把一个处于锁定状态的变量释放出来,释放后的变量才可以被其他线程锁定
    3. **read(读取)**:作用于主内存变量,把一个变量值从主内存传输到线程的工作内存中,以便随后的load动作使用
    4. **load(载入)**:作用于工作内存的变量,它把read操作从主内存中得到的变量值放入工作内存的变量副本中
    5. **use(使用)**:作用于工作内存的变量,把工作内存中的一个变量值传递给执行引擎,每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作
    6. **assign(赋值)**:作用于工作内存的变量,它把一个从执行引擎接收到的值赋值给工作内存的变量,每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作
    7. **store(存储)**:作用于工作内存的变量,把工作内存中的一个变量的值传送到主内存中,以便随后的write的操作
    8. **write(写入)**:作用于主内存的变量,它把store操作从工作内存中一个变量的值传送到主内存的变量中

### volatile

- volatile关键字是用来保证有序性和可见性的
- **有序性**:`volatile`是通过编译器在生成字节码时,在指令序列中添加**内存屏障**来禁止指令重排序的
- 当对volatile变量执行写操作后,JMM会把工作内存中的最新变量值强制刷新到主内存写操作会导致其他线程中的缓存无效这样,其他线程使用缓存时,发现本地工作内存中此变量无效,便从主内存中获取,这样获取到的变量便是最新的值,实现了线程的可见性

### synchronize底层是怎么实现的

- synchronize是java中的关键字,可以用来修饰实例方法,静态方法,还有代码块,主要有三种作用:可以确保原子性,可见性,有序性
- synchronized的底层原理是跟monitor有关,也就是视图器锁,每个对象都有一个关联的monitor,当Synchronize获得monitor对象的所有权后会进行两个指令:加锁指令跟减锁指令
- monitor里面有个计数器,初始值是从0开始的,如果一个线程想要获取monitor的所有权,就看看它的计数器是不是0,如果是0的话,那么就说明没人获取锁,那么它就可以获取锁了,然后将计数器+1,也就是执行monitorenter加锁指令,monitorexit减锁指令是跟在程序执行结束和异常里的,如果不是0的话,就会陷入一个堵塞等待的过程,直到为0等待结束

- `synchronized`是同步锁,同步块内的代码相当于同一时刻单线程执行,故不存在原子性和指令重排序的问题

### 线程池

- 线程池顾名思义就是事先创建若干个可执行的线程放入一个池(容器)中,需要的时候从池中获取线程不用自行创建,使用完毕不需要销毁线程而是放回池中,从而减少创建和销毁线程对象的开销
- 使用线程池可以降低资源消耗,提高响应速度,提高线程的可管理性,提供更多更强大的功能

#### 主要参数

- 线程池核心线程数大小
- 最大线程数
    1. CPU 密集型:最大线程数等于本机CPU线程数,可以保持CPU的效率最高`Runtime.getRuntime().availableProcessors()`
    2. IO 密集型:最大线程数大于 > 判断你程序中十分耗IO的线程,应为IO会导致线程阻塞
- 空闲线程存活时长
- 时间单位
- 阻塞队列
- 线程工厂
- 拒绝策略

#### 运行流程

- 当需要任务大于核心线程数时候,就开始把任务往存储任务的队列里,当存储队列满了的话,就开始增加线程池创建的线程数量,如果当线程数量也达到了最大,就开始执行拒绝策略,比如说记录日志,直接丢弃,或者丢弃最老的任务,或者交给提交任务的线程执行
- 当一个线程完成时,它会从队列中取下一个任务来执行,当一个线程无事可做,且超过一定的时间(keepAliveTime)时,如果当前运行的线程数大于核心线程数,那么这个线程会停掉了

#### 线程池种类

- `Executors`:工具类,线程池的工厂类,用于创建并返回不同类型的线程池,本质上是调用ThreadPoolExecutor的构造方法
    - newFixedThreadPool创建一个指定大小的线程池,每当提交一个任务就创建一个线程,如果工作线程数量达到线程池初始的最大数,则将提交的任务存入到等待队列中
    - newCachedThreadPool创建一个可缓存的线程池,这种类型的线程池特点是:
        - 工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger. MAX_VALUE), 这样可灵活的往线程池中添加线程
        - 如果长时间没有往线程池中提交任务,即如果工作线程空闲了指定的时间(默认为1分钟),则该工作线程将自动终止,终止后,如果你又提交了新的任务,则线程池重新创建一个工作线程
    - newSingleThreadExecutor创建一个单线程的Executor,即只创建唯一的工作者线程来执行任务,如果这个线程异常结束,会有另一个取代它,保证顺序执行
    - newScheduleThreadPool创建一个定长的线程池,而且支持定时的以及周期性的任务执行,类似于Timer

#### 线程池的submit和execute的区别

**execute提交的方式**

execute提交的方式只能提交一个Runnable的对象,且该方法的返回值是void,也即是提交后如果线程运行后,和主线程就脱离了关系了,当然可以设置一些变量来获取到线程的运行结果,并且当线程的执行过程中抛出了异常通常来说主线程也无法获取到异常的信息的,只有通过ThreadFactory主动设置线程的异常处理类才能感知到提交的线程中的异常信息

**submit提交的方式**

- submit提交的方式有如下三种情况

```java
<T> Future<T> submit(Callable<T> task);
```

- 这种提交的方式是提交一个实现了Callable接口的对象,这种提交的方式会返回一个Future对象,这个Future对象代表这线程的执行结果
- 当主线程调用Future的get方法的时候会获取到从线程中返回的结果数据
- 如果在线程的执行过程中发生了异常,get会获取到异常的信息

```java
Future<?> submit(Runnable task);
```

- 也可以提交一个Runable接口的对象,这样当调用get方法的时候,如果线程执行成功会直接返回null,如果线程执行异常会返回异常的信息

```java
<T> Future<T> submit(Runnable task, T result);
```

- 这种方式除了task之外还有一个result对象,当线程正常结束的时候调用Future的get方法会返回result对象,当线程抛出异常的时候会获取到对应的异常的信息

### ThreadLocal原理

### 多线程按顺序执行

### 解决死锁

1.  使用`jps -l`定位进程号
2.  使用`jstack`进程号,找到死锁问题并解决

## 集合

### List,Set,Map的区别

- List有序存取元素,可以有重复元素
- Set不能存放重复元素,存入的元素是无序的
- Map保存键值对映射,映射关系可以是一对一或多对一

### HashMap,Hashtable,HashSet,LinkedHashMap 和 TreeMap 比较

- Hashmap 是一个最常用的 Map,它根据键的 HashCode 值存储数据,根据键可以直接获取它的值,具有很快的访问速度,遍历时,取得数据的顺序是完全随机的,HashMap 最多只允许一条记录的键为Null,允许多条记录的值为 Null
- Hashtable 与 HashMap 类似,不同的是:它不允许记录的键或者值为空,它支持线程的同步,即任一时刻只有一个线程能写 Hashtable,因此也导致了 Hashtale 在写入时会比较慢
- HashSet 是一个没有重复元素的集合,它是由 HashMap 实现的,不保证元素的顺序 (这里所说的没有顺序是指:元素插入的顺序与输出的顺序不一致),而且 HashSet 允许使用 null 元素
- LinkedHashMap 是 HashMap 的一个子类,如果需要输出的顺序和输入的相同,那么用 LinkedHashMap 可以实现,它还可以按读取顺序来排列,像连接池中可以应用
    - LinkedHashMap 实现与 HashMap 的不同之处在于,后者维护着一个运行于所有条目的双重链表,此链接列表定义了迭代顺序,该迭代顺序可以是插入顺序或者是访问顺序,对于 LinkedHashMap 而言,它继承与 HashMap,底层使用哈希表与双向链表来保存所有元素,其基本操作与父类 HashMap 相似,它通过重写父类相关的方法,来实现自己的链接列表特性
- TreeMap 实现 SortMap 接口,内部实现是红黑树,能够把它保存的记录根据键排序,默认是按键值的升序排序,也可以指定排序的比较器,当用 Iterator 遍历 TreeMap 时,得到的记录是排过序的,TreeMap 不允许 key 的值为 null,非同步的

### 请说说快速失败(fail-fast)和安全失败(fail-safe)的区别？

Iterator的安全失败是基于对底层集合做拷贝,因此,它不受源集合上修改的影响,java.util包下面的所有的集合类都是快速失败的,而java.util.concurrent包下面的所有的类都是安全失败的,快速失败的迭代器会抛出ConcurrentModificationException异常,而安全失败的迭代器永远不会抛出这样的异常

### 红黑树

一种二叉查找树,但在每个节点增加一个存储位表示节点的颜色,可以是红或黑(非红即黑),通过对任何一条从根到叶子的路径上各个节点着色的方式的限制,红黑树确保没有一条路径会比其它路径长出两倍,因此,红黑树是一种弱平衡二叉树(由于是弱平衡,可以看到,在相同的节点情况下,AVL树的高度低于红黑树),相对于要求严格的AVL树来说,它的旋转次数少,所以对于搜索,插入,删除操作较多的情况下,我们就用红黑树


1. 每个节点要么是红色,要么是黑色
2. 根节点永远是黑色的
3. 所有的叶节点都是空节点(即 null),并且是黑色的
4. 每个红色节点的两个子节点都是黑色,(从每个叶子到根的路径上不会有两个连续的红色节点)
5. 从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点

### 重写 equals 和 hashCode

1. 作为`key`的对象必须正确覆写`equals()`方法,相等的两个`key`实例调用`equals()`必须返回`true`
2. 作为`key`的对象还必须正确覆写`hashCode()`方法,因为通过`key`计算索引的方式就是调用`key`对象的`hashCode()`方法,它返回一个`int`整数,`HashMap`正是通过这个方法直接定位`key`对应的`value`的索引,继而直接返回`value`,且`hashCode()`方法要严格遵循以下规范:
   - 如果两个对象相等,则两个对象的`hashCode()`必须相等
   - 如果两个对象不相等,则两个对象的`hashCode()`尽量不要相等
3. 即对应两个实例`a`和`b`:
   - 如果`a`和`b`相等,那么`a.equals(b)`一定为`true`,则`a.hashCode()`必须等于`b.hashCode()`
   - 如果`a`和`b`不相等,那么`a.equals(b)`一定为`false`,则`a.hashCode()`和`b.hashCode()`尽量不要相等

### TreeMap和TreeSet在排序时如何比较元素？Collections工具类中的sort()方法如何比较元素？

TreeSet要求存放的对象所属的类必须实现Comparable接口,该接口提供了比较元素的compareTo()方法,当插入元素时会回调该方法比较元素的大小,TreeMap要求存放的键值对映射的键必须实现Comparable接口从而根据键对元素进行排序,Collections工具类的sort方法有两种重载的形式,第一种要求传入的待排序容器中存放的对象比较实现Comparable接口以实现元素的比较,第二种不强制性的要求容器中的元素必须可比较,但是要求传入第二个参数,参数是Comparator接口的子类型(需要重写compare方法实现元素的比较),相当于一个临时定义的排序规则,其实就是通过接口注入比较元素大小的算法,也是对回调模式的应用(Java中对函数式编程的支持)

### 阐述ArrayList,Vector,LinkedList的存储性能和特性

ArrayList 和Vector都是使用数组方式存储数据,此数组元素数大于实际存储的数据以便增加和插入元素,它们都允许直接按序号索引元素,但是插入元素要涉及数组元素移动等内存操作,所以索引数据快而插入数据慢,Vector中的方法由于添加了synchronized修饰,因此Vector是线程安全的容器,但性能上较ArrayList差,因此已经是Java中的遗留容器,LinkedList使用双向链表实现存储(将内存中零散的内存单元通过附加的引用关联起来,形成一个可以按序号索引的线性结构,这种链式存储方式与数组的连续存储方式相比,内存的利用率更高),按序号索引数据需要进行前向或后向遍历,但是插入数据时只需要记录本项的前后项即可,所以插入速度较快,Vector属于遗留容器(Java早期的版本中提供的容器,除此之外,Hashtable,Dictionary,BitSet,Stack,Properties都是遗留容器),已经不推荐使用,但是由于ArrayList和LinkedListed都是非线程安全的,如果遇到多个线程操作同一个容器的场景,则可以通过工具类Collections中的synchronizedList方法将其转换成线程安全的容器后再使用(这是对装潢模式的应用,将已有对象传入另一个类的构造器中创建新的对象来增强实现)

### ArrayList和LinkedList的区别

- ArrayList和LinkedList都实现了List接口,他们有以下的不同点:
- ArrayList是基于索引的数据接口,它的底层是数组,它可以以O(1)时间复杂度对元素进行随机访问,与此对应,LinkedList是以元素列表的形式存储它的数据,每一个元素都和它的前一个和后一个元素链接在一起,在这种情况下,查找某个元素的时间复杂度是O(n)
- 相对于ArrayList,LinkedList的插入,添加,删除操作速度更快,因为当元素被添加到集合任意位置的时候,不需要像数组那样重新计算大小或者是更新索引
- LinkedList比ArrayList更占内存,因为LinkedList为每一个节点存储了两个引用,一个指向前一个元素,一个指向下一个元素

### Iterator和ListIterator

- Iterator提供了统一遍历操作集合元素的统一接口, Collection接口实现Iterable接口,
    每个集合都通过实现Iterable接口中iterator()方法返回Iterator接口的实例, 然后对集合的元素进行迭代操作

**Iterator和ListIterator的区别**

- Iterator可用来遍历Set和List集合,但是ListIterator只能用来遍历List
- Iterator对集合只能是前向遍历,ListIterator既可以前向也可以后向
- ListIterator实现了Iterator接口,并包含其他的功能,比如:增加元素,替换元素,获取前一个和后一个元素的索引,等等

### HashMap

- HashMap基于哈希表的Map接口实现,是以key-value存锗形式存在,即主要用来存放键值对,HashMap的实现不是同步的,这意味着它不是线程安全的,它的key,value都可以为null,此外,HashMap中的映射不是有序的
- jdk1.8之前HashMap由数组+链表组成的,数组是HashMap的主体,链表则是主要为了解决哈希冲突(两个对象调用的hashCode方法计算的哈希值一致导致计算的教组索引值相同)而存在的("拉链法”解决冲突)
- jdk1.8以后在解决哈希冲突时有了较大的变化,当链表长度大于阈值(或者红黑树的边界值,默认为8)并且当前数组的长度大于64时,此时此索引位置上的所有数据改为使用红黑树存储
- **补充**:将链表转换成红黑树前会判断,即便阈值大于8,但是数组长度小于64,此时并不会将链表变为红黑树,而是选择逬行数组扩容
- 这样做的目的是因为数组比较小,尽量避开红黑树结构,这种情况下变为红黑树结构,反而会降低效率,因为红黑树需要逬行左旋,右旋,变色这些操作来保持平衡,同时数组长度小于64时,搜索时间相对要快些,所以结上所述为了提高性能和减少搜索时间,底层阈值大于8并且数组长度大于64时,链表才转换为红黑树,具体可以参考 **treeifyBin() 方法,**
- 当然虽然增了红黑树作为底层数据结构,结构变得复杂了,但是阈值大于8并且数组长度大于64时,链表转换为红黑树时,效率也变的更高
- 使用HashMap,如果key是自定义的类,就必须重写hashcode()和equals()
- **HashMap的扩容机制**:HashMap底层是数组,在第一次put的时候会初始化,发生第一次扩容到16,它有一个负载因子是0.75,下一次扩容的时候就是当前数组大小*0.75,扩大容量为原来的2倍

### ConcurrentHashMap

-   Concurrenthashmap是线程安全的

-   JDK1.7

    -   采用Segment + HashEntry的方式进行实现的,Segment 类继承于 ReentrantLock 类,从而使得 Segment 对象能充当锁的角色,每个 Segment 对象用来守护其(成员对象 table 中)包含的若干个桶
    -   size的计算是先采用不加锁的方式,连续计算元素的个数,最多计算3次:
        1.  如果前后两次计算结果相同,则说明计算出来的元素个数是准确的
        2.  如果前后两次计算结果都不同,则给每个Segment进行加锁,再计算一次元素的个数

    -   ConcurrentHashMap 类中包含两个静态内部类 HashEntry 和 Segment,HashEntry 用来封装映射表的键 / 值对,Segment 用来充当锁的角色,每个 Segment 对象守护整个散列映射表的若干个桶,每个桶是由若干个 HashEntry 对象链接起来的链表,一个 ConcurrentHashMap 实例中包含由若干个 Segment 对象组成的数组,HashEntry 用来封装散列映射表中的键值对,在 HashEntry 类中,key,hash 和 next 域都被声明为 final 型,value 域被声明为 volatile 型
    -   在ConcurrentHashMap 中,在散列时如果产生"碰撞”,将采用"分离链接法”来处理"碰撞”:把"碰撞”的 HashEntry 对象链接成一个链表,由于 HashEntry 的 next 域为 final 型,所以新节点只能在链表的表头处插入,由于只能在表头插入,所以链表中节点的顺序和插入的顺序相反

-   JDK1.8

    -   放弃了Segment臃肿的设计,取而代之的是采用Node + CAS + Synchronized来保证并发安全进行实现
    -   使用一个volatile类型的变量baseCount记录元素的个数,当插入新数据或则删除数据时,会通过addCount()方法更新baseCount,通过累加baseCount和CounterCell数组中的数量,即可得到元素的总个数

## 设计模式

### DCL为什么要用volatile关键字？

先看一下DCL(双重检查锁模式)的示例代码:

```java
public class Singleton {
  //Singleton对象属性,加上volatile关键字是为了防止指定重排序,要知道singleton = new Singleton()拆分成cpu指令的话,有足足3个步骤
  private volatile static Singleton singleton;

  //对外提供的获取实例的方法
  public static Singleton getInstance() {
    if (singleton == null) {
      synchronized (Singleton.class) {
        if (singleton == null) {
          singleton = new Singleton();
        }
      }
    }
    return singleton;
  }
}
```

从代码里可以看到,做了两重的singleton == null的判断,中间还用了synchronized关键字,第一个singleton == null的判断是为了避免线程串行化,如果为空,就进入synchronized代码块中,获取锁后再操作,如果不为空,直接就返回singleton对象了,无需再进行锁竞争和等待了,而第二个singleton == null的判断是为了防止有多个线程同时跳过第一个singleton == null的判断,比如线程一先获取到锁,进入同步代码块中,发现singleton实例还是null,就会做new操作,然后退出同步代码块并释放锁,这时一起跳过第一层singleton == null的判断的还有线程二,这时线程一释放了锁,线程二就会获取到锁,如果没有第二层的singleton == null这个判断挡着,那就会再创建一个singleton实例,就违反了单例的约束了

**总结**:DCL使用volatile关键字,是为了禁止指令重排序,避免返回还没完成初始化的singleton对象,导致调用报错,也保证了线程的安全

## Spring

### AOP

- AOP指面向切面编程,用于处理系统中分布于各个模块的横切关注点,把那些与业务无关,但是却为业务模块所共同调用的逻辑部分封装起来,从而使得业务逻辑各部分之间的耦合度降低, 提高程序的可重用性, 同时提高了开发的效率
- AOP实现的关键在于AOP框架自动创建的AOP代理,AOP代理主要分为静态代理和动态代理,静态代理的代表为AspectJ,而动态代理则以Spring AOP为代表
    - 通常使用AspectJ的编译时增强实现AOP,AspectJ是静态代理的增强,所谓的静态代理就是AOP框架会在编译阶段生成AOP代理类,因此也称为编译时增强
    - Spring AOP中的动态代理主要有两种方式,JDK动态代理和CGLIB动态代理,JDK动态代理通过反射来接收被代理的类,并且要求被代理的类必须实现一个接口,JDK动态代理的核心是InvocationHandler接口和Proxy类
- 在AOP编程中,我们经常会遇到下面的概念:
    - Joinpoint:连接点,即定义在应用程序流程的何处插入切面的执行
    - Pointcut:切入点,即一组连接点的集合
    - Advice:增强,指特定连接点上执行的动作
    - Introduction:引介,特殊的增强,指为一个已有的Java对象动态地增加新的接口
    - Weaving:织入,将增强添加到目标类具体连接点上的过程
    - Aspect:切面,由切点和增强(引介)组成,包括了对横切关注功能的定义,已包括了对连接点的定义

### IoC

- 控制反转,是把传统上由程序代码直接操控的对象的调用权交给容器,由容器来创建对象并管理对象之间的依赖关系,DI是对IoC更准确的描述,即由容器动态的将某种依赖关系注入到组件之中

- **IoC的原理**

    1. 定义用来描述bean的配置的Java类或配置文件
    2. 解析bean的配置,将bean的配置信息转换为的BeanDefinition对象保存在内存中,spring中采用HashMap进行对象存储,其中会用到一些xml解析技术

    - 遍历存放BeanDefinition的HashMap对象,逐条取出BeanDefinition对象,获取bean的配置信息,利用Java的反射机制实例化对象,将实例化后的对象保存在另外一个Map中

### DI

- 依赖注入的方式有以下几种:
    - @Autowired,@Resource
    - Setter方法注入
    - p命名空间和c命名空间注入
    - 构造器注入
    - 自动装配
    - 工厂模式的方法注入
- @Autowired 和@Resource区别
    - @Autowired注解是按照类型(byType)装配依赖对象,当有且仅有一个匹配的Bean时,Spring将其注入@Autowired标注的变量中,如果我们想使用按照名称(byName)来装配,可以结合@Qualifier注解一起使用
    - @Resource默认按照ByName自动注入,@Resource有两个重要的属性:name和type,而Spring将@Resource注解的name属性解析为bean的名字,而type属性则解析为bean的类型,所以,如果使用name属性,则使用byName的自动注入策略,而使用type属性时则使用byType自动注入策略,如果既不制定name也不制定type属性,这时将通过反射机制使用byName自动注入策略

### Bean作用域

- 在Spring的早期版本中仅有两个作用域:singleton和prototype,前者表示Bean以单例的方式存在,后者表示每次从容器中调用Bean时,都会返回一个新的实例
- Spring2.x中针对WebApplicationContext新增了3个作用域,分别是:request(每次HTTP请求都会创建一个新的Bean), session(同一个HttpSession共享同一个Beaan,不同的HttpSession使用不同的Bean)和globalSession(同一个全局Session共享一个Bean)

### Bean的生命周期

Spring生命周期流程图

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-21-308572_1537967995043_4D7CF33471A392D943F00167D1C86C10.png)

### Spring ApplicationContext 容器

- **Application Context** :是BeanFactory的子类,因为古老的BeanFactory无法满足不断更新的spring的需求,于是ApplicationContext就基本上代替了BeanFactory的工作,它可以加载配置文件中定义的 bean,将所有的 bean 集中在一起,当有请求的时候分配 bean
- 最常被使用的 ApplicationContext 接口实现:
    - **FileSystemXmlApplicationContext**:该容器从 XML 文件中加载已被定义的 bean,在这里,你需要提供给构造器 XML 文件的完整路径
    - **ClassPathXmlApplicationContext**:该容器从 XML 文件中加载已被定义的 bean,在这里,你不需要提供 XML 文件的完整路径,只需正确配置 CLASSPATH 环境变量即可,因为,容器会从 CLASSPATH 中搜索 bean 配置文件
    - **WebXmlApplicationContext**:该容器会在一个 web 应用程序的范围内加载在 XML 文件中已被定义的 bean

### Spring 事务

- 事务属性可以理解成事务的一些基本配置,描述了事务策略如何应用到方法上,事务属性包含了5个方面:传播行为,隔离规则,回滚规则,事务超时,是否只读
- 并发状态下可能产生:　脏读,不可重复读,幻读的情况,因此我们需要将事务与事务之间隔离,Spring中定义了五种隔离规则:数据库默认,读未提交,读已提交,可重复读,序列化
- 当事务方法被另一个事务方法调用时,必须指定事务应该如何传播,Spring定义了七种传播行为:默认的事务传播行为是`PROPAGATION_REQUIRED`, 它适合于绝大多数的情况:如果当前没有事务,就新建一个事务,如果已经存在一个事务,则加入到这个事务中,这是最常见的选择

### Springmvc的执行流程

1. `DispatcherServlet`表示前置控制器,是整个Spring MVC的控制中心,用户发出请求,`DispatcherServlet`接收请求并拦截请求
2. `HandlerMapping`为处理器映射,`DispatcherServlet`调用`HandlerMapping`,`HandlerMapping`根据请求url查找`Handler`
3. `HandlerExecution`表示具体的Handler,其主要作用是根据url查找Controller
4. `HandlerExecution`将解析后的信息传递给`DispatcherServlet`,如解析Controller映射等
5. `HandlerAdapter`表示处理器适配器,其按照特定的规则去执行`Handler`
6. `Handler`让具体的Controller执行
7. Controller将具体的执行信息返回给`HandlerAdapter`,如ModelAndView
8. `HandlerAdapter`将逻辑视图或模型传递给`DispatcherServlet`
9. `DispatcherServlet`调用`ViewResolver`将逻辑视图解析为真实视图对象
10. `ViewResolver`将解析的真实视图对象返回`DispatcherServlet`
11. `DispatcherServlet`利用是土地向对模型数据进行渲染
12. 最终视图呈现给客户端

### SpringMVC的常用注解

- `@Component`:会被spring容器识别,并转为bean
- `@Repository`:对Dao实现类进行注解
- `@Service`:对业务逻辑层进行注解
- `@Controller`:表明这个类是Spring MVC里的Controller,将其声明为Spring的一个Bean,Dispatch Servlet会自动扫描注解了此注解的类,并将Web请求映射到注解了@RequestMapping的方法上
- `@RequestMapping`:用来映射Web请求(访问路径和参数),处理类和方法的,它可以注解在类和方法上,注解在方法上的@RequestMapping路径会继承注解在类上的路径
- `@RequestBody`:可以将整个返回结果以某种格式返回,如json或xml格式
- `@PathVariable`:用来接收路径参数,如/news/001,可接收001作为参数,此注解放置在参数前
- `@RequestParam`:用于获取传入参数的值
- `@RestController`:是一个组合注解,组合了@Controller和@ResponseBody,意味着当只开发一个和页面交互数据的控制的时候,需要使用此注解

### Spring MVC将数据存储到session

一般都是使用Servlet-Api,在处理请求的方法参数列表中,添加一个HTTPSession对象,之后SpringMVC就可以自动注入进来了,在方法体中调用session.setAttribute就可以了

### 过滤器和拦截器的区别

1. 拦截器是基于java的反射机制的,而过滤器是基于函数回调
2. 拦截器不依赖servlet容器,过滤器依赖servlet容器
3. 拦截器只能对action请求起作用,而过滤器则可以对几乎所有的请求起作用
4. 拦截器可以访问action上下文,值栈里的对象,而过滤器不能访问
5. 在action的生命周期中,拦截器可以多次被调用,而过滤器只能在容器初始化时被调用一次
6. 拦截器可以获取IOC容器中的各个bean,而过滤器就不行,这点很重要,在拦截器里注入一个service,可以调用业务逻辑

### Spring拦截器的执行顺序

Springmvc的拦截器实现HandlerInterceptor接口后,会有三个抽象方法需要实现,分别为方法前执行preHandle,方法后postHandle,页面渲染后afterCompletion

1. 当俩个拦截器都实现放行操作时,顺序为preHandle 1,preHandle 2,postHandle 2,postHandle 1,afterCompletion 2,afterCompletion 1
2. 当第一个拦截器preHandle返回false,也就是对其进行拦截时,第二个拦截器是完全不执行的,第一个拦截器只执行preHandle部分
3. 当第一个拦截器preHandle返回true,第二个拦截器preHandle返回false,顺序为preHandle 1,preHandle 2,afterCompletion 1

总结:

```
preHandle 按拦截器定义顺序调用
postHandler 按拦截器定义逆序调用
afterCompletion 按拦截器定义逆序调用
postHandler 在拦截器链内所有拦截器返成功调用
afterCompletion 只有preHandle返回true才调用
```

### SpringBootApplication的加载过程

### Spring Security 原理

**过滤器**

- Spring Security 基本都是通过过滤器来完成配置的身份认证,权限认证以及登出
- Spring Security 在 Servlet 的过滤链(filter chain)中注册了一个过滤器 `FilterChainProxy`,它会把请求代理到 Spring Security 自己维护的多个过滤链,每个过滤链会匹配一些 URL,如果匹配则执行对应的过滤器,过滤链是有顺序的,一个请求只会执行第一条匹配的过滤链,Spring Security 的配置本质上就是新增,删除,修改过滤器
- 默认情况下系统帮我们注入的这 15 个过滤器,分别对应配置不同的需求,接下来我们重点是分析下 `UsernamePasswordAuthenticationFilter` 这个过滤器,他是用来使用用户名和密码登录认证的过滤器,但是很多情况下我们的登录不止是简单的用户名和密码,又可能是用到第三方授权登录,这个时候我们就需要使用自定义过滤器,当然这里不做详细说明,只是说下自定义过滤器怎么注入

```java
@Override
protected void configure(HttpSecurity http) throws Exception {

  http.addFilterAfter(...);
  ...
}
```

**身份认证流程**

在开始身份认证流程之前我们需要了解下几个基本概念

**SecurityContextHolder**

`SecurityContextHolder` 存储 `SecurityContext` 对象,`SecurityContextHolder` 是一个存储代理,有三种存储模式分别是:

- MODE_THREADLOCAL:SecurityContext 存储在线程中
- MODE_INHERITABLETHREADLOCAL:`SecurityContext` 存储在线程中,但子线程可以获取到父线程中的 `SecurityContext`
- MODE_GLOBAL:`SecurityContext` 在所有线程中都相同

`SecurityContextHolder` 默认使用 MODE_THREADLOCAL 模式,`SecurityContext` 存储在当前线程中,调用 `SecurityContextHolder` 时不需要显示的参数传递,在当前线程中可以直接获取到 `SecurityContextHolder` 对象

```java
//获取当前线程里面认证的对象
SecurityContext context = SecurityContextHolder.getContext();
Authentication authentication = context.getAuthentication();

//保存认证对象 (一般用于自定义认证成功保存认证对象)
SecurityContextHolder.getContext().setAuthentication(authResult);

//清空认证对象 (一般用于自定义登出清空认证对象)
SecurityContextHolder.clearContext();
```

**2.Authentication**

`Authentication` 即验证,表明当前用户是谁,什么是验证,比如一组用户名和密码就是验证,当然错误的用户名和密码也是验证,只不过 Spring Security 会校验失败

`Authentication` 接口

```java
public interface Authentication extends Principal, Serializable {
  //获取用户权限,一般情况下获取到的是用户的角色信息
  Collection<? extends GrantedAuthority> getAuthorities();
  //获取证明用户认证的信息,通常情况下获取到的是密码等信息,不过登录成功就会被移除
  Object getCredentials();
  //获取用户的额外信息,比如 IP 地址,经纬度等
  Object getDetails();
  //获取用户身份信息,在未认证的情况下获取到的是用户名,在已认证的情况下获取到的是 UserDetails (暂时理解为,当前应用用户对象的扩展)
  Object getPrincipal();
  //获取当前 Authentication 是否已认证
  boolean isAuthenticated();
  //设置当前 Authentication 是否已认证
  void setAuthenticated(boolean isAuthenticated);
}
```

**3.AuthenticationManager ProviderManager AuthenticationProvider**

其实这三者很好区分,`AuthenticationManager` 主要就是为了完成身份认证流程,`ProviderManager`是 `AuthenticationManager` 接口的具体实现类,`ProviderManager` 里面有个记录 `AuthenticationProvider` 对象的集合属性 `providers`,`AuthenticationProvider` 接口类里有两个方法

```java
public interface AuthenticationProvider {
  //实现具体的身份认证逻辑,认证失败抛出对应的异常
  Authentication authenticate(Authentication authentication)
    throws AuthenticationException;
  //该认证类是否支持该 Authentication 的认证
  boolean supports(Class<?> authentication);
}
```

接下来就是遍历 `ProviderManager` 里面的 `providers` 集合,找到和合适的 `AuthenticationProvider`完成身份认证

**4.UserDetailsService UserDetails**

在 `UserDetailsService` 接口中只有一个简单的方法

```java
public interface UserDetailsService {
  //根据用户名查到对应的 UserDetails 对象
  UserDetails loadUserByUsername(String username) throws UsernameNotFoundException;
}
```

**5.流程**

对于上面概念有什么不明白的地方,在们在接下来的流程中慢慢分析

在运行到 `UsernamePasswordAuthenticationFilter` 过滤器的时候首先是进入其父类 `AbstractAuthenticationProcessingFilter` 的 `doFilter()` 方法中

```java
public void doFilter(ServletRequest req, ServletResponse res, FilterChain chain)
  throws IOException, ServletException {
  ...
    //首先配对是不是配置的身份认证的URI,是则执行下面的认证,不是则跳过
    if (!requiresAuthentication(request, response)) {
      chain.doFilter(request, response);

      return;
    }
  ...
    Authentication authResult;

  try {
    //关键方法, 实现认证逻辑并返回 Authentication, 由其子类 UsernamePasswordAuthenticationFilter 实现, 由下面 5.3 详解
    authResult = attemptAuthentication(request, response);
    if (authResult == null) {
      // return immediately as subclass has indicated that it hasn't completed
      // authentication
      return;
    }
    sessionStrategy.onAuthentication(authResult, request, response);
  }
  catch (InternalAuthenticationServiceException failed) {
    //认证失败调用...由下面 5.1 详解
    unsuccessfulAuthentication(request, response, failed);

    return;
  }
  catch (AuthenticationException failed) {
    //认证失败调用...由下面 5.1 详解
    unsuccessfulAuthentication(request, response, failed);

    return;
  }

  // Authentication success
  if (continueChainBeforeSuccessfulAuthentication) {
    chain.doFilter(request, response);
  }
  //认证成功调用...由下面 5.2 详解
  successfulAuthentication(request, response, chain, authResult);
}
```

**5.1 认证失败处理逻辑**

```java
protected void unsuccessfulAuthentication(HttpServletRequest request,
                                          HttpServletResponse response, AuthenticationException failed)
  throws IOException, ServletException {
  SecurityContextHolder.clearContext();
  ...
    rememberMeServices.loginFail(request, response);
  //该 handler 处理失败界面跳转和响应逻辑
  failureHandler.onAuthenticationFailure(request, response, failed);
}
```

这里默认配置的失败处理 handler 是 `SimpleUrlAuthenticationFailureHandler`,**可自定义**

```java
public class SimpleUrlAuthenticationFailureHandler implements
        AuthenticationFailureHandler {
    ...

    public void onAuthenticationFailure(HttpServletRequest request,
            HttpServletResponse response, AuthenticationException exception)
            throws IOException, ServletException {
        //没有配置失败跳转的URL则直接响应错误
        if (defaultFailureUrl == null) {
            logger.debug("No failure URL set, sending 401 Unauthorized error");

            response.sendError(HttpStatus.UNAUTHORIZED.value(),
                HttpStatus.UNAUTHORIZED.getReasonPhrase());
        }
        else {
            //否则
            //缓存异常
            saveException(request, exception);
            //根据配置的异常页面是重定向还是转发进行不同方式跳转
            if (forwardToDestination) {
                logger.debug("Forwarding to " + defaultFailureUrl);

                request.getRequestDispatcher(defaultFailureUrl)
                        .forward(request, response);
            }
            else {
                logger.debug("Redirecting to " + defaultFailureUrl);
                redirectStrategy.sendRedirect(request, response, defaultFailureUrl);
            }
        }
    }
    //缓存异常,转发则保存在request里面,重定向则保存在session里面
    protected final void saveException(HttpServletRequest request,
            AuthenticationException exception) {
        if (forwardToDestination) {
            request.setAttribute(WebAttributes.AUTHENTICATION_EXCEPTION, exception);
        }
        else {
            HttpSession session = request.getSession(false);

            if (session != null || allowSessionCreation) {
                request.getSession().setAttribute(WebAttributes.AUTHENTICATION_EXCEPTION,
                        exception);
            }
        }
    }
}
```

**这里做下小拓展:用系统的错误处理handler,指定认证失败跳转的URL,在MVC里面对应的URL方法里面可以通过key从`request`或`session`里面拿到错误信息,反馈给前端**

**5.2 认证成功处理逻辑**

```java
protected void successfulAuthentication(HttpServletRequest request,
                                        HttpServletResponse response, FilterChain chain, Authentication authResult)
  throws IOException, ServletException {
  ...
    //这里要注意很重要,将认证完成返回的 Authentication 保存到线程对应的 `SecurityContext` 中
    SecurityContextHolder.getContext().setAuthentication(authResult);

  rememberMeServices.loginSuccess(request, response, authResult);

  // Fire event
  if (this.eventPublisher != null) {
    eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent(
      authResult, this.getClass()));
  }
  //该 handler 就是为了完成页面跳转
  successHandler.onAuthenticationSuccess(request, response, authResult);
}
```

这里默认配置的成功处理 handler 是 `SavedRequestAwareAuthenticationSuccessHandler`,里面的代码就不做具体展开了,反正是跳转到指定的认证成功之后的界面,**可自定义**

**5.3 身份认证详情**

```java
public class UsernamePasswordAuthenticationFilter extends
  AbstractAuthenticationProcessingFilter {
  ...
    public static final String SPRING_SECURITY_FORM_USERNAME_KEY = "username";
  public static final String SPRING_SECURITY_FORM_PASSWORD_KEY = "password";

  private String usernameParameter = SPRING_SECURITY_FORM_USERNAME_KEY;
  private String passwordParameter = SPRING_SECURITY_FORM_PASSWORD_KEY;
  private boolean postOnly = true;

  ...
    //开始身份认证逻辑
    public Authentication attemptAuthentication(HttpServletRequest request,
                                                HttpServletResponse response) throws AuthenticationException {
    if (postOnly && !request.getMethod().equals("POST")) {
      throw new AuthenticationServiceException(
        "Authentication method not supported: " + request.getMethod());
    }

    String username = obtainUsername(request);
    String password = obtainPassword(request);

    if (username == null) {
      username = "";
    }

    if (password == null) {
      password = "";
    }

    username = username.trim();
    //先用前端提交过来的 username 和 password 封装一个简易的 AuthenticationToken
    UsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(
      username, password);

    // Allow subclasses to set the "details" property
    setDetails(request, authRequest);
    //具体的认证逻辑还是交给 AuthenticationManager 对象的 authenticate(..) 方法完成,接着往下看
    return this.getAuthenticationManager().authenticate(authRequest);
  }
}
```

由源码断点跟踪得知,最终解析是由 `AuthenticationManager` 接口实现类 `ProviderManager` 来完成

```java
public class ProviderManager implements AuthenticationManager, MessageSourceAware,
InitializingBean {
  ...
    private List<AuthenticationProvider> providers = Collections.emptyList();
  ...

    public Authentication authenticate(Authentication authentication)
    throws AuthenticationException {
    ....
      //遍历所有的 AuthenticationProvider, 找到合适的完成身份验证
      for (AuthenticationProvider provider : getProviders()) {
        if (!provider.supports(toTest)) {
          continue;
        }
        ...
          try {
            //进行具体的身份验证逻辑, 这里使用到的是 DaoAuthenticationProvider, 具体逻辑记着往下看
            result = provider.authenticate(authentication);

            if (result != null) {
              copyDetails(authentication, result);
              break;
            }
          }
        catch
          ...
      }
    ...
      throw lastException;
  }
}
```

`DaoAuthenticationProvider` 继承自 `AbstractUserDetailsAuthenticationProvider` 实现了 `AuthenticationProvider` 接口

```java
public abstract class AbstractUserDetailsAuthenticationProvider implements
  AuthenticationProvider, InitializingBean, MessageSourceAware {
  ...
    private UserDetailsChecker preAuthenticationChecks = new DefaultPreAuthenticationChecks();
  private UserDetailsChecker postAuthenticationChecks = new DefaultPostAuthenticationChecks();
  ...

    public Authentication authenticate(Authentication authentication)
    throws AuthenticationException {
    ...
      // 获得提交过来的用户名
      String username = (authentication.getPrincipal() == null) ? "NONE_PROVIDED"
      : authentication.getName();
    //根据用户名从缓存中查找 UserDetails
    boolean cacheWasUsed = true;
    UserDetails user = this.userCache.getUserFromCache(username);

    if (user == null) {
      cacheWasUsed = false;

      try {
        //缓存中没有则通过 retrieveUser(..) 方法查找 (看下面 DaoAuthenticationProvider 的实现)
        user = retrieveUser(username,
                            (UsernamePasswordAuthenticationToken) authentication);
      }
      catch
        ...
    }

    try {
      //比对前的检查,例如账户以一些状态信息(是否锁定, 过期...)
      preAuthenticationChecks.check(user);
      //子类实现比对规则 (看下面 DaoAuthenticationProvider 的实现)
      additionalAuthenticationChecks(user,
                                     (UsernamePasswordAuthenticationToken) authentication);
    }
    catch (AuthenticationException exception) {
      if (cacheWasUsed) {
        // There was a problem, so try again after checking
        // we're using latest data (i.e. not from the cache)
        cacheWasUsed = false;
        user = retrieveUser(username,
                            (UsernamePasswordAuthenticationToken) authentication);
        preAuthenticationChecks.check(user);
        additionalAuthenticationChecks(user,
                                       (UsernamePasswordAuthenticationToken) authentication);
      }
      else {
        throw exception;
      }
    }

    postAuthenticationChecks.check(user);

    if (!cacheWasUsed) {
      this.userCache.putUserInCache(user);
    }

    Object principalToReturn = user;

    if (forcePrincipalAsString) {
      principalToReturn = user.getUsername();
    }
    //根据最终user的一些信息重新生成具体详细的 Authentication 对象并返回
    return createSuccessAuthentication(principalToReturn, authentication, user);
  }
  //具体生成还是看子类实现
  protected Authentication createSuccessAuthentication(Object principal,
                                                       Authentication authentication, UserDetails user) {
    // Ensure we return the original credentials the user supplied,
    // so subsequent attempts are successful even with encoded passwords.
    // Also ensure we return the original getDetails(), so that future
    // authentication events after cache expiry contain the details
    UsernamePasswordAuthenticationToken result = new UsernamePasswordAuthenticationToken(
      principal, authentication.getCredentials(),
      authoritiesMapper.mapAuthorities(user.getAuthorities()));
    result.setDetails(authentication.getDetails());

    return result;
  }
}
```

接下来我们来看下 `DaoAuthenticationProvider` 里面的三个重要的方法,比对方式,获取需要比对的 `UserDetails` 对象以及生产最终返回 `Authentication` 的方法

```java
public class DaoAuthenticationProvider extends AbstractUserDetailsAuthenticationProvider {
  ...
    //密码比对
    @SuppressWarnings("deprecation")
    protected void additionalAuthenticationChecks(UserDetails userDetails,
                                                  UsernamePasswordAuthenticationToken authentication)
    throws AuthenticationException {
    if (authentication.getCredentials() == null) {
      logger.debug("Authentication failed: no credentials provided");

      throw new BadCredentialsException(messages.getMessage(
        "AbstractUserDetailsAuthenticationProvider.badCredentials",
        "Bad credentials"));
    }

    String presentedPassword = authentication.getCredentials().toString();
    //通过 PasswordEncoder 进行密码比对, 注: 可自定义
    if (!passwordEncoder.matches(presentedPassword, userDetails.getPassword())) {
      logger.debug("Authentication failed: password does not match stored value");

      throw new BadCredentialsException(messages.getMessage(
        "AbstractUserDetailsAuthenticationProvider.badCredentials",
        "Bad credentials"));
    }
  }

  //通过 UserDetailsService 获取 UserDetails
  protected final UserDetails retrieveUser(String username,
                                           UsernamePasswordAuthenticationToken authentication)
    throws AuthenticationException {
    prepareTimingAttackProtection();
    try {
      //通过 UserDetailsService 获取 UserDetails
      UserDetails loadedUser = this.getUserDetailsService().loadUserByUsername(username);
      if (loadedUser == null) {
        throw new InternalAuthenticationServiceException(
          "UserDetailsService returned null, which is an interface contract violation");
      }
      return loadedUser;
    }
    catch (UsernameNotFoundException ex) {
      mitigateAgainstTimingAttack(authentication);
      throw ex;
    }
    catch (InternalAuthenticationServiceException ex) {
      throw ex;
    }
    catch (Exception ex) {
      throw new InternalAuthenticationServiceException(ex.getMessage(), ex);
    }
  }

  //生成身份认证通过后最终返回的 Authentication, 记录认证的身份信息
  @Override
  protected Authentication createSuccessAuthentication(Object principal,
                                                       Authentication authentication, UserDetails user) {
    boolean upgradeEncoding = this.userDetailsPasswordService != null
      && this.passwordEncoder.upgradeEncoding(user.getPassword());
    if (upgradeEncoding) {
      String presentedPassword = authentication.getCredentials().toString();
      String newPassword = this.passwordEncoder.encode(presentedPassword);
      user = this.userDetailsPasswordService.updatePassword(user, newPassword);
    }
    return super.createSuccessAuthentication(principal, authentication, user);
  }
}
```

## Mybatis

### MyBatis核心类

### Mybatis的执行过程

1. 读取MyBatis的核心配置文件
2. 构造SqlSessionFactoryBuilder获取SqlSessionFactory
3. SqlSessionFactory创建会话对象SqlSession
4. 使用SqlSession获得Mapper
5. 调用Mapper接口中的方法

### Mybatis的Mapper只有接口没有实现类却能工作的原因

1. 获取已知的加载过的Mapper中获取出MapperProxyFactory，Mapper代理工厂是通过Class.forName反射生成namespace的对应接口的反射对象并将生成的对象传入MapperProxyFactory的构造函数，最后存入knownMappers集合
2. 代理工厂生成动态代理返回,调用MapperProxyFactory的newInstance方法封装InvocationHandler的实现类MapperProxy,最后并返回代理类

### 命名空间

- 在大型项目中,可能存在大量SQL语句,这时候为每个SQL语句起一个唯一的标识就变得并不容易了,为了解决这个问题,在Mybatis中,可以为每个映射文件起一个唯一的命名空间,这样定义在这个映射文件中的每个SQL语句就成了定义在这个命名空间中的一个ID,只要我们能保证每个命名空间中的这个ID是唯一的,即使在不同的映射文件中的语句ID相同,也不会再产生冲突了

### #{ } 和${ }的区别

- `#{}`:这种方式是使用的预编译的方式,一个#{}就是一个占位符,相当于jdbc的占位符PrepareStatement,设置值的时候会加上引号
- `${}`:这种方式是直接拼接的方式,不对数值做预编译,存在sql注入的现象,设置值的时候不会加上引号

### 二级缓存

- Mybatis中一级缓存是默认开启的,二级缓存默认是不开启的,一级缓存是对于一个sqlSeesion而言,而二级缓存是对于一个nameSpace而言,可以多个SqlSession共享
- 查出的数据都会被默认先放在一级缓存中,只有会话提交或者关闭以后, 一级缓存中的数据才会转到二级缓存中

## MySQL

### 数据库建表三大范式

- 第一范式:原子性,要求属性具有原子性,不可再分解
- 第二范式:唯一性,要求记录有唯一标识,即实体的唯一性,即不存在部分依赖
- 第三范式:消除冗余性,要求任何字段不能由其他字段派生出来,它要求字段没有冗余,即不存在传递依赖

### B 树与B+树

- B+树的中间节点不保存数据,所以磁盘页能容纳更多节点数据,更矮胖
- B+树查询必须查找到叶子节点,B树查询有可能在非叶子节点结束,因此B+树的查询更稳定
- 对于范围查找来说,B+树只需序遍历叶子节点链表即可,B树却需要重复地中序遍历
- B+树非叶子节点相当于是叶子节点的索引层,叶子节点是 存储关键字数据的数据层,实现了索引与数据的分离

### druid连接池

1. 强大的监控特性,通过Druid提供的监控功能,可以清楚知道连接池和SQL的工作情况
   1.  监控SQL的执行时间,ResultSet持有时间,返回行数,更新行数,错误次数,错误堆栈信息;
   2.  SQL执行的耗时区间分布,什么是耗时区间分布呢？比如说,某个SQL执行了1000次,其中`0~1`毫秒区间50次,`1~10`毫秒800次,`10~100`毫秒100次,`100~1000`毫秒30次,`1~10`秒15次,10秒以上5次,通过耗时区间分布,能够非常清楚知道SQL的执行耗时情况
   3.  监控连接池的物理连接创建和销毁次数,逻辑连接的申请和关闭次数,非空等待次数,PSCache命中率等
2. 其次,方便扩展,Druid提供了Filter-Chain模式的扩展API,可以自己编写Filter拦截JDBC中的任何方法,可以在上面做任何事情,比如说性能监控,SQL审计,用户名密码加密,日志等等
3. Druid集合了开源和商业数据库连接池的优秀特性,并结合阿里巴巴大规模苛刻生产环境的使用经验进行优化

### InnoDB和MyISAM的区别

- InnoDB支持事务,MyISAM不支持
- InnoDB支持行级锁而MyISAM仅仅支持表锁,但是InnoDB可能出现死锁
- InnoDB的关注点在于:并发写,事务,更大资源,而MyISAM的关注点在于:节省资源,消耗少,简单业务
- InnoDB比MyISAM更安全,但是MyISAM的效率要比InnoDB高
- 在MySQL5.7的时候,默认就是InnoDb作为默认的存储引擎了

### Sql执行计划

- 使用EXPLAIN关键字可以模拟优化器执行SQL查询语句,从而知道MySQL是如何处理你的SQL语句的,分析查询语句或是表结构的性能瓶颈

```
Explain + SQL语句
```

- 通过Explain,我们可以获取以下信息:
  - 表的读取顺序
  - 哪些索引可以使用
  - 数据读取操作的操作类型
  - **哪些索引被实际使用**
  - 表之间的引用
  - 每张表有多少行被物理查询

### 数据库优化

- 选取最适用的字段属性
- 使用连接查询代替子查询
- 对查询进行优化,应尽量避免全表扫描,首先应考虑在 WHERE 及 ORDER BY 涉及的列上建立索引
- 选择表合适存储引擎
- 避免索引失效

### 数据库索引的优化建议以及有哪些注意点

- 使用复合索引的效果会大于使用单个字段索引(但是要注意顺序)
- 查询条件时要按照索引中的定义顺序进行匹配,如果索引了多列,要遵守最左前缀法则,指的是查询从索引的最左前列开始并且不跳过索引中的列
- 不在索引列上做任何操作(计算,函数,(自动or手动)类型转换),会导致索引失效而转向全表扫描
- 存储引擎不能使用索引中范围条件右边的列,范围查询的列在定义索引的时候,应该放在最后面
- mysql 在使用不等于(!= 或者<>)的时候无法使用索引会导致全表扫描
- is not null 也无法使用索引,但是is null是可以使用索引的
- like以通配符开头('%abc...')mysql索引失效会变成全表扫描的操作
- 字符串不加单引号索引失效(类型转换导致索引失效)

### MySQL锁

**悲观锁**

- MyISAM支持表锁,InnoDB支持表锁和行锁,默认行锁
    - 表级锁:开锁小,加锁快,不会出现死锁,锁的粒度大,发生锁冲突的概率最高,并发量最低
    - 行级锁:开销大,加锁慢,会出现死锁,锁的粒度小,容易发生冲突的概率小,并发度最高,innoDB支持三种行锁定方式:
        - 行锁(Record Lock):锁直接加在索引记录上面(无索引项时演变成表锁)
        - 间隙锁(Gap Lock):锁定索引记录间隙,确保索引记录的间隙不变,间隙锁是针对事务隔离级别为可重复读或以上级别的
        - Next-Key Lock:行锁和间隙锁组合起来就是 Next-Key Lock
    - innoDB默认的隔离级别是可重复读(Repeatable Read),并且会以Next-Key Lock的方式对数据行进行加锁,Next-Key Lock是行锁和间隙锁的组合,当InnoDB扫描索引记录的时候,会首先对索引记录加上行锁(Record Lock),再对索引记录两边的间隙加上间隙锁(Gap Lock),加上间隙锁之后,其他事务就不能在这个间隙修改或者插入记录
    - 当查询的索引含有唯一属性(唯一索引,主键索引)时,Innodb存储引擎会对next-key lock进行优化,将其降为record lock,即仅锁住索引本身,而不是范围
    - **何时使用行锁,何时产生间隙锁**
        - 只使用唯一索引查询,并且只锁定一条记录时,innoDB会使用行锁
        - 只使用唯一索引查询,但是检索条件是范围检索,或者是唯一检索然而检索结果不存在(试图锁住不存在的数据)时,会产生 Next-Key Lock
        - 使用普通索引检索时,不管是何种查询,只要加锁,都会产生间隙锁
        - 同时使用唯一索引和普通索引时,由于数据行是优先根据普通索引排序,再根据唯一索引排序,所以也会产生间隙锁

**乐观锁**

- 使用数据版本(Version)记录机制实现,这是乐观锁最常用的一种实现方式,何谓数据版本？即为数据增加一个版本标识,一般是通过为数据库表增加一个数字类型的"version” 字段来实现,当读取数据时,将version字段的值一同读出,数据每更新一次,对此version值加一,当我们提交更新的时候,判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对,如果数据库表当前版本号与第一次取出来的version值相等,则予以更新,否则认为是过期数据
- 使用时间戳(timestamp),乐观锁定的第二种实现方式和第一种差不多,同样是在需要乐观锁控制的table中增加一个字段,名称无所谓,字段类型使用时间戳(timestamp),和上面的version类似,也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比,如果一致则OK,否则就是版本冲突

### 事务的ACID

- 原子性(Atomic):事务中各项操作,要么全做要么全不做,任何一项操作的失败都会导致整个事务的失败
- 一致性(Consistent):事务结束后系统状态是一致的
- 隔离性(Isolated):并发执行的事务彼此无法看到对方的中间状态
- 持久性(Durable):事务完成后所做的改动都会被持久化,即使发生灾难性的失败,通过日志和同步备份可以在故障发生后重建数据

### 事务的隔离级别

- 只有存在并发数据访问时才需要事务,当多个事务访问同一数据时,可能会存在5类问题,包括3类数据读取问题(脏读,不可重复读和幻读)和2类数据更新问题(第1类丢失更新和第2类丢失更新)

- 脏读(Dirty Read):A事务读取B事务尚未提交的数据并在此基础上操作,而B事务执行回滚,那么A读取到的数据就是脏数据
- 不可重复读(Unrepeatable Read):事务A重新读取前面读取过的数据,发现该数据已经被另一个已提交的事务B修改过了
- 幻读(Phantom Read):事务A重新执行一个查询,返回一系列符合查询条件的行,发现其中插入了被事务B提交的行
- 第1类丢失更新:事务A撤销时,把已经提交的事务B的更新数据覆盖了
- 第2类丢失更新:事务A覆盖事务B已经提交的数据,造成事务B所做的操作丢失

- 数据并发访问所产生的问题,在有些场景下可能是允许的,但是有些场景下可能就是致命的,数据库通常会通过锁机制来解决数据并发访问问题,按锁定对象不同可以分为表级锁和行级锁,按并发事务锁定关系可以分为共享锁和独占锁,具体的内容大家可以自行查阅资料进行了解
- 直接使用锁是非常麻烦的,为此数据库为用户提供了自动锁机制,只要用户指定会话的事务隔离级别,数据库就会通过分析SQL语句然后为事务访问的资源加上合适的锁,此外,数据库还会维护这些锁通过各种手段提高系统的性能,这些对用户来说都是透明的(就是说你不用理解,事实上我确实也不知道),ANSI/ISO SQL 92标准定义了4个等级的事务隔离级别,如下表所示:

| 隔离级别        | 脏读   | 不可重复读 | 幻读   | 第一类丢失更新 | 第二类丢失更新 |
| --------------- | ------ | ---------- | ------ | -------------- | -------------- |
| READ UNCOMMITED | 允许   | 允许       | 允许   | 不允许         | 允许           |
| READ COMMITTED  | 不允许 | 允许       | 允许   | 不允许         | 允许           |
| REPEATABLE READ | 不允许 | 不允许     | 允许   | 不允许         | 不允许         |
| SERIALIZABLE    | 不允许 | 不允许     | 不允许 | 不允许         | 不允许         |

需要说明的是,事务隔离级别和数据访问的并发性是对立的,事务隔离级别越高并发性就越差,所以要根据具体的应用来确定合适的事务隔离级别

### 手动事务处理

- Connection提供了事务处理的方法,通过调用setAutoCommit(false)可以设置手动提交事务,当事务完成后用commit()显式提交事务如果在事务处理过程中发生异常则通过rollback()进行事务回滚,除此之外,从JDBC 3.0中还引入了Savepoint(保存点)的概念,允许通过代码设置保存点并让事务回滚到指定的保存点

### 数据库连接池

由于创建连接和释放连接都有很大的开销(尤其是数据库服务器不在本地时,每次建立连接都需要进行TCP的三次握手,释放连接需要进行TCP四次握手,造成的开销是不可忽视的),为了提升系统访问数据库的性能,可以事先创建若干连接置于连接池中,需要时直接从连接池获取,使用结束时归还连接池而不必关闭连接,从而避免频繁创建和释放连接所造成的开销,这是典型的用空间换取时间的策略(浪费了空间存储连接,但节省了创建和释放连接的时间),池化技术在Java开发中是很常见的,在使用线程时创建线程池的道理与此相同,基于Java的开源数据库连接池主要有:C3P0,Proxool,DBCP,BoneCP,Druid等

> **补充**:在计算机系统中时间和空间是不可调和的矛盾,理解这一点对设计满足性能要求的算法是至关重要的,大型网站性能优化的一个关键就是使用缓存,而缓存跟上面讲的连接池道理非常类似,也是使用空间换时间的策略,可以将热点数据置于缓存中,当用户查询这些数据时可以直接从缓存中得到,这无论如何也快过去数据库中查询,当然,缓存的置换策略等也会对系统性能产生重要影响,对于这个问题的讨论已经超出了这里要阐述的范围

### MySQL SQL语句执行过程

### 数据库主键为什么要用递增的序列？UUID为什么不适合做主键？

顺序的ID占用的空间比随机ID占用的空间小,原因是数据库主键和索引索引使用B+树的数据结构进行存储,顺序ID数据存储在最后一个节点的最后的位置,前面的节点数据都是满的,随机ID存储时可能会出现节点分裂,导致节点多了,但是每个节点的数据量少了,存储到文件系统中时,无论节点中数据是不是满的都会占用一页的空间,所以所导致空间占用较大

### 分表策略

- 水平拆分行,行数据拆分到不同表中,垂直拆分列,表数据拆分到不同表中
- **垂直拆分**:单表大数据量依然存在性能瓶颈,垂直拆分就是要把表按模块划分到不同数据库表中,相对于垂直切分更进一步的是服务化改造,说得简单就是要把原来强耦合的系统拆分成多个弱耦合的服务,通过服务间的调用来满足业务需求看,因此表拆出来后要通过服务的形式暴露出去,而不是直接调用不同模块的表
- 水平拆分,上面谈到垂直切分只是把表按模块划分到不同数据库,但没有解决单表大数据量的问题,而水平切分就是要把一个表按照某种规则把数据划分到不同表或数据库里,例如像计费系统,通过按时间来划分表就比较合适,因为系统都是处理某一时间段的数据,而像SaaS应用,通过按用户维度来划分数据比较合适,因为用户与用户之间的隔离的,一般不存在处理多个用户数据的情况,简单的按user_id范围来水平切分

## Redis

### 什么是中间件

中间件是一类提供系统软件和应用软件之间连接,便于软件各部件之间的沟通的软件,应用软件可以借助中间件在不同的技术架构之间共享信息与资源,中间件位于客户机服务器的操作系统之上,管理着计算资源和网络通信

### 分布式锁

### 缓存穿透,缓存击穿,缓存雪崩

#### 缓存穿透

- 缓存穿透是指用户请求的数据在缓存中不存在即没有命中,同时在数据库中也不存在,导致用户每次请求该数据都要去数据库中查询一遍,如果有恶意攻击者不断请求系统中不存在的数据,会导致短时间大量请求落在数据库上,造成数据库压力过大,甚至导致数据库承受不住而宕机崩溃

**解决方法**

1. **将无效的key存放进Redis中**:当出现Redis查不到数据,数据库也查不到数据的情况,我们就把这个key保存到Redis中,设置value="null",并设置其过期时间极短,后面再出现查询这个key的请求的时候,直接返回null,就不需要再查询数据库了,但这种处理方式是有问题的,假如传进来的这个不存在的Key值每次都是随机的,那存进Redis也没有意义
2. **使用布隆过滤器**:如果布隆过滤器判定某个 key 不存在布隆过滤器中,那么就一定不存在,如果判定某个 key 存在,那么很大可能是存在(存在一定的误判率),于是我们可以在缓存之前再加一个布隆过滤器,将数据库中的所有key都存储在布隆过滤器中,在查询Redis前先去布隆过滤器查询 key 是否存在,如果不存在就直接返回,不让其访问数据库,从而避免了对底层存储系统的查询压力

**注意**

- 即使对空值设置了过期时间,还是会存在缓存层和存储层的数据会有一段时间窗口的不一致,这对于需要保持一致性的业务会有影响
- **如何选择**:针对一些恶意攻击,攻击带过来的大量key是随机,那么我们采用第一种方案就会缓存大量不存在key的数据,那么这种方案就不合适了,我们可以先对使用布隆过滤器方案进行过滤掉这些key,所以,针对这种key异常多,请求重复率比较低的数据,优先使用第二种方案直接过滤掉,而对于空数据的key有限的,重复率比较高的,则可优先采用第一种方式进行缓存

#### 缓存击穿

- 缓存击穿跟缓存雪崩有点类似,缓存雪崩是大规模的key失效,而缓存击穿是某个热点的key失效,大并发集中对其进行请求,就会造成大量请求读缓存没读到数据,从而导致高并发访问数据库,引起数据库压力剧增,这种现象就叫做缓存击穿

**解决方案**

1. **加互斥锁**:在缓存失效后,通过互斥锁或者队列来控制读数据写缓存的线程数量,比如某个key只允许一个线程查询数据和写缓存,其他线程等待,这种方式会阻塞其他的线程,此时系统的吞吐量会下降
2. **热点数据缓存永远不过期**,永不过期实际包含两层意思:
   - 物理不过期,针对热点key不设置过期时间
   - 逻辑过期,把过期时间存在key对应的value里,如果发现要过期了,通过一个后台的异步线程进行缓存的构建

#### 缓存雪崩

- 如果缓存某一个时刻出现大规模的key失效,那么就会导致大量的请求打在了数据库上面,导致数据库压力巨大,如果在高并发的情况下,可能瞬间就会导致数据库宕机,这时候如果运维马上又重启数据库,马上又会有新的流量把数据库打死,这就是缓存雪崩

**解决方案**

1. 事前
   - 均匀过期:设置不同的过期时间,让缓存失效的时间尽量均匀,避免相同的过期时间导致缓存雪崩,造成大量数据库的访问
   - 分级缓存:第一级缓存失效的基础上,访问二级缓存,每一级缓存的失效时间都不同
   - 热点数据缓存永远不过期
   - 保证Redis缓存的高可用,防止Redis宕机导致缓存雪崩的问题,可以使用 主从+ 哨兵,Redis集群来避免 Redis 全盘崩溃的情况
2. 事中
   - 互斥锁:在缓存失效后,通过互斥锁或者队列来控制读数据写缓存的线程数量,比如某个key只允许一个线程查询数据和写缓存,其他线程等待,这种方式会阻塞其他的线程,此时系统的吞吐量会下降
   - 使用熔断机制,限流降级,当流量达到一定的阈值,直接返回"系统拥挤”之类的提示,防止过多的请求打在数据库上将数据库击垮,至少能保证一部分用户是可以正常使用,其他用户多刷新几次也能得到结果
3. 事后
   - 开启Redis持久化机制,尽快恢复缓存数据,一旦重启,就能从磁盘上自动加载数据恢复内存中的数据



### 数据类型

- String字符串:字符串类型是 Redis 最基础的数据结构,首先键都是字符串类型,而且 其他几种数据结构都是在字符串类型基础上构建的,我们常使用的 set key value 命令就是字符串,常用在缓存,计数,共享Session,限速等
- Hash哈希:在Redis中,哈希类型是指键值本身又是一个键值对结构,哈希可以用来存放用户信息,比如实现购物车
- List列表(双向链表):列表(list)类型是用来存储多个有序的字符串,可以做简单的消息队列的功能
- Set集合:集合(set)类型也是用来保存多个的字符串元素,但和列表类型不一 样的是,集合中不允许有重复元素,并且集合中的元素是无序的,不能通过索引下标获取元素,利用 Set 的交集,并集,差集等操作,可以计算共同喜好,全部的喜好,自己独有的喜好等功能
- Sorted Set有序集合(跳表实现):Sorted Set 多了一个权重参数 Score,集合中的元素能够按 Score 进行排列,可以做排行榜应用,取 TOP N 操作

### 持久化技术

- Redis为了保证效率,数据缓存在了内存中,但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中,以保证数据的持久化
- Redis的持久化策略有两种:
  1. RDB:快照形式是直接把内存中的数据保存到一个dump的文件中,定时保存,保存策略,当Redis需要做持久化时,Redis会fork一个子进程,子进程将数据写到磁盘上一个临时RDB文件中,当子进程完成写临时文件后,将原来的RDB替换掉
  2. AOF:把所有的对Redis的服务器进行修改的命令都存到一个文件里,命令的集合,使用AOF做持久化,每一个写命令都通过write函数追加到appendonly.aof中,aof的默认策略是每秒钟fsync一次,在这种配置下,就算发生故障停机,也最多丢失一秒钟的数据,缺点是对于相同的数据集来说,AOF的文件体积通常要大于RDB文件的体积,根据所使用的fsync策略,AOF的速度可能会慢于RDB,Redis默认是快照RDB的持久化方式,对于主从同步来说,主从刚刚连接的时候,进行全量同步(RDB),全同步结束后,进行增量同步(AOF)

### Redis效率高的原因

1. 纯内存操作,相对于读写磁盘,读写速度提升明显
2. 单线程操作,避免了频繁的上下文切换
4. 采用了非阻塞I/O多路复用机制(有一个文件描述符同时监听多个文件描述符是否有数据到来):多路指的是多个网络连接,复用指的是复用同一个线程,采用多路I/O复用技术可以让单个线程高效的处理多个连接请求,尽量减少网络IO的时间消耗

### 事务

事务可以理解为一个打包的批量执行脚本,但批量指令并非原子化的操作,中间某条指令的失败不会导致前面已做指令的回滚,也不会造成后续的指令不做

###  Redis存的数据过期了,数据会立即删除吗

不会,其实有三种不同的删除策略:

1. 立即删除,在设置键的过期时间时,创建一个定时器,当过期时间达到时,立即执行删除操作
2. 惰性删除,key过期的时候不删除,每次从数据库获取key的时候去检查是否过期,若过期,则删除,返回null
3. 定时删除,每隔一段时间,对全部的键进行检查,删除里面的过期键

### Redis 和 Mysql 数据库数据如何保持一致性

先更新数据库,再删缓存,数据库的读操作的速度远快于写操作的,所以脏数据很难出现,可以对异步延时删除策略,保证读请求完成以后,再进行删除操作

### Redis的应用场景

- 缓存
- 共享Session
- 消息队列系统
- 分布式锁

### 主从复制

1. 与master建立连接
2. 向master发起同步请求(SYNC)
3. 接受master发来的RDB文件
4. 载入RDB文件

### 常用命令

```
key
    keys * 获取所有的key
    select 0 选择第一个库
    move myString 1 将当前的数据库key移动到某个数据库,目标库有,则不能移动
    flush db      清除指定库
    randomkey     随机key
    type key      类型

    set key1 value1 设置key
    get key1    获取key
    mset key1 value1 key2 value2 key3 value3
    mget key1 key2 key3
    del key1   删除key
    exists key      判断是否存在key
    expire key 10   10过期
    pexpire key 1000 毫秒
    persist key     删除过期时间

string
    set name cxx
    get name
    getrange name 0 -1        字符串分段
    getset name new_cxx       设置值,返回旧值
    mset key1 key2            批量设置
    mget key1 key2            批量获取
    setnx key value           不存在就插入(not exists)
    setex key time value      过期时间(expire)
    setrange key index value  从index开始替换value
    incr age        递增
    incrby age 10   递增
    decr age        递减
    decrby age 10   递减
    incrbyfloat     增减浮点数
    append          追加
    strlen          长度
    getbit/setbit/bitcount/bitop    位操作

hash
    hset myhash name cxx
    hget myhash name
    hmset myhash name cxx age 25 note "i am notes"
    hmget myhash name age note
    hgetall myhash               获取所有的
    hexists myhash name          是否存在
    hsetnx myhash score 100      设置不存在的
    hincrby myhash id 1          递增
    hdel myhash name             删除
    hkeys myhash                 只取key
    hvals myhash                 只取value
    hlen myhash                  长度

list
    lpush mylist a b c  左插入
    rpush mylist x y z  右插入
    lrange mylist 0 -1  数据集合
    lpop mylist  弹出元素
    rpop mylist  弹出元素
    llen mylist  长度
    lrem mylist count value  删除
    lindex mylist 2          指定索引的值
    lset mylist 2 n          索引设值
    ltrim mylist 0 4         删除key
    linsert mylist before a  插入
    linsert mylist after a   插入
    rpoplpush list list2     转移列表的数据

set
    sadd myset redis
    smembers myset       数据集合
    srem myset set1         删除
    sismember myset set1 判断元素是否在集合中
    scard key_name       个数
    sdiff | sinter | sunion 操作:集合间运算:差集 | 交集 | 并集
    srandmember          随机获取集合中的元素
    spop                 从集合中弹出一个元素

zset
    zadd zset 1 one
    zadd zset 2 two
    zadd zset 3 three
    zincrby zset 1 one              增长分数
    zscore zset two                 获取分数
    zrange zset 0 -1 withscores     范围值
    zrangebyscore zset 10 25 withscores 指定范围的值
    zrangebyscore zset 10 25 withscores limit 1 2 分页
    Zrevrangebyscore zset 10 25 withscores  指定范围的值
    zcard zset  元素数量
    Zcount zset 获得指定分数范围内的元素个数
    Zrem zset one two        删除一个或多个元素
    Zremrangebyrank zset 0 1  按照排名范围删除元素
    Zremrangebyscore zset 0 1 按照分数范围删除元素
    Zrank zset 0 -1    分数最小的元素排名为0
    Zrevrank zset 0 -1  分数最大的元素排名为0
    Zinterstore
    zunionstore rank:last_week 7 rank:20150323 rank:20150324 rank:20150325  weights 1 1 1 1 1 1 1


排序:
    sort mylist  排序
    sort mylist alpha desc limit 0 2 字母排序
    sort list by it:* desc           by命令
    sort list by it:* desc get it:*  get参数
    sort list by it:* desc get it:* store sorc:result  sort命令之store参数:表示把sort查询的结果集保存起来
```

## RabbitMq

### 怎么防止重复消费

- 可能因为各种原因,导致了生产端发送了多条一样的消息给消费端,但是,消费端也只能消费一条,不会多消费,可以使用`唯一ID + 指纹码机制`防止消息被重复消费
- 指纹码(就是时间戳 + 业务的一些规则,来保证id + 指纹码在同一时刻是唯一的,不会出现重复)
  1. 唯一ID + 指纹码机制,利用数据库主键去重
  2. select count(1) from t_order where id = 唯一ID + 指纹码
     - 如果不存在,则正常消费,消费完毕后将[唯一ID + 指纹码]写入数据库
     - 如果存在,则证明消息被消费过,直接丢弃

### Rabbitmq怎么防止消息丢失

将信道设置成confirm模式(发送方确认模式),则所有在信道上发布的消息都会被指派一个唯一的ID,一旦消息被投递到目的队列后,或者消息被写入磁盘后(可持久化的消息),信道会发送一个确认给生产者(包含消息唯一ID)

### 为什么选择使用MQ来实现同步

通过使用消息队列,我们可以异步处理请求,从而缓解系统的压力,同样可以达到解耦的效果

## Elasticsearch

### 高亮你们是怎么做的

- SpringBoot整合Elasticsearch有一个searchSourceBuilder,通过链式调用一个highlighter方法,传入一个HighlightBuilder对象并设置好查询的列和高亮的标签
- 之后调用RestHighLevelClient对象的Search方法之后返回一个SearchResponse对象,之后可以调用response.getHits().getHits();获得击中的结果数组,数组中每一个对象除了包含原始内容还包含了一个高亮结果集,是一个Map集合

### SpringBoot怎么集成Elasticsearch

首先需要导入`spring-boot-starter-data-elasticsearch`,在Spring官网的data项目里面有详细的文档介绍,官方强烈建议使用  High Level REST Client来操作ES,之后需要添加一个配置类,在官方文档有介绍,之后我们就可以通过Spring容器来管理获取HighLevelRESTClient对象了

## 其他

### Maven 命令

- clean：清理项目生产的临时文件,一般是模块下的target目录
- compile：编译源代码,一般编译模块下的src/main/java目录
- test：测试命令,或执行src/test/java/下junit的测试用例
- package：项目打包工具,会在模块下的target目录生成jar或war等文件
- install：将打包的jar/war文件复制到你的本地仓库中,供其他模块使用
- deploy：将打包的文件发布到远程参考,提供其他人员进行下载依赖
- site：生成项目相关信息的网站
- dependency：打印出项目的整个依赖树

## 数据结构

### 红黑树

​	根节点是黑色

​	每个节点都只能是红色或者黑色

​	每个叶节点(NIL节点,空节点)是黑色的

​	如果一个节点是红色的,则它两个子节点都是黑色的,也就是说在一条路径上不能出现两个红色的节点

​	从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点

## 算法

### 排序算法

排序算法是最经典的算法知识,因为其实现代码短,应该广,在面试中经常会问到排序算法及其相关的问题,一般在面试中最常考的是快速排序和归并排序等基本的排序算法,并且经常要求现场手写基本的排序算法,如果这些问题回答不好,估计面试就凉凉了,所以熟练掌握排序算法思想及其特点并能够熟练地手写代码至关重要

下面介绍几种常见的排序算法:冒泡排序,选择排序,插入排序,归并排序,快速排序,希尔排序,堆排序,计数排序,桶排序,基数排序的思想,其代码均采用Java实现

#### 冒泡排序

冒泡排序是一种简单的排序算法,它重复地走访过要排序的数列,一次比较两个元素,如果它们的顺序错误就把它们交换过来,走访数列的工作是重复地进行直到没有再需要交换,也就是说该数列已经排序完成,这个算法的名字由来是因为越小的元素会经由交换慢慢"浮”到数列的顶端

**算法描述**

1. 比较相邻的元素,如果第一个比第二个大,就交换它们两个
2. 对每一对相邻元素作同样的工作,从开始第一对到结尾的最后一对,这样在最后的元素应该会是最大的数
3. 针对所有的元素重复以上的步骤,除了最后一个
4. 重复步骤1~3,直到排序完成

**动图演示**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123345.gif)

**算法实现**

```java
public static void bubbleSort(int[] arr) {
    int temp = 0;
    for (int i = arr.length - 1; i > 0; i--) { // 每次需要排序的长度
        for (int j = 0; j < i; j++) { // 从第一个元素到第i个元素
            if (arr[j] > arr[j + 1]) {
                temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
            }
        }//loop j
    }//loop i
}// method bubbleSort
```

**稳定性**

在相邻元素相等时,它们并不会交换位置,所以,冒泡排序是稳定排序

**适用场景**

冒泡排序思路简单,代码也简单,特别适合小数据的排序,但是,由于算法复杂度较高,在数据量大的时候不适合使用

**代码优化**

在数据完全有序的时候展现出最优时间复杂度,为O(n),其他情况下,几乎总是O( n2 ),因此,算法在数据基本有序的情况下,性能最好
要使算法在最佳情况下有O(n)复杂度,需要做一些改进,增加一个`swap`的标志,当前一轮没有进行交换时,说明数组已经有序,没有必要再进行下一轮的循环了,直接退出

```java
public static void bubbleSort(int[] arr) {
    int temp = 0;
    boolean swap;
    for (int i = arr.length - 1; i > 0; i--) { // 每次需要排序的长度
        swap=false;
        for (int j = 0; j < i; j++) { // 从第一个元素到第i个元素
            if (arr[j] > arr[j + 1]) {
                temp = arr[j];
                arr[j] = arr[j + 1];
                arr[j + 1] = temp;
                swap=true;
            }
        }//loop j
        if (swap==false){
            break;
        }
    }//loop i
}// method bubbleSort
```

#### 选择排序

选择排序是一种简单直观的排序算法,它也是一种交换排序算法,和冒泡排序有一定的相似度,可以认为选择排序是冒泡排序的一种改进

**算法描述**

1. 在未排序序列中找到最小(大)元素,存放到排序序列的起始位置
2. 从剩余未排序元素中继续寻找最小(大)元素,然后放到已排序序列的末尾
3. 重复第二步,直到所有元素均排序完毕

**动图演示**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123157.gif)

**算法实现**

```java
public static void selectionSort(int[] arr) {
    int temp, min = 0;
    for (int i = 0; i < arr.length - 1; i++) {
        min = i;
        // 循环查找最小值
        for (int j = i + 1; j < arr.length; j++) {
            if (arr[min] > arr[j]) {
                min = j;
            }
        }
        if (min != i) {
            temp = arr[i];
            arr[i] = arr[min];
            arr[min] = temp;
        }
    }
}
```

**稳定性**

用数组实现的选择排序是不稳定的,用链表实现的选择排序是稳定的
不过,一般提到排序算法时,大家往往会默认是数组实现,所以选择排序是不稳定的

**适用场景**

选择排序实现也比较简单,并且由于在各种情况下复杂度波动小,因此一般是优于冒泡排序的,在所有的完全交换排序中,选择排序也是比较不错的一种算法,但是,由于固有的O(n2)复杂度,选择排序在海量数据面前显得力不从心,因此,它适用于简单数据排序

#### 插入排序

插入排序是一种简单直观的排序算法,它的工作原理是通过构建有序序列,对于未排序数据,在已排序序列中从后向前扫描,找到相应位置并插入

**算法描述**

1. 把待排序的数组分成已排序和未排序两部分,初始的时候把第一个元素认为是已排好序的
2. 从第二个元素开始,在已排好序的子数组中寻找到该元素合适的位置并插入该位置
3. 重复上述过程直到最后一个元素被插入有序子数组中

**动图演示**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123205.gif)

**算法实现**

```java
public static void insertionSort(int[] arr){
    for (int i=1; i<arr.length; ++i){
        int value = arr[i];
        int position=i;
        while (position>0 && arr[position-1]>value){
            arr[position] = arr[position-1];
            position--;
        }
        arr[position] = value;
    }//loop i
}
```

**稳定性**

由于只需要找到不大于当前数的位置而并不需要交换,因此,直接插入排序是稳定的排序方法

**适用场景**

插入排序由于O( n2 )的复杂度,在数组较大的时候不适用,但是,在数据比较少的时候,是一个不错的选择,一般做为快速排序的扩充,例如,在STL的sort算法和stdlib的qsort算法中,都将插入排序作为快速排序的补充,用于少量元素的排序,又如,在JDK 7 java.util.Arrays所用的sort方法的实现中,当待排数组长度小于47时,会使用插入排序

#### 归并排序

归并排序是建立在归并操作上的一种有效的排序算法,该算法是采用分治法的一个非常典型的应用,将已有序的子序列合并,得到完全有序的序列,即先使每个子序列有序,再使子序列段间有序,若将两个有序表合并成一个有序表,称为2-路归并

**算法描述**

两种方法

- 递归法(Top-down)

1. 申请空间,使其大小为两个已经排序序列之和,该空间用来存放合并后的序列
2. 设定两个指针,最初位置分别为两个已经排序序列的起始位置
3. 比较两个指针所指向的元素,选择相对小的元素放入到合并空间,并移动指针到下一位置
4. 重复步骤3直到某一指针到达序列尾
5. 将另一序列剩下的所有元素直接复制到合并序列尾

- 迭代法(Bottom-up)

原理如下(假设序列共有n个元素):

1. 将序列每相邻两个数字进行归并操作,形成ceil(n/2)个序列,排序后每个序列包含两/一个元素
2. 若此时序列数不是1个则将上述序列再次归并,形成ceil(n/4)个序列,每个序列包含四/三个元素
3. 重复步骤2,直到所有元素排序完毕,即序列数为1

**动图演示**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123213.gif)

**算法实现**

```java
public static void mergeSort(int[] arr){
    int[] temp =new int[arr.length];
    internalMergeSort(arr, temp, 0, arr.length-1);
}
private static void internalMergeSort(int[] arr, int[] temp, int left, int right){
    //当left==right的时,已经不需要再划分了
    if (left<right){
        int middle = (left+right)/2;
        internalMergeSort(arr, temp, left, middle);          //左子数组
        internalMergeSort(arr, temp, middle+1, right);       //右子数组
        mergeSortedArray(arr, temp, left, middle, right);    //合并两个子数组
    }
}
// 合并两个有序子序列
private static void mergeSortedArray(int arr[], int temp[], int left, int middle, int right){
    int i=left;
    int j=middle+1;
    int k=0;
    while (i<=middle && j<=right){
        temp[k++] = arr[i] <= arr[j] ? arr[i++] : arr[j++];
    }
    while (i <=middle){
        temp[k++] = arr[i++];
    }
    while ( j<=right){
        temp[k++] = arr[j++];
    }
    //把数据复制回原数组
    for (i=0; i<k; ++i){
        arr[left+i] = temp[i];
    }
}
```

**稳定性**

因为我们在遇到相等的数据的时候必然是按顺序"抄写”到辅助数组上的,所以,归并排序同样是稳定算法

**适用场景**

归并排序在数据量比较大的时候也有较为出色的表现(效率上),但是,其空间复杂度O(n)使得在数据量特别大的时候(例如,1千万数据)几乎不可接受,而且,考虑到有的机器内存本身就比较小,因此,采用归并排序一定要注意

#### **快速排序**

快速排序是一个知名度极高的排序算法,其对于大数据的优秀排序性能和相同复杂度算法中相对简单的实现使它注定得到比其他算法更多的宠爱

**算法描述**

1. 从数列中挑出一个元素,称为"基准"(pivot)
2. 重新排序数列,所有比基准值小的元素摆放在基准前面,所有比基准值大的元素摆在基准后面(相同的数可以到任何一边),在这个分区结束之后,该基准就处于数列的中间位置,这个称为分区(partition)操作
3. 递归地(recursively)把小于基准值元素的子数列和大于基准值元素的子数列排序

**动图演示**

![v2-c411339b79f92499dcb7b5](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123302.gif)

**算法实现**

```java
public static void quickSort(int[] arr){
    qsort(arr, 0, arr.length-1);
}
private static void qsort(int[] arr, int low, int high){
    if (low >= high)
        return;
    int pivot = partition(arr, low, high);        //将数组分为两部分
    qsort(arr, low, pivot-1);                   //递归排序左子数组
    qsort(arr, pivot+1, high);                  //递归排序右子数组
}
private static int partition(int[] arr, int low, int high){
    int pivot = arr[low];     //基准
    while (low < high){
        while (low < high && arr[high] >= pivot) --high;
        arr[low]=arr[high];             //交换比基准大的记录到左端
        while (low < high && arr[low] <= pivot) ++low;
        arr[high] = arr[low];           //交换比基准小的记录到右端
    }
    //扫描完成,基准到位
    arr[low] = pivot;
    //返回的是基准的位置
    return low;
}
```

- **稳定性**:快速排序并不是稳定的,这是因为我们无法保证相等的数据按顺序被扫描到和按顺序存放
- **适用场景**:快速排序在大多数情况下都是适用的,尤其在数据量大的时候性能优越性更加明显,但是在必要的时候,需要考虑下优化以提高其在最坏情况下的性能

#### **堆排序**

堆排序(Heapsort)是指利用堆积树(堆)这种数据结构所设计的一种排序算法,它是选择排序的一种,可以利用数组的特点快速定位指定索引的元素,堆排序就是把最大堆堆顶的最大数取出,将剩余的堆继续调整为最大堆,再次将堆顶的最大数取出,这个过程持续到剩余数只有一个时结束

**堆的概念**

堆是一种特殊的完全二叉树(complete binary tree),完全二叉树的一个"优秀”的性质是,除了最底层之外,每一层都是满的,这使得堆可以利用数组来表示(普通的一般的二叉树通常用链表作为基本容器表示),每一个结点对应数组中的一个元素
如下图,是一个堆和数组的相互关系:

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123311.jpeg)


对于给定的某个结点的下标 i,可以很容易的计算出这个结点的父结点,孩子结点的下标:

- Parent(i) = floor(i/2),i 的父节点下标
- Left(i) = 2i,i 的左子节点下标
- Right(i) = 2i + 1,i 的右子节点下标

二叉堆一般分为两种:最大堆和最小堆
**最大堆**
最大堆中的最大元素值出现在根结点(堆顶)
堆中每个父节点的元素值都大于等于其孩子结点(如果存在)

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123316.jpeg)

**最小堆**
最小堆中的最小元素值出现在根结点(堆顶)
堆中每个父节点的元素值都小于等于其孩子结点(如果存在)

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123319.jpeg)

**堆排序原理**

堆排序就是把最大堆堆顶的最大数取出,将剩余的堆继续调整为最大堆,再次将堆顶的最大数取出,这个过程持续到剩余数只有一个时结束,在堆中定义以下几种操作:

- 最大堆调整(Max-Heapify):将堆的末端子节点作调整,使得子节点永远小于父节点
- 创建最大堆(Build-Max-Heap):将堆所有数据重新排序,使其成为最大堆
- 堆排序(Heap-Sort):移除位在第一个数据的根节点,并做最大堆调整的递归运算 继续进行下面的讨论前,需要注意的一个问题是:数组都是 Zero-Based,这就意味着我们的堆数据结构模型要发生改变

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123329.jpeg)


相应的,几个计算公式也要作出相应调整:

- Parent(i) = floor((i-1)/2),i 的父节点下标
- Left(i) = 2i + 1,i 的左子节点下标
- Right(i) = 2(i + 1),i 的右子节点下标

**堆的建立和维护**

堆可以支持多种操作,但现在我们关心的只有两个问题:

1. 给定一个无序数组,如何建立为堆？
2. 删除堆顶元素后,如何调整数组成为新堆？

先看第二个问题,假定我们已经有一个现成的大根堆,现在我们删除了根元素,但并没有移动别的元素,想想发生了什么:根元素空了,但其它元素还保持着堆的性质,我们可以把**最后一个元素**(代号A)移动到根元素的位置,如果不是特殊情况,则堆的性质被破坏,但这仅仅是由于A小于其某个子元素,于是,我们可以把A和这个子元素调换位置,如果A大于其所有子元素,则堆调整好了,否则,重复上述过程,A元素在树形结构中不断"下沉”,直到合适的位置,数组重新恢复堆的性质,上述过程一般称为"筛选”,方向显然是自上而下

> 删除后的调整,是把最后一个元素放到堆顶,自上而下比较

删除一个元素是如此,插入一个新元素也是如此,不同的是,我们把新元素放在**末尾**,然后和其父节点做比较,即自下而上筛选

> 插入是把新元素放在末尾,自下而上比较

那么,第一个问题怎么解决呢？

常规方法是从第一个非叶子结点向下筛选,直到根元素筛选完毕,这个方法叫"筛选法”,需要循环筛选n/2个元素

但我们还可以借鉴"插入排序”的思路,我们可以视第一个元素为一个堆,然后不断向其中添加新元素,这个方法叫做"插入法”,需要循环插入(n-1)个元素

由于筛选法和插入法的方式不同,所以,相同的数据,它们建立的堆一般不同,大致了解堆之后,堆排序就是水到渠成的事情了

**动图演示**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/v2-c66a7e83189427b6a5a5c378f73c17ca_b.gif)

**算法描述**

我们需要一个升序的序列,怎么办呢？我们可以建立一个最小堆,然后每次输出根元素,但是,这个方法需要额外的空间(否则将造成大量的元素移动,其复杂度会飙升到O(n2)),如果我们需要就地排序(即不允许有O(n)空间复杂度),怎么办？

有办法,我们可以建立最大堆,然后我们倒着输出,在最后一个位置输出最大值,次末位置输出次大值……由于每次输出的最大元素会腾出第一个空间,因此,我们恰好可以放置这样的元素而不需要额外空间,很漂亮的想法,是不是？

**算法实现**

```java
public class ArrayHeap {
    private int[] arr;
    public ArrayHeap(int[] arr) {
        this.arr = arr;
    }
    private int getParentIndex(int child) {
        return (child - 1) / 2;
    }
    private int getLeftChildIndex(int parent) {
        return 2 * parent + 1;
    }
    private void swap(int i, int j) {
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
    }
    /**
     * 调整堆
     */
    private void adjustHeap(int i, int len) {
        int left, right, j;
        left = getLeftChildIndex(i);
        while (left <= len) {
            right = left + 1;
            j = left;
            if (j < len && arr[left] < arr[right]) {
                j++;
            }
            if (arr[i] < arr[j]) {
                swap(array, i, j);
                i = j;
                left = getLeftChildIndex(i);
            } else {
                break; // 停止筛选
            }
        }
    }
    /**
     * 堆排序
     * */
    public void sort() {
        int last = arr.length - 1;
        // 初始化最大堆
        for (int i = getParentIndex(last); i >= 0; --i) {
            adjustHeap(i, last);
        }
        // 堆调整
        while (last >= 0) {
            swap(0, last--);
            adjustHeap(0, last);
        }
    }

}
```

**稳定性**

堆排序存在大量的筛选和移动过程,属于不稳定的排序算法

**适用场景**

堆排序在建立堆和调整堆的过程中会产生比较大的开销,在元素少的时候并不适用,但是,在元素比较多的情况下,还是不错的一个选择,尤其是在解决诸如"前n大的数”一类问题时,几乎是首选算法

#### **希尔排序(插入排序的改良版)**

在希尔排序出现之前,计算机界普遍存在"排序算法不可能突破O(n2)”的观点,希尔排序是第一个突破O(n2)的排序算法,它是简单插入排序的改进版,希尔排序的提出,主要基于以下两点:

1. 插入排序算法在数组基本有序的情况下,可以近似达到O(n)复杂度,效率极高
2. 但插入排序每次只能将数据移动一位,在数组较大且基本无序的情况下性能会迅速恶化

**算法描述**

先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序,具体算法描述:

- 选择一个增量序列t1,t2,…,tk,其中ti>tj,tk=1
- 按增量序列个数k,对序列进行 k 趟排序
- 每趟排序,根据对应的增量ti,将待排序列分割成若干长度为m 的子序列,分别对各子表进行直接插入排序,仅增量因子为1 时,整个序列作为一个表来处理,表长度即为整个序列的长度

**动图演示**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123335.gif)

**算法实现**

Donald Shell增量

```java
public static void shellSort(int[] arr){
    int temp;
    for (int delta = arr.length/2; delta>=1; delta/=2){                              //对每个增量进行一次排序
        for (int i=delta; i<arr.length; i++){
            for (int j=i; j>=delta && arr[j]<arr[j-delta]; j-=delta){ //注意每个地方增量和差值都是delta
                temp = arr[j-delta];
                arr[j-delta] = arr[j];
                arr[j] = temp;
            }
        }//loop i
    }//loop delta
}
```

O(n3/2) by Knuth

```java
public static void shellSort2(int[] arr){
    int delta = 1;
    while (delta < arr.length/3){//generate delta
        delta=delta*3+1;    // <O(n^(3/2)) by Knuth,1973>: 1, 4, 13, 40, 121, ...
    }
    int temp;
    for (; delta>=1; delta/=3){
        for (int i=delta; i<arr.length; i++){
            for (int j=i; j>=delta && arr[j]<arr[j-delta]; j-=delta){
                temp = arr[j-delta];
                arr[j-delta] = arr[j];
                arr[j] = temp;
            }
        }//loop i
    }//loop delta
}
```

**希尔排序的增量**

希尔排序的增量数列可以任取,需要的唯一条件是最后一个一定为1(因为要保证按1有序),但是,不同的数列选取会对算法的性能造成极大的影响,上面的代码演示了两种增量
切记:增量序列中每两个元素最好不要出现1以外的公因子!(很显然,按4有序的数列再去按2排序意义并不大)
下面是一些常见的增量序列
\- 第一种增量是最初Donald Shell提出的增量,即折半降低直到1,据研究,使用希尔增量,其时间复杂度还是O(n2)

第二种增量Hibbard:{1, 3, ..., 2k-1},该增量序列的时间复杂度大约是O(n1.5)

第三种增量Sedgewick增量:(1, 5, 19, 41, 109,...),其生成序列或者是9*4i* *- 9*2i + 1或者是4i - 3*2i + 1

**稳定性**

我们都知道插入排序是稳定算法,但是,Shell排序是一个多次插入的过程,在一次插入中我们能确保不移动相同元素的顺序,但在多次的插入中,相同元素完全有可能在不同的插入轮次被移动,最后稳定性被破坏,因此,Shell排序不是一个稳定的算法

**适用场景**

Shell排序虽然快,但是毕竟是插入排序,其数量级并没有后起之秀--快速排序O(n㏒n)快,在大量数据面前,Shell排序不是一个好的算法,但是,中小型规模的数据完全可以使用它

#### **计数排序**

计数排序不是基于比较的排序算法,其核心在于将输入的数据值转化为键存储在额外开辟的数组空间中,作为一种线性时间复杂度的排序,计数排序要求输入的数据必须是有确定范围的整数

**算法描述**

1. 找出待排序的数组中最大和最小的元素
2. 统计数组中每个值为i的元素出现的次数,存入数组C的第i项
3. 对所有的计数累加(从C中的第一个元素开始,每一项和前一项相加)
4. 反向填充目标数组:将每个元素i放在新数组的第C(i)项,每放一个元素就将C(i)减去1

**动图演示**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/v2-3c7ddb59df2d21b287e42a7b908409cb_b.gif)

**算法实现**

```java
public static void countSort(int[] a, int max, int min) {
     int[] b = new int[a.length];//存储数组
     int[] count = new int[max - min + 1];//计数数组

     for (int num = min; num <= max; num++) {
        //初始化各元素值为0,数组下标从0开始因此减min
        count[num - min] = 0;
     }

     for (int i = 0; i < a.length; i++) {
        int num = a[i];
        count[num - min]++;//每出现一个值,计数数组对应元素的值+1
     }

     for (int num = min + 1; num <= max; num++) {
        //加总数组元素的值为计数数组对应元素及左边所有元素的值的总和
        count[num - min] += sum[num - min - 1]
     }

     for (int i = 0; i < a.length; i++) {
          int num = a[i];//源数组第i位的值
          int index = count[num - min] - 1;//加总数组中对应元素的下标
          b[index] = num;//将该值存入存储数组对应下标中
          count[num - min]--;//加总数组中,该值的总和减少1
     }

     //将存储数组的值一一替换给源数组
     for(int i=0;i<a.length;i++){
         a[i] = b[i];
     }
}
```

**稳定性**

最后给 b 数组赋值是倒着遍历的,而且放进去一个就将C数组对应的值(表示前面有多少元素小于或等于A[i])减去一,如果有相同的数x1,x2,那么相对位置后面那个元素x2放在(比如下标为4的位置),相对位置前面那个元素x1下次进循环就会被放在x2前面的位置3,从而保证了稳定性

**适用场景**

排序目标要能够映射到整数域,其最大值最小值应当容易辨别,例如高中生考试的总分数,显然用0-750就OK啦,又比如一群人的年龄,用个0-150应该就可以了,再不济就用0-200喽,另外,计数排序需要占用大量空间,它比较适用于数据比较集中的情况

#### **桶排序**

桶排序又叫箱排序,是计数排序的升级版,它的工作原理是将数组分到有限数量的桶子里,然后对每个桶子再分别排序(有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序),最后将各个桶中的数据有序的合并起来

> 计数排序是桶排序的一种特殊情况,可以把计数排序当成每个桶里只有一个元素的情况,网络中很多博文写的桶排序实际上都是计数排序,并非标准的桶排序,要注意辨别

**算法描述**

1. 找出待排序数组中的最大值max,最小值min
2. 我们使用 动态数组ArrayList 作为桶,桶里放的元素也用 ArrayList 存储,桶的数量为(max-min)/arr.length+1
3. 遍历数组 arr,计算每个元素 arr[i] 放的桶
4. 每个桶各自排序
5. 遍历桶数组,把排序好的元素放进输出数组

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/v2-465190477b7fb90d17aef27c2a213368_720w.jpg)

**算法实现**

```java
public static void bucketSort(int[] arr){
    int max = Integer.MIN_VALUE;
    int min = Integer.MAX_VALUE;
    for(int i = 0; i < arr.length; i++){
        max = Math.max(max, arr[i]);
        min = Math.min(min, arr[i]);
    }
    //桶数
    int bucketNum = (max - min) / arr.length + 1;
    ArrayList<ArrayList<Integer>> bucketArr = new ArrayList<>(bucketNum);
    for(int i = 0; i < bucketNum; i++){
        bucketArr.add(new ArrayList<Integer>());
    }
    //将每个元素放入桶
    for(int i = 0; i < arr.length; i++){
        int num = (arr[i] - min) / (arr.length);
        bucketArr.get(num).add(arr[i]);
    }
    //对每个桶进行排序
    for(int i = 0; i < bucketArr.size(); i++){
        Collections.sort(bucketArr.get(i));
    }
    System.out.println(bucketArr.toString());
}
```

**稳定性**

可以看出,在分桶和从桶依次输出的过程是稳定的,但是,由于我们在对每个桶进行排序时使用了其他算法,所以,桶排序的稳定性依赖于这一步,如果我们使用了快排,显然,算法是不稳定的

**适用场景**

桶排序可用于最大最小值相差较大的数据情况,但桶排序要求数据的分布必须均匀,否则可能导致数据都集中到一个桶中,比如[104,150,123,132,20000], 这种数据会导致前4个数都集中到同一个桶中,导致桶排序失效

#### **基数排序**

基数排序(Radix Sort)是桶排序的扩展,它的基本思想是:将整数按位数切割成不同的数字,然后按每个位数分别比较
排序过程:将所有待比较数值(正整数)统一为同样的数位长度,数位较短的数前面补零,然后,从最低位开始,依次进行一次排序,这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列

**算法描述**

1. 取得数组中的最大数,并取得位数
2. arr为原始数组,从最低位开始取每个位组成radix数组
3. 对radix进行计数排序(利用计数排序适用于小范围数的特点)

**动图**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/v2-3a6f1e5059386523ed941f0d6c3a136e_b.gif)

**算法实现**

```java
public abstract class Sorter {
     public abstract void sort(int[] array);
}

public class RadixSorter extends Sorter {

     private int radix;

     public RadixSorter() {
          radix = 10;
     }

     @Override
     public void sort(int[] array) {
          // 数组的第一维表示可能的余数0-radix,第二维表示array中的等于该余数的元素
          // 如:十进制123的个位为3,则bucket[3][] = {123}
          int[][] bucket = new int[radix][array.length];
          int distance = getDistance(array); // 表示最大的数有多少位
          int temp = 1;
          int round = 1; // 控制键值排序依据在哪一位
          while (round <= distance) {
               // 用来计数:数组counter[i]用来表示该位是i的数的个数
               int[] counter = new int[radix];
               // 将array中元素分布填充到bucket中,并进行计数
               for (int i = 0; i < array.length; i++) {
                    int which = (array[i] / temp) % radix;
                    bucket[which][counter[which]] = array[i];
                    counter[which]++;
               }
               int index = 0;
               // 根据bucket中收集到的array中的元素,根据统计计数,在array中重新排列
               for (int i = 0; i < radix; i++) {
                    if (counter[i] != 0)
                         for (int j = 0; j < counter[i]; j++) {
                              array[index] = bucket[i][j];
                              index++;
                         }
                    counter[i] = 0;
               }
               temp *= radix;
               round++;
          }
     }

     private int getDistance(int[] array) {
          int max = computeMax(array);
          int digits = 0;
          int temp = max / radix;
          while(temp != 0) {
               digits++;
               temp = temp / radix;
          }
          return digits + 1;
     }

     private int computeMax(int[] array) {
          int max = array[0];
          for(int i=1; i<array.length; i++) {
               if(array[i]>max) {
                    max = array[i];
               }
          }
          return max;
     }
}
```

**稳定性**

通过上面的排序过程,我们可以看到,每一轮映射和收集操作,都保持从左到右的顺序进行,如果出现相同的元素,则保持他们在原始数组中的顺序,可见,基数排序是一种稳定的排序

**适用场景**

基数排序要求较高,元素必须是整数,整数时长度10W以上,最大值100W以下效率较好,但是基数排序比其他排序好在可以适用字符串,或者其他需要根据多个条件进行排序的场景,例如日期,先排序日,再排序月,最后排序年,其它排序算法可是做不了的

#### **总结**

<img src="https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-14-v2-f718f6b01ad35a60b9d4f02330f81439_720w.jpg" alt="img" style="zoom:50%;" />

### 为什么先序中序可以决定一颗树

前序和后序在本质上都是将父节点与子结点进行分离,但并没有指明左子树和右子树的能力,因此得到这两个序列只能明确父子关系,而不能确定一个二叉树

### 二叉树遍历

- 前序遍历:根结点 ---> 左子树 ---> 右子树
- 中序遍历:左子树---> 根结点 ---> 右子树
- 后序遍历:左子树 ---> 右子树 ---> 根结点
- 层次遍历:只需按层次遍历即可

<img src="https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-23-image-20210423144633672.png" alt="image-20210423144633672" style="zoom:50%;" />

- 前序遍历:1  2  4  5  7  8  3  6
- 中序遍历:4  2  7  5  8  1  3  6
- 后序遍历:4  7  8  5  2  6  3  1
- 层次遍历:1  2  3  4  5  6  7  8

一,前序遍历

1)根据上文提到的遍历思路:根结点 ---> 左子树 ---> 右子树,很容易写出递归版本:

```java
public void preOrderTraverse1(TreeNode root) {
  if (root != null) {
    System.out.print(root.val+"  ");
    preOrderTraverse1(root.left);
    preOrderTraverse1(root.right);
  }
}
```

2)现在讨论非递归的版本:
根据前序遍历的顺序,优先访问根结点,然后在访问左子树和右子树,所以,对于任意结点node,第一部分即直接访问之,之后在判断左子树是否为空,不为空时即重复上面的步骤,直到其为空,若为空,则需要访问右子树,注意,在访问过左孩子之后,需要反过来访问其右孩子,所以,需要栈这种数据结构的支持,对于任意一个结点node,具体步骤如下:

a)访问之,并把结点node入栈,当前结点置为左孩子

b)判断结点node是否为空,若为空,则取出栈顶结点并出栈,将右孩子置为当前结点,否则重复a)步直到当前结点为空或者栈为空(可以发现栈中的结点就是为了访问右孩子才存储的)

代码如下:

```java
public void preOrderTraverse2(TreeNode root) {
  LinkedList<TreeNode> stack = new LinkedList<>();
  TreeNode pNode = root;
  while (pNode != null || !stack.isEmpty()) {
    if (pNode != null) {
      System.out.print(pNode.val+"  ");
      stack.push(pNode);
      pNode = pNode.left;
    } else { //pNode == null && !stack.isEmpty()
      TreeNode node = stack.pop();
      pNode = node.right;
    }
  }
}
```

二,中序遍历
1)根据上文提到的遍历思路:左子树 ---> 根结点 ---> 右子树,很容易写出递归版本:

```java
public void inOrderTraverse1(TreeNode root) {
  if (root != null) {
    inOrderTraverse1(root.left);
    System.out.print(root.val+"  ");
    inOrderTraverse1(root.right);
  }
}
```

2)非递归实现,有了上面前序的解释,中序也就比较简单了,相同的道理,只不过访问的顺序移到出栈时,代码如下:

```java
public void inOrderTraverse2(TreeNode root) {
  LinkedList<TreeNode> stack = new LinkedList<>();
  TreeNode pNode = root;
  while (pNode != null || !stack.isEmpty()) {
    if (pNode != null) {
      stack.push(pNode);
      pNode = pNode.left;
    } else { //pNode == null && !stack.isEmpty()
      TreeNode node = stack.pop();
      System.out.print(node.val+"  ");
      pNode = node.right;
    }
  }
}
```

三,后序遍历

1)根据上文提到的遍历思路:左子树 ---> 右子树 ---> 根结点,很容易写出递归版本:

```java
public void postOrderTraverse1(TreeNode root) {
  if (root != null) {
    postOrderTraverse1(root.left);
    postOrderTraverse1(root.right);
    System.out.print(root.val+"  ");
  }
}
```

2)非递归的代码,暂且不写

```java

    public static void postTraverse(TreeNode node) {
        if (node == null)
            return;
        Deque<TreeNode> s = new LinkedList<>();

        TreeNode curNode; //当前访问的结点
        TreeNode lastVisitNode; //上次访问的结点
        curNode = node;
        lastVisitNode = null;

        //把currentNode移到左子树的最下边
        while (curNode != null) {
            s.push(curNode);
            curNode = curNode.left;
        }
        while (!s.isEmpty()) {
            curNode = s.pop();  //弹出栈顶元素
            //一个根节点被访问的前提是:无右子树或右子树已被访问过
            if (curNode.right != null && curNode.right != lastVisitNode) {
                //根节点再次入栈
                s.push(curNode);
                //进入右子树,且可肯定右子树一定不为空
                curNode = curNode.right;
                while (curNode != null) {
                    //再走到右子树的最左边
                    s.push(curNode);
                    curNode = curNode.left;
                }
            } else {
                //访问
                System.out.print(curNode.val + "  ");
                //修改最近被访问的节点
                lastVisitNode = curNode;
            }
        } //while
```

四,层次遍历

层次遍历的代码比较简单,只需要一个队列即可,先在队列中加入根结点,之后对于任意一个结点来说,在其出队列的时候,访问之,同时如果左孩子和右孩子有不为空的,入队列,代码如下:

```java
public void levelTraverse(TreeNode root) {
  if (root == null) {
    return;
  }
  LinkedList<TreeNode> queue = new LinkedList<>();
  queue.offer(root);
  while (!queue.isEmpty()) {
    TreeNode node = queue.poll();
    System.out.print(node.val+"  ");
    if (node.left != null) {
      queue.offer(node.left);
    }
    if (node.right != null) {
      queue.offer(node.right);
    }
  }
}
```

五,深度优先遍历
其实深度遍历就是上面的前序,中序和后序,但是为了保证与广度优先遍历相照应,也写在这,代码也比较好理解,其实就是前序遍历,代码如下:

```java
public void depthOrderTraverse(TreeNode root) {
  if (root == null) {
    return;
  }
  LinkedList<TreeNode> stack = new LinkedList<>();
  stack.push(root);
  while (!stack.isEmpty()) {
    TreeNode node = stack.pop();
    System.out.print(node.val+"  ");
    if (node.right != null) {
      stack.push(node.right);
    }
    if (node.left != null) {
      stack.push(node.left);
    }
  }
}
```

### DCL

```java
public class LazyMan {

  private LazyMan() {
    System.out.println(Thread.currentThread().getName());
  }

  private volatile static LazyMan lazyman;

  public static LazyMan getInstance() {
    if (lazyman == null) {
      synchronized (LazyMan.class) {
        if (lazyman == null) {
          lazyman = new LazyMan();
        }
      }
    }
    return lazyman;
  }

  // 模拟多线程并发
  public static void main(String[] args) {
    for (int i = 0; i < 10; i++) {
      new Thread(() -> {
        LazyMan.getInstance();
      }).start();
    }
  }
}
```

### 用Java写一个冒泡排序

冒泡排序几乎是个程序员都写得出来,但是面试的时候如何写一个逼格高的冒泡排序却不是每个人都能做到,下面提供一个参考代码:

```java
import java.util.Comparator;

/**
 * 排序器接口(策略模式: 将算法封装到具有共同接口的独立的类中使得它们可以相互替换)
 *
 */
public interface Sorter {

  /**
    * 排序
    * @param list 待排序的数组
    */
  public <T extends Comparable<T>> void sort(T[] list);

  /**
    * 排序
    * @param list 待排序的数组
    * @param comp 比较两个对象的比较器
    */
  public <T> void sort(T[] list, Comparator<T> comp);
}
```

```java
import java.util.Comparator;

/**
 * 冒泡排序
 *
 * @author骆昊
 *
 */
public class BubbleSorter implements Sorter {

  @Override
  public <T extends Comparable<T>> void sort(T[] list) {
    boolean swapped = true;
    for (int i = 1, len = list.length; i < len && swapped; ++i) {
      swapped = false;
      for (int j = 0; j < len - i; ++j) {
        if (list[j].compareTo(list[j + 1]) > 0) {
          T temp = list[j];
          list[j] = list[j + 1];
          list[j + 1] = temp;
          swapped = true;
        }
      }
    }
  }

  @Override
  public <T> void sort(T[] list, Comparator<T> comp) {
    boolean swapped = true;
    for (int i = 1, len = list.length; i < len && swapped; ++i) {
      swapped = false;
      for (int j = 0; j < len - i; ++j) {
        if (comp.compare(list[j], list[j + 1]) > 0) {
          T temp = list[j];
          list[j] = list[j + 1];
          list[j + 1] = temp;
          swapped = true;
        }
      }
    }
  }
}
```

### 用Java写一个折半查找

折半查找,也称二分查找,二分搜索,是一种在有序数组中查找某一特定元素的搜索算法,搜素过程从数组的中间元素开始,如果中间元素正好是要查找的元素,则搜素过程结束,如果某一特定元素大于或者小于中间元素,则在数组大于或小于中间元素的那一半中查找,而且跟开始一样从中间元素开始比较,如果在某一步骤数组已经为空,则表示找不到指定的元素,这种搜索算法每一次比较都使搜索范围缩小一半,其时间复杂度是O(logN)

```java
import java.util.Comparator;

public class MyUtil {

  public static <T extends Comparable<T>> int binarySearch(T[] x, T key) {
    return binarySearch(x, 0, x.length- 1, key);
  }

  // 使用循环实现的二分查找
  public static <T> int binarySearch(T[] x, T key, Comparator<T> comp) {
    int low = 0;
    int high = x.length - 1;
    while (low <= high) {
      int mid = (low + high) >>> 1;
      int cmp = comp.compare(x[mid], key);
      if (cmp < 0) {
        low= mid + 1;
      }
      else if (cmp > 0) {
        high= mid - 1;
      }
      else {
        return mid;
      }
    }
    return -1;
  }

  // 使用递归实现的二分查找
  private static<T extends Comparable<T>> int binarySearch(T[] x, int low, int high, T key) {
    if(low <= high) {
      int mid = low + ((high -low) >> 1);
      if(key.compareTo(x[mid])== 0) {
        return mid;
      }
      else if(key.compareTo(x[mid])< 0) {
        return binarySearch(x,low, mid - 1, key);
      }
      else {
        return binarySearch(x,mid + 1, high, key);
      }
    }
    return -1;
  }
}
```

> **说明**:上面的代码中给出了折半查找的两个版本,一个用递归实现,一个用循环实现,需要注意的是计算中间位置时不应该使用(high+ low) / 2的方式,因为加法运算可能导致整数越界,这里应该使用以下三种方式之一:low + (high - low) / 2或low + (high – low) >> 1或(low + high) >>> 1(>>>是逻辑右移,是不带符号位的右移)

## 操作系统

### 进程与线程的区别

- 进程是系统进行资源分配和调度的一个独立单位,线程是进程的一个实体,是CPU调度和分派的基本单位
- 一个程序至少一个进程,一个进程至少一个线程
- 每个进程都有独立的内存地址空间,系统不会为线程分配内存,线程组之间只能共享所属进程的资源
- 程序之间的切换会有较大的开销而线程之间切换的开销小
    - 每当切换进程时,必须要考虑保存当前进程的状态,状态包括存放在内存中的程序的代码和数据,它的栈,通用目的寄存器的内容,程序计数器,环境变量以及打开的文件描述符的集合,这个状态叫做上下文(Context)
    - 同样线程有自己的上下文,包括唯一的整数线程ID,栈,栈指针,程序计数器,通用目的寄存器和条件码,可以理解为线程上下文是进程上下文的子集
    - 由于保存线程的上下文明显比进程的上下文小,因此系统切换线程时,必然开销更小

### 进程的状态

- 就绪(Ready)状态:当进程已分配到除CPU以外的所有必要资源后,只要再获得CPU,便可立即执行,进程这时的状态称为就绪状态,在一个系统中处于就绪状态的进程可能有多个,通常将它们排成一个队列,称为就绪队列
- 执行状态:进程已获得CPU,其程序正在执行,在单处理机系统中,只有一个进程处于执行状态,在多处理机系统中,则有多个进程处于执行状态
- 阻塞状态:正在执行的进程由于发生某事件而暂时无法继续执行时,便放弃处理机而处于暂停状态,亦即进程的执行受到阻塞,把这种暂停状态称为阻塞状态,有时也称为等待状态或封锁状态,致使进程阻塞的典型事件有:请求I/O,申请缓冲空间等,通常将这种处于阻塞状态的进程也排成一个队列,有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列

**三者的转换图如下**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123413.png)

- **创建状态**:创建一个进程一般要通过两个步骤
    1. 为一个新进程创建PCB,并填写必要的管理信息
    2. 把该进程转入就绪状态并插入就绪队列之中,当一个新进程被创建时,系统已为其分配了PCB,填写了进程标识等信息,但由于该进程所必需的资源或其它信息,如主存资源尚未分配等,一般而言,此时的进程已拥有了自己PCB,但进程自身还未进入主存,即创建工作尚未完成,进程还不能被调度运行,其所处的状态就是创建状态,引入创建状态,是为了保证进程的调度必须在创建工作完成后进行,以确保对进程控制块操作的完整性,同时,创建状态的引入,也增加了管理的灵活性,操作系统可以根据系统性能或主存容量的限制,推迟创建状态进程的提交,对于处于创建状态的进程,获得了其所必需的资源,以及对其PCB初始化工作完成后,进程状态便可由创建状态转入就绪状态
- **终止状态**:等待操作系统进行善后处理,然后将其PCB清零,并将PCB空间返还系统,当一个进程到达了自然结束点,或是出现了无法克服的错误,或是被操作系统所终结,或是被其他有终止权的进程所终结,它将进入终止状态,进入终止态的进程以后不能再执行,但在操作系统中依然保留一个记录,其中保存状态码和一些计时统计数据,供其它进程收集,一旦其它进程完成了对终止状态进程的信息提取之后,操作系统将删除该进程
- 增加了创建状态和终止状态后,进程的三种基本状态及转换图衍变为五种状态及转换关系图

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123448.png)

- **挂起状态**:在不少系统中进程只有上述三种状态,但在另一些系统中,又增加了一些新状态,最重要的是挂起状态,引入挂起状态的原因有:
    -  终端用户的请求,当终端用户在自己的程序运行期间发现有可疑问题时,希望暂时使自己的程序静止下来,亦即,使正在执行的进程暂停执行,若此时用户进程正处于就绪状态而未执行,则该进程暂不接受调度,以便用户研究其执行情况或对程序进行修改,我们把这种静止状态称为挂起状态
    - 父进程请求,有时父进程希望挂起自己的某个子进程,以便考查和修改该子进程,或者协调各子进程间的活动
    - 负荷调节的需要,当实时系统中的工作负荷较重,已可能影响到对实时任务的控制时,可由系统把一些不重要的进程挂起,以保证系统能正常运行
    - 操作系统的需要,操作系统有时希望挂起某些进程,以便检查运行中的资源使用情况或进行记账

**具有挂起状态的转换图**

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123425.jpeg)

### 死锁

-  AB两个线程由于互相持有对方需要的锁,而发生的阻塞现象,我们称为死锁
  -   **互斥条件**:一个资源每次只能被一个进程使用
  - **请求与保持**:一个进程因请求资源而阻塞时,对已获得的资源保持不放
  - **不剥夺条件**:进程已获得的资源,在末使用完之前,不能强行剥夺
  - **循环等待条件**:若干进程之间形成一种头尾相接的循环等待资源关系
- 这四个条件是死锁的必要条件,只要系统发生死锁,这些条件必然成立,而只要上述条件之一不成立,则死锁解除

**预防死锁**:执行获取锁的顺序,并强制要求线程按照指定的顺序获取锁

### 并发与并行

-   并行是指两个或者多个事件在同一时刻发生,而并发是指两个或多个事件在同一时间间隔发生
-   并发:一个处理器同时处理多个任务
-   并行:多个处理器或者是多核的处理器同时处理多个不同的任务

### 同步和异步

-   同步和异步关注的是消息通信机制,所谓同步,就是在发出一个调用时,在没有得到结果之前,该调用就不返回,但是一旦调用返回,就得到返回值了,换句话说,就是由调用者主动等待这个调用的结果
-   而异步则是相反,调用在发出之后,这个调用就直接返回了,所以没有返回结果,换句话说,当一个异步过程调用发出后,调用者不会立刻得到结果,而是在调用发出后,被调用者通过状态,通知机制来通知调用者,或通过回调函数处理这个调用

### 阻塞与非阻塞

-   阻塞与非阻塞关注的是程序在等待调用结果(消息,返回值)时的状态
-   阻塞调用时指调用结果返回之前,当前线程被挂起,调用线程只有在得到结果之后才会返回
-   非阻塞调用时指在不能立刻得到结果之前,该调用不会阻塞当前线程

### 页式存储

- 主存被等分成大小相等的片，称为主存块，又称为实页
- 当一个用户程序装入内存时，以页面为单位进行分配。页面的大小是为<span>2n ,</span>通常为<span>1KB</span>、<span>2KB</span>、<span>2n KB</span>等

## 计算机网络

### OSI七层模型和协议

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2021-04-21-v2-2d62ba265be486cb94ab531912aa3b9c_720w.jpg)

### 常见状态码

| 状态码 | 原因短语                               |
| :----- | :------------------------------------- |
| 200    | OK (成功)                              |
| 301    | Moved Permanently (永久移动)           |
| 302    | Found (临时移动)                       |
| 304    | Not Modified (未修改)                  |
| 400    | Bad Request (错误请求)                 |
| 401    | Unauthorized (未授权)                  |
| 403    | Forbidden (禁止访问)                   |
| 404    | Not Found (未找到)                     |
| 500    | Internal Server Error (内部服务器错误) |
| 502    | Bad Gateway (网关错误)                 |
| 503    | Service Unavailable (服务不可用)       |

### TCP三次握手,四次挥手的过程

**握手过程**

1. 主机A向主机B发送请求连接数据报,其中包括A的序列号`seq=x`,请求连接的标志位`SYN=1`
2. 主机B收到请求之后返回确认连接数据报,其中包括B的序列号`seq=y`,请求连接的标志位`SYN=1`,`ACK=1`还有一个确认号,`ack=x+1`
3. 主机A收到了B的确认报文后再次做出确认,再发送一个数据报,其中包括:`ACK=1`,`seq=x+1`,`ack=y+1`

- 至于为什么要发送第三条是因为在发送第一条的时候,可能因为网络原因导致数据报滞留,那么超过一定时间主机A会再次发送请求连接的数据报文,之后主机B返回确认连接报文,如果主机A收到确认报文之后不发送第三条报文告诉主机B自己已经收到了,那么B其实是不知道的,这时候可能A第一次发送的原本滞留的报文突然正常了,B就再次收到了请求连接的报文,但是实际上A已经连接了

**挥手过程**

1. 客户端向服务器发送一个请求断开连接的数据报,终止位`FIN=1`,序列号`seq=u`
2. 服务器收到请求后返回`ACK=1`,`seq=v`,`ack=u+1`,之后客户端通往服务器的单向连接就断开了
3. 之后服务器也需要和客户端断开连接,也是发送了一个FIN
4. 客户端收到FIN后返回ACK,并将确认号设置为收到的序号+1

- 其实在客户端断开和服务器的单向连接之后,服务器仍然可以往客户端发送数据
- 客户端需要最后等一段时间才能进入关闭状态是因为:客户端无法保证最后发送的ACK报文会一定被对方收到,所以有时候需要重发可能丢失的ACK报文

### HTTP与HTTPS的区别

- https协议要申请证书到ca,需要一定经济成本
- http是明文传输,https是加密的安全传输
- 连接的端口不一样,http是80,https是443
- http连接很简单,没有状态
- https是ssl加密的传输,身份认证的网络协议,相对http传输比较安全

### SSL四次握手

1. **客户端发出请求** :首先,客户端(通常是浏览器)先向服务器发出加密通信的请求,这被叫做ClientHello请求
2. **服务器回应**:服务器收到客户端请求后,向客户端发出回应,这叫做SeverHello
3. **客户端回应**:客户端收到服务器回应以后,首先验证服务器证书,如果证书不是可信机构颁布,或者证书中的域名与实际域名不一致,或者证书已经过期,就会向访问者显示一个警告,由其选择是否还要继续通信
4. **服务器的最后回应**:服务器收到客户端的第三个随机数pre-master key之后,计算生成本次会话所用的"会话密钥",然后,向客户端最后发送下面信息
    1. 编码改变通知,表示随后的信息都将用双方商定的加密方法和密钥发送
    2. 服务器握手结束通知,表示服务器的握手阶段已经结束,这一项同时也是前面发送的所有内容的hash值,用来供客户端校验
5. 至此,整个握手阶段全部结束,接下来,客户端与服务器进入加密通信,就完全是使用普通的HTTP协议,只不过用"会话密钥"加密内容

### ARP协议与ARP攻击

- 用于在网络层将IP数据报的IP地址转化为物理地址
- 首先向ARP高速缓存寻找IP地址对应的MAC地址,如果有直接发送,没有直接广播,其余主机收到后直接抛弃

### ICMP协议

- Ping 的原理是 ICMP 协议:确认IP包是否成功送达目标地址以及通知在发送过程当中IP包被废弃的具体原因
- 差错报文,例如:差错报文,时间超过报文
- 询问报文:回送请求,应答报文,时间戳报文

### IP地址

![image-20200520145902844](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/2020-12-10-la9Hrsd8OPA1Jk6.png)

### IP数据报的格式

首部长度固定,占20B

- 版本,指IP版本(占4位)
- 首部长度,以32位为单位即4B,最常用的首部长度是20B,(占4位)
- 总长度,单位为字节,以太网的最大传送单元(MTU)为1500B,(占16位),因此IP数据报的最大长度是2^16
- 标识,占16位,如果IP数据报被分割成很多分组,标识就用来标识这些分组是属于哪个数据报的
- 片偏移,占13位,以8B为单位,无论你属于哪个分片,片偏移都是针对0B来说的
- 首部校验和,只校验首部
- 生存时间(TTL)占8位,数据报在网络中路由器的数目,最多只能转发16次
- 协议 指出该分组的数据应该交给哪个传输层协议,6标识TCP协议,17表示UDP协议
- 源地址字段(占4B)表示发送方的IP的地址
- 目的地址(占4B)表示接收方的IP地址
- 标志(占3位)MF = 1表示后面还有分片,DF = 0才允许分片

### 路由转发算法

1. 先看是不是路由器就在目标网络里,如果在直接发给目的主机
2. 若路由表中有这个主机的地址,就直接发送给这个主机
3. 如果路由表有这个网络的路由地址,就发送到目标网络路由中去
4. 再没有就发送到默认路由
5. 都没有就直接ICMP差错报文

### RIP路由协议

每30s都都广播一次RIP路由更新信息,把跳数最少的路径更新

### OSPF协议

直接广播,利用Dijkstra算法构造最优的路由表

### DNS寻址过程

1. 在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析
2. 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析
3. 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性
4. 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性
5. 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。       从客户端到本地DNS服务器是属于递归查询，而DNS服务器之间就是的交互查询就是迭代查询。   

### HTTP长连接短连接

- Connection:keep-alive
- **短连接**的操作步骤是:
  - 建立连接——数据传输——关闭连接...建立连接——数据传输——关闭连接
- **长连接**的操作步骤是:
  - 建立连接——数据传输...(保持连接)...数据传输——关闭连接
- **长连接**多用于操作频繁,点对点的通讯,而且连接数不能太多情况,,每个TCP连接都需要三步握手,这需要时间,如果每个操作都是先连接,再操作的话那么处理速度会降低很多,所以每个操作完后都不断开,次处理时直接发送数据包就OK了,不用建立TCP连接,例如:数据库的连接用长连接,如果用短连接频繁的通信会造成socket错误,而且频繁的socket 创建也是对资源的浪费
- 而像WEB网站的http服务一般都用**短链接**,因为长连接对于服务端来说会耗费一定的资源,而像WEB网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源,如果用长连接,而且同时有成千上万的用户,如果每个用户都占用一个连接的话,那可想而知吧,所以并发量大,但每个用户无需频繁操作情况下需用短连好

### 流量控制

什么是流量控制？流量控制的目的？

如果发送者发送数据过快,接收者来不及接收,那么就会有分组丢失,为了避免分组丢失,控制发送者的发送速度,使得接收者来得及接收,这就是流量控制,流量控制根本目的是防止分组丢失,它是构成TCP可靠性的一方面

如何实现流量控制？

由滑动窗口协议(连续ARQ协议)实现,滑动窗口协议既保证了分组无差错,有序接收,也实现了流量控制,主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小,并且利用大小来控制发送方的数据发送

流量控制引发的死锁？怎么避免死锁的发生？

当发送者收到了一个窗口为0的应答,发送者便停止发送,等待接收者的下一个应答,但是如果这个窗口不为0的应答在传输过程丢失,发送者一直等待下去,而接收者以为发送者已经收到该应答,等待接收新数据,这样双方就相互等待,从而产生死锁
为了避免流量控制引发的死锁,TCP使用了持续计时器,每当发送者收到一个零窗口的应答后就启动该计时器,时间一到便主动发送报文询问接收者的窗口大小,若接收者仍然返回零窗口,则重置该计时器继续等待,若窗口不为0,则表示应答报文丢失了,此时重置发送窗口后开始发送,这样就避免了死锁的产生

### 拥塞控制

我们在开始假定:1,数据是单方向传递,另一个窗口只发送确认,2,接收方的缓存足够大,因此发送方的大小的大小由网络的拥塞程度来决定

(一)慢开始算法:

发送方维持一个叫做拥塞窗口cwnd(congestion window)的状态变量,拥塞窗口的大小取决于网络的拥塞程度,并且动态地在变化,发送方让自己的发送窗口等于拥塞窗口,另外考虑到接受方的接收能力,发送窗口可能小于拥塞窗口

慢开始算法的思路就是,不要一开始就发送大量的数据,先探测一下网络的拥塞程度,也就是说由小到大逐渐增加拥塞窗口的大小

这里用报文段的个数作为拥塞窗口的大小举例说明慢开始算法,实际的拥塞窗口大小是以字节为单位的,如下图:

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123119.jpeg)

从上图可以看到,一个传输轮次所经历的时间其实就是往返时间RTT,而且没经过一个传输轮次(transmission round),拥塞窗口cwnd就加倍

为了防止cwnd增长过大引起网络拥塞,还需设置一个慢开始门限ssthresh状态变量,ssthresh的用法如下:当cwnd<ssthresh时,使用慢开始算法
当cwnd>ssthresh时,改用拥塞避免算法
当cwnd=ssthresh时,慢开始与拥塞避免算法任意

注意,这里的"慢”并不是指cwnd的增长速率慢,而是指在TCP开始发送报文段时先设置cwnd=1,然后逐渐增大,这当然比按照大的cwnd一下子把许多报文段突然注入到网络中要"慢得多”

(二)拥塞避免算法:

- 拥塞避免算法让拥塞窗口缓慢增长,即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1,而不是加倍,这样拥塞窗口按线性规律缓慢增长
- 无论是在慢开始阶段还是在拥塞避免阶段,只要发送方判断网络出现拥塞(其根据就是没有按时收到确认,虽然没有收到确认可能是其他原因的分组丢失,但是因为无法判定,所以都当做拥塞来处理),就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半(但不能小于2),然后把拥塞窗口cwnd重新设置为1,执行慢开始算法,这样做的目的就是要迅速减少主机发送到网络中的分组数,使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕

整个拥塞控制的流程如下图:

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123131.jpeg)

(1)拥塞窗口cwnd初始化为1个报文段,慢开始门限初始值为16
(2)执行慢开始算法,指数规律增长到第4轮,即cwnd=16=ssthresh,改为执行拥塞避免算法,拥塞窗口按线性规律增长
(3)假定cwnd=24时,网络出现超时(拥塞),则更新后的ssthresh=12,cwnd重新设置为1,并执行慢开始算法,当cwnd=12=ssthresh时,改为执行拥塞避免算法

关于 乘法减小(Multiplicative Decrease)和加法增大(Additive Increase):

"乘法减小”指的是无论是在慢开始阶段还是在拥塞避免阶段,只要发送方判断网络出现拥塞,就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半,并执行慢开始算法,所以当网络频繁出现拥塞时,ssthresh下降的很快,以大大减少注入到网络中的分组数,"加法增大”是指执行拥塞避免算法后,使拥塞窗口缓慢增大,以防止过早出现拥塞,常合起来成为AIMD算法

注意:"拥塞避免”并非完全能够避免了阻塞,而是使网络比较不容易出现拥塞

(三)快重传算法:

快重传要求接收方在收到一个失序的报文段后就立即发出重复确认(为的是使发送方及早知道有报文段没有到达对方,可提高网络吞吐量约20%)而不要等到自己发送数据时捎带确认,快重传算法规定,发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段,而不必继续等待设置的重传计时器时间到期,如下图:

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123139.jpeg)

(四)快恢复算法:

- 快重传配合使用的还有快恢复算法,有以下两个要点:
- 当发送方连续收到三个重复确认时,就执行"乘法减小”算法,把ssthresh门限减半(为了预防网络发生拥塞),但是接下去并不执行慢开始算法
  考虑到如果网络出现拥塞的话就不会收到好几个重复的确认,所以发送方现在认为网络可能没有出现拥塞,所以此时不执行慢开始算法,而是将cwnd设置为ssthresh减半后的值,然后执行拥塞避免算法,使cwnd缓慢增大,如下图:TCP Reno版本是目前使用最广泛的版本

![img](https://raw.githubusercontent.com/LuShan123888/Files/main/Pictures/20210611123148.jpeg)

注意:在采用快恢复算法时,慢开始算法只是在TCP连接建立时和网络出现超时时才使用

**拥塞控制和流量控制的区别**

拥塞控制:拥塞控制是作用于网络的,它是防止过多的数据注入到网络中,避免出现网络负载过大的情况,常用的方法就是:(1)慢开始,拥塞避免(2)快重传,快恢复

流量控制:流量控制是作用于接收者的,它是控制发送者的发送速度从而使接收者来得及接收,防止分组丢失的

## JS

### 什么是闭包

- 闭包就是能够读取其他函数内部变量的函数
- 由于在Javascript语言中,只有函数内部的子函数才能读取局部变量,因此可以把闭包简单理解成"定义在一个函数内部的函数"
- 所以,在本质上,闭包就是将函数内部和函数外部连接起来的一座桥梁

##

## 场景题

### 高并发减库存

**一,防止重复**

**利用redis分布式锁**

用分布式锁,是为了防刷,防止同一个用户同一秒里面把购物车里的商品进行多次结算,防止前端代码出问题触发两次,利用Jedis客户端编写分布式锁

```java
String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime);
```

lockKey是redis的Key,为用户id+商品id+商品数量组成,这样同一秒中只能有一次处理逻辑,requestId是redis的value,实际是当前线程id,表示有一条线程占用

> 大家要注意这种分布式锁写法,是同时设定超时时间的,有些分布式锁的文章可能是比较旧版的redis不支持同时设置超时时间,他就一条语句先设置key value,另一条语句后设置超时时间,所以大家留意一下

**二,扣减库存**

安全扣减库存方案有很多说法,列一下几个方案和我推荐的方案

**方案一:分布式锁**

有的文章会用redis分布式锁来做保证扣库存数量准确的环节,让点击结算时,后端逻辑会查询库存和扣库存的update语句同时只有一条线程能够执行,以商品id为分布式锁的key,锁一个商品,但是这样,其他购买相同商品的用户将会进行等待

- 优点:这样做虽然安全
- 缺点:但是失去的是性能问题

**方案二:分布式锁+分段缓存**

也有文章会说借鉴ConcurrenthashMap,分段锁的机制,把100个商品,分在3个段上,key为分段名字,value为库存数量,用户下单时对用户id进行%3计算,看落在哪个redis的key上,就去取哪个

> 如key1=product-01,value1=33;key2=product-02,value2=33;key3=product-03,value3=33;

其实会有几个问题:

- 一个是用户想买34件的时候,要去两个片查
- 一个片上卖完了为0,又要去另外一个片查
- 取余方式计算每一片数量,除不尽时,让最后一片补,如100/3=33.33

**缺点**

- 方案复杂
- 有遗留问题

**方案三:redis的lpush rpop**

redis队列的lpush,rpop都是只能每次进出一个,对于购买多个数量的情况下不适用,只适用于秒杀情况购买一个的场景,或者抢红包的场景,所以觉得不是很通用

> 备注:这个抢红包场景以后再分享

**方案四:推荐使用redis原子操作+sql乐观锁**

**利用Redis increment 的原子操作,保证库存数安全**

1. 先查询redis中是否有库存信息,如果没有就去数据库查,这样就可以减少访问数据库的次数,获取到后把数值填入redis,以商品id为key,数量为value,注意要设置**序列化方式为StringRedisSerializer**,不然不能把value做加减操作,还需要设置redis对应这个key的超时时间,以防所有商品库存数据都在redis中
2. 比较下单数量的大小,如果够就做后续逻辑
3. 执行redis客户端的increment,参数为负数,则做减法,因为redis是**单线程处理**,并且因为**increment让key对应的value 减少后返回的是修改后的值**,有的人会不做第一步查询直接减,其实这样不太好,因为当库存为1时,很多做减3,或者减30情况,其实都是不够,这样就白减
4. 扣减数据库的库存,这个时候就不需要再select查询,直接乐观锁update,把库存字段值减1 
5. 做完扣库存就在订单系统做下单

**样例场景**

1. 假设两个用户在第一步查询得到库存等于10,A用户走到第二步扣10件,同时一秒内B用户走到第二部扣3件
2. 因为redis单线程处理,若A用户线程先执行redis语句,那么现在库存等于0,B就只能失败,就不会出更新数据库了

```java
public void order(OrderReq req) {
  String key = "product:" + req.getProductId();
  // 第一步:先检查 库存是否充足
  Integer num = (Integer) redisTemplate.get(key);
  if (num == null){
    // 去查数据库的数据
    // 并且把数据库的库存set进redis,注意使用NX参数表示只有当没有redis中没有这个key的时候才set库存数量到redis
    //注意要设置序列化方式为StringRedisSerializer,不然不能把value做加减操作
    // 同时设置超时时间,因为不能让redis存着所有商品的库存数,以免占用内存
    if (count >=0) {
      //设置有效期十分钟
      redisTemplate.expire(key, 60*10+随机数防止雪崩, TimeUnit.SECONDS);
    }
    // 减少经常访问数据库,因为磁盘比内存访问速度要慢
  }
  if (num < req.getNum()) {
    logger.info("库存不足");
  }
  // 第二步:减少库存
  long value = redisTemplate.increment(key, -req.getNum().longValue());
  // 库存充足
  if (value >= 0) {
    logger.info("成功购买");
    // update 数据库中商品库存和订单系统下单,单的状态未待支付
    // 分开两个系统处理时,可以用LCN做分布式事务,但是也是有概率会订单系统的网络超时
    // 也可以使用最终一致性的方式,更新库存成功后,发送mq,等待订单创建生成回调
    boolean res= updateProduct(req);
    if (res)
      createOrder(req);
  } else {
    // 减了后小小于0,如两个人同时买这个商品,导致A人第一步时看到还有10个库存,但是B人买9个先处理完逻辑
    // 导致B人的线程10-9=1, A人的线程1-10=-9,则现在需要增加刚刚减去的库存,让别人可以买1个
    redisTemplate.increment(key, req.getNum().longValue());
    logger.info("恢复redis库存");
  }
}
```

**update使用乐观锁**

updateProduct方法中执行的sql如下:

```
update Product set count = count - #{购买数量} where id = #{id} and count - #{购买数量} >= 0;
复制代码
```

虽然redis已经防止了超卖,但是数据库层面,为了也要防止超卖,以防redis崩溃时无法使用或者不需要redis处理时,则用乐观锁,因为不一定全部商品都用redis

利用sql每条单条语句都是有事务的,所以两条sql同时执行,也就只会有其中一条sql先执行成功,另外一条后执行,也如上文提及到的场景一样

**分布式事务**

分开两个系统处理库存和订单时,这个时候可以用LCN框架做分布式事务,但是因为是http请求的,也是有概率会订单系统的网络超时,导致未返回结果

其实也可以使用最终一致性的方式,数据表记录一条交互流水记录,更新库存成功后,更新这个交互流水记录的库存操作字段为已处理,订单处理字段为处理中,然后发送mq,等待订单创建生成回调,也要做定时任务做主动查询订单系统的结果,以防没有结果回来

**方案优势**

- 不需要频繁访问数据库商品库存还有多少
- 不阻塞其他用户
- 安全扣减库存量
- 内存访问库存数量,减少数据库交互

**高并发额外优化**

- 用户访问下单是,前端ui可以让用户触发结算后,把按钮置灰色,防止重复触发
- 可以按照库存数量来选定是否要用redis,因为如果库存数量少,或者说最近下单次数少的商品,就不用放redis,因为少人看和买的情况下,不必放redis导致占用内存
- 如果到时间点抢购时,可以使用mq队列形式,用户触发购买商品后,进入队列,让用户的页面一直在转圈圈,等轮到他买的时候再进入结算页面,结算页面的后续流程和本文一致

### 如何保证Redis和 MySQL双写数据一致性

**1.MySQL持久化数据,Redis只读数据**

redis在启动之后,从数据库加载数据

**读请求**

**不要求强一致性的读请求,走redis,要求强一致性的直接从mysql读取**

**写请求**

**数据首先都写到数据库,之后更新redis**(先写redis再写mysql,如果写入失败事务回滚会造成redis中存在脏数据)

**2.MySQL和Redis处理不同的数据类型**

- MySQL处理实时性数据,例如金融数据,交易数据
- Redis处理实时性要求不高的数据,例如网站最热贴排行榜,好友列表等

在并发不高的情况下,读操作优先读取redis,不存在的话就去访问MySQL,并把读到的数据写回Redis中

写操作的话,直接写MySQL,成功后再写入Redis(可以在MySQL端定义CRUD触发器,在触发CRUD操作后写数据到Redis,也可以在Redis端解析binlog,再做相应的操作)

在并发高的情况下,读操作和上面一样,写操作是异步写,写入Redis后直接返回,然后定期写入MySQL

几个例子:

1.当更新数据时,如更新某商品的库存,当前商品的库存是100,现在要更新为99,先更新数据库更改成99,然后删除缓存,发现删除缓存失败了,这意味着数据库存的是99,而缓存是100,这导致数据库和缓存不一致

解决方法:

这种情况应该是先删除缓存,然后再更新数据库,如果删除缓存失败,那就不要更新数据库,如果说删除缓存成功,而更新数据库失败,那查询的时候只是从数据库里查了旧的数据而已,这样就能保持数据库与缓存的一致性

2.在高并发的情况下,如果当删除完缓存的时候,这时去更新数据库,但还没有更新完,另外一个请求来查询数据,发现缓存里没有,就去数据库里查,还是以上面商品库存为例,如果数据库中产品的库存是100,那么查询到的库存是100,然后插入缓存,插入完缓存后,原来那个更新数据库的线程把数据库更新为了99,导致数据库与缓存不一致的情况

解决方法:

遇到这种情况,可以用队列的去解决这个问,创建几个队列,如20个,根据商品的ID去做hash值,然后对队列个数取摸,当有数据更新请求时,先把它丢到队列里去,当更新完后再从队列里去除,如果在更新的过程中,遇到以上场景,先去缓存里看下有没有数据,如果没有,可以先去队列里看是否有相同商品ID在做更新,如果有也把查询的请求发送到队列里去,然后同步等待缓存更新完成

这里有一个优化点,如果发现队列里有一个查询请求了,那么就不要放新的查询操作进去了,用一个while(true)循环去查询缓存,循环个200MS左右,如果缓存里还没有则直接取数据库的旧数据,一般情况下是可以取到的

在高并发下解决场景二要注意的问题:

**1,读请求时长阻塞**

由于读请求进行了非常轻度的异步化,所以一定要注意读超时的问题,每个读请求必须在超时间内返回,该解决方案最大的风险在于可能数据更新很频繁,导致队列中挤压了大量的更新操作在里面,然后读请求会发生大量的超时,最后导致大量的请求直接走数据库,像遇到这种情况,一般要做好足够的压力测试,如果压力过大,需要根据实际情况添加机器

**2,请求并发量过高**

这里还是要做好压力测试,多模拟真实场景,并发量在最高的时候QPS多少,扛不住就要多加机器,还有就是做好读写比例是多少

**3,多服务实例部署的请求路由**

可能这个服务部署了多个实例,那么必须保证说,执行数据更新操作,以及执行缓存更新操作的请求,都通过nginx服务器路由到相同的服务实例上

**4,热点商品的路由问题,导致请求的倾斜**

某些商品的读请求特别高,全部打到了相同的机器的相同丢列里了,可能造成某台服务器压力过大,因为只有在商品数据更新的时候才会清空缓存,然后才会导致读写并发,所以更新频率不是太高的话,这个问题的影响并不是很大,但是确实有可能某些服务器的负载会高一些

![如何保证Redis和 MySQL双写数据一致性](http://p3.pstatp.com/large/pgc-image/51d30e5381ca4663aff8c97a39c9af9f)